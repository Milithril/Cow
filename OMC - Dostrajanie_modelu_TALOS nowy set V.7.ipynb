{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hairy-iraqi",
   "metadata": {},
   "source": [
    "## 1. Biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compressed-russell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import talos as ta\n",
    "from talos.model.early_stopper import early_stopper\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-upset",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "humanitarian-desperate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1881, 26)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv('D:/STUDIA/ROK_II/Projekt/Dane_jalowka_i_krowa_train.csv')\n",
    "test_df=pd.read_csv('D:/STUDIA/ROK_II/Projekt/Dane_jalowka_i_krowa_test.csv')\n",
    "val_df=pd.read_csv('D:/STUDIA/ROK_II/Projekt/Dane_jalowka_i_krowa_val.csv')\n",
    "\n",
    "train_df.columns = ['id','Województwo', 'Data urodzenia', 'IE', 'Dokł. IE', 'PF', 'PI-PROD', 'PI-POKR', 'Prc', 'Psm', 'Pnr', 'Pw','PI-PLOD', 'CRj', 'CRk', 'PP', 'OMC', 'WH-KSOM', 'WH-DLUG', 'IP', 'kg ml', 'kg tł', '% tł', 'kg bi', '% bi', 'rc', 'sm', 'nr', 'w', 'og','kategoria']\n",
    "test_df.columns = ['id','Województwo', 'Data urodzenia', 'IE', 'Dokł. IE', 'PF', 'PI-PROD', 'PI-POKR', 'Prc', 'Psm', 'Pnr', 'Pw','PI-PLOD', 'CRj', 'CRk', 'PP', 'OMC', 'WH-KSOM', 'WH-DLUG', 'IP', 'kg ml', 'kg tł', '% tł', 'kg bi', '% bi', 'rc', 'sm', 'nr', 'w', 'og','kategoria']\n",
    "val_df.columns = ['id','Województwo', 'Data urodzenia', 'IE', 'Dokł. IE', 'PF', 'PI-PROD', 'PI-POKR', 'Prc', 'Psm', 'Pnr', 'Pw','PI-PLOD', 'CRj', 'CRk', 'PP', 'OMC', 'WH-KSOM', 'WH-DLUG', 'IP', 'kg ml', 'kg tł', '% tł', 'kg bi', '% bi', 'rc', 'sm', 'nr', 'w', 'og','kategoria']\n",
    "\n",
    "caly_df = pd.concat([train_df, test_df, val_df])\n",
    "caly_df['Województwo']=caly_df['Województwo'].astype('category')\n",
    "caly_df['Data urodzenia']=caly_df['Data urodzenia'].astype('category')\n",
    "\n",
    "del caly_df[\"id\"]\n",
    "del caly_df[\"PF\"]\n",
    "del caly_df[\"IE\"]\n",
    "del caly_df[\"Dokł. IE\"]\n",
    "del caly_df['kategoria']\n",
    "\n",
    "caly_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b3fcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Województwo</th>\n",
       "      <th>Data urodzenia</th>\n",
       "      <th>PI-PROD</th>\n",
       "      <th>PI-POKR</th>\n",
       "      <th>Prc</th>\n",
       "      <th>Psm</th>\n",
       "      <th>Pnr</th>\n",
       "      <th>Pw</th>\n",
       "      <th>PI-PLOD</th>\n",
       "      <th>CRj</th>\n",
       "      <th>...</th>\n",
       "      <th>kg ml</th>\n",
       "      <th>kg tł</th>\n",
       "      <th>% tł</th>\n",
       "      <th>kg bi</th>\n",
       "      <th>% bi</th>\n",
       "      <th>rc</th>\n",
       "      <th>sm</th>\n",
       "      <th>nr</th>\n",
       "      <th>w</th>\n",
       "      <th>og</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIELKOPOLSKIE</td>\n",
       "      <td>2020</td>\n",
       "      <td>137</td>\n",
       "      <td>127</td>\n",
       "      <td>121</td>\n",
       "      <td>113</td>\n",
       "      <td>106</td>\n",
       "      <td>128</td>\n",
       "      <td>109</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>1370</td>\n",
       "      <td>577</td>\n",
       "      <td>2</td>\n",
       "      <td>452</td>\n",
       "      <td>1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KUJAWSKO-POMORSKIE</td>\n",
       "      <td>2018</td>\n",
       "      <td>126</td>\n",
       "      <td>123</td>\n",
       "      <td>109</td>\n",
       "      <td>113</td>\n",
       "      <td>103</td>\n",
       "      <td>128</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>1209</td>\n",
       "      <td>358</td>\n",
       "      <td>-16</td>\n",
       "      <td>354</td>\n",
       "      <td>-4</td>\n",
       "      <td>115.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POMORSKIE</td>\n",
       "      <td>2020</td>\n",
       "      <td>126</td>\n",
       "      <td>120</td>\n",
       "      <td>110</td>\n",
       "      <td>107</td>\n",
       "      <td>102</td>\n",
       "      <td>124</td>\n",
       "      <td>113</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>982</td>\n",
       "      <td>368</td>\n",
       "      <td>-4</td>\n",
       "      <td>350</td>\n",
       "      <td>4</td>\n",
       "      <td>104.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KUJAWSKO-POMORSKIE</td>\n",
       "      <td>2020</td>\n",
       "      <td>133</td>\n",
       "      <td>111</td>\n",
       "      <td>104</td>\n",
       "      <td>110</td>\n",
       "      <td>99</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>1080</td>\n",
       "      <td>546</td>\n",
       "      <td>12</td>\n",
       "      <td>410</td>\n",
       "      <td>7</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZACHODNIOPOMORSKIE</td>\n",
       "      <td>2020</td>\n",
       "      <td>125</td>\n",
       "      <td>115</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "      <td>101</td>\n",
       "      <td>124</td>\n",
       "      <td>134</td>\n",
       "      <td>129</td>\n",
       "      <td>...</td>\n",
       "      <td>516</td>\n",
       "      <td>501</td>\n",
       "      <td>36</td>\n",
       "      <td>289</td>\n",
       "      <td>15</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Województwo Data urodzenia  PI-PROD  PI-POKR  Prc  Psm  Pnr   Pw  \\\n",
       "0       WIELKOPOLSKIE           2020      137      127  121  113  106  128   \n",
       "1  KUJAWSKO-POMORSKIE           2018      126      123  109  113  103  128   \n",
       "2           POMORSKIE           2020      126      120  110  107  102  124   \n",
       "3  KUJAWSKO-POMORSKIE           2020      133      111  104  110   99  114   \n",
       "4  ZACHODNIOPOMORSKIE           2020      125      115   91   95  101  124   \n",
       "\n",
       "   PI-PLOD  CRj  ...  kg ml  kg tł  % tł  kg bi  % bi     rc     sm     nr  \\\n",
       "0      109  107  ...   1370    577     2    452     1  115.0  114.0  109.0   \n",
       "1      114  114  ...   1209    358   -16    354    -4  115.0  113.0  104.0   \n",
       "2      113  112  ...    982    368    -4    350     4  104.0  103.0  102.0   \n",
       "3      114  113  ...   1080    546    12    410     7  106.0  106.0  101.0   \n",
       "4      134  129  ...    516    501    36    289    15  102.0  102.0  118.0   \n",
       "\n",
       "       w     og  \n",
       "0  127.0  123.0  \n",
       "1  123.0  123.0  \n",
       "2  122.0  117.0  \n",
       "3  112.0  112.0  \n",
       "4  123.0  109.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1db4b939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1881 entries, 0 to 188\n",
      "Data columns (total 26 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   Województwo     1881 non-null   category\n",
      " 1   Data urodzenia  1881 non-null   category\n",
      " 2   PI-PROD         1881 non-null   int64   \n",
      " 3   PI-POKR         1881 non-null   int64   \n",
      " 4   Prc             1881 non-null   int64   \n",
      " 5   Psm             1881 non-null   int64   \n",
      " 6   Pnr             1881 non-null   int64   \n",
      " 7   Pw              1881 non-null   int64   \n",
      " 8   PI-PLOD         1881 non-null   int64   \n",
      " 9   CRj             1881 non-null   int64   \n",
      " 10  CRk             1881 non-null   int64   \n",
      " 11  PP              1881 non-null   int64   \n",
      " 12  OMC             1881 non-null   int64   \n",
      " 13  WH-KSOM         1881 non-null   int64   \n",
      " 14  WH-DLUG         1881 non-null   int64   \n",
      " 15  IP              1881 non-null   int64   \n",
      " 16  kg ml           1881 non-null   int64   \n",
      " 17  kg tł           1881 non-null   int64   \n",
      " 18  % tł            1881 non-null   int64   \n",
      " 19  kg bi           1881 non-null   int64   \n",
      " 20  % bi            1881 non-null   int64   \n",
      " 21  rc              1881 non-null   float64 \n",
      " 22  sm              1881 non-null   float64 \n",
      " 23  nr              1881 non-null   float64 \n",
      " 24  w               1881 non-null   float64 \n",
      " 25  og              1881 non-null   float64 \n",
      "dtypes: category(2), float64(5), int64(19)\n",
      "memory usage: 372.1 KB\n"
     ]
    }
   ],
   "source": [
    "caly_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26512094",
   "metadata": {},
   "source": [
    "## 3. Usuwam mniejszości zmiennych kategorycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e25cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WIELKOPOLSKIE          579\n",
       "KUJAWSKO-POMORSKIE     298\n",
       "OPOLSKIE               227\n",
       "ZACHODNIOPOMORSKIE     212\n",
       "PODLASKIE              175\n",
       "MAZOWIECKIE            106\n",
       "POMORSKIE               94\n",
       "LUBUSKIE                47\n",
       "ŁÓDZKIE                 41\n",
       "DOLNOŚLĄSKIE            32\n",
       "WARMIŃSKO-MAZURSKIE     23\n",
       "ŚLĄSKIE                 17\n",
       "ŚWIĘTOKRZYSKIE          13\n",
       "MAŁOPOLSKIE             12\n",
       "LUBELSKIE                4\n",
       "PODKARPACKIE             1\n",
       "Name: Województwo, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caly_df['Województwo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab61a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "caly_df=caly_df[caly_df['Województwo']!='PODKARPACKIE']\n",
    "caly_df=caly_df[caly_df['Województwo']!='LUBELSKIE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8facbffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WIELKOPOLSKIE          579\n",
       "KUJAWSKO-POMORSKIE     298\n",
       "OPOLSKIE               227\n",
       "ZACHODNIOPOMORSKIE     212\n",
       "PODLASKIE              175\n",
       "MAZOWIECKIE            106\n",
       "POMORSKIE               94\n",
       "LUBUSKIE                47\n",
       "ŁÓDZKIE                 41\n",
       "DOLNOŚLĄSKIE            32\n",
       "WARMIŃSKO-MAZURSKIE     23\n",
       "ŚLĄSKIE                 17\n",
       "ŚWIĘTOKRZYSKIE          13\n",
       "MAŁOPOLSKIE             12\n",
       "LUBELSKIE                0\n",
       "PODKARPACKIE             0\n",
       "Name: Województwo, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caly_df['Województwo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8d9702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    1066\n",
       "2019     396\n",
       "2018     275\n",
       "2017      68\n",
       "2021      47\n",
       "2016      23\n",
       "2015       1\n",
       "Name: Data urodzenia, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caly_df['Data urodzenia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3248c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "caly_df=caly_df[caly_df['Data urodzenia']!=2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3340ad27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    1066\n",
       "2019     396\n",
       "2018     275\n",
       "2017      68\n",
       "2021      47\n",
       "2016      23\n",
       "2015       0\n",
       "Name: Data urodzenia, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caly_df['Data urodzenia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb3aef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 26)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caly_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c159c",
   "metadata": {},
   "source": [
    "## 4. Zakodowuje zmienne kategoryczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1643a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.get_dummies(caly_df['Województwo'])\n",
    "b=pd.get_dummies(caly_df['Data urodzenia'])\n",
    "caly_df= pd.concat([caly_df,a,b], axis=1)\n",
    "del caly_df['Województwo']\n",
    "del caly_df['Data urodzenia']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756e767",
   "metadata": {},
   "source": [
    "## 5. Klasyfikuje wartosci IE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "513abdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.,   0.,   2.,   9.,  11.,  12.,  29.,  25.,  22.,  71., 121.,\n",
       "         61., 166., 174., 106., 234., 190.,  98., 148., 122.,  53.,  78.,\n",
       "         58.,  20.,  33.,  13.,   9.,   5.,   1.,   2.]),\n",
       " array([ 82.        ,  83.66666667,  85.33333333,  87.        ,\n",
       "         88.66666667,  90.33333333,  92.        ,  93.66666667,\n",
       "         95.33333333,  97.        ,  98.66666667, 100.33333333,\n",
       "        102.        , 103.66666667, 105.33333333, 107.        ,\n",
       "        108.66666667, 110.33333333, 112.        , 113.66666667,\n",
       "        115.33333333, 117.        , 118.66666667, 120.33333333,\n",
       "        122.        , 123.66666667, 125.33333333, 127.        ,\n",
       "        128.66666667, 130.33333333, 132.        ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(caly_df[\"OMC\"],bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f618a743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1875.000000\n",
       "mean      107.665067\n",
       "std         7.413236\n",
       "min        82.000000\n",
       "25%       103.000000\n",
       "50%       107.000000\n",
       "75%       112.000000\n",
       "max       132.000000\n",
       "Name: OMC, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caly_df[\"OMC\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0761d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "caly_df.loc[(caly_df[\"OMC\"]<=103), \"Klasa\"] = \"Małe\"\n",
    "caly_df.loc[(103<caly_df[\"OMC\"]) & (caly_df[\"OMC\"]<=107), \"Klasa\"] = \"Średnie\"\n",
    "caly_df.loc[(107<caly_df[\"OMC\"]) & (caly_df[\"OMC\"]<=112), \"Klasa\"] = \"Wysokie\"\n",
    "caly_df.loc[caly_df[\"OMC\"]>112, \"Klasa\"] = \"Ekstrimum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "910d75b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([415.,   0.,   0., 531.,   0.,   0., 465.,   0.,   0., 464.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(caly_df[\"Klasa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "958a64f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Małe         531\n",
       "Ekstrimum    465\n",
       "Wysokie      464\n",
       "Średnie      415\n",
       "Name: Klasa, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caly_df[\"Klasa\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "268437e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PI-PROD',\n",
       " 'PI-POKR',\n",
       " 'Prc',\n",
       " 'Psm',\n",
       " 'Pnr',\n",
       " 'Pw',\n",
       " 'PI-PLOD',\n",
       " 'CRj',\n",
       " 'CRk',\n",
       " 'PP',\n",
       " 'OMC',\n",
       " 'WH-KSOM',\n",
       " 'WH-DLUG',\n",
       " 'IP',\n",
       " 'kg ml',\n",
       " 'kg tł',\n",
       " '% tł',\n",
       " 'kg bi',\n",
       " '% bi',\n",
       " 'rc',\n",
       " 'sm',\n",
       " 'nr',\n",
       " 'w',\n",
       " 'og',\n",
       " 'DOLNOŚLĄSKIE',\n",
       " 'KUJAWSKO-POMORSKIE',\n",
       " 'LUBELSKIE',\n",
       " 'LUBUSKIE',\n",
       " 'MAZOWIECKIE',\n",
       " 'MAŁOPOLSKIE',\n",
       " 'OPOLSKIE',\n",
       " 'PODKARPACKIE',\n",
       " 'PODLASKIE',\n",
       " 'POMORSKIE',\n",
       " 'WARMIŃSKO-MAZURSKIE',\n",
       " 'WIELKOPOLSKIE',\n",
       " 'ZACHODNIOPOMORSKIE',\n",
       " 'ŁÓDZKIE',\n",
       " 'ŚLĄSKIE',\n",
       " 'ŚWIĘTOKRZYSKIE',\n",
       " 2015,\n",
       " 2016,\n",
       " 2017,\n",
       " 2018,\n",
       " 2019,\n",
       " 2020,\n",
       " 2021,\n",
       " 'Klasa']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(caly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33410b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(caly_df, test_size=0.2, random_state=42,stratify=caly_df['Klasa'])\n",
    "#test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=42,stratify=test_df['Klasa'])\n",
    "\n",
    "del train_df['Klasa']\n",
    "del test_df['Klasa']\n",
    "#del val_df['Klasa']\n",
    "\n",
    "\n",
    "train_label=train_df['OMC']\n",
    "test_label=test_df['OMC']\n",
    "#val_label=val_df['IE']\n",
    "\n",
    "del train_df['OMC']\n",
    "del test_df['OMC']\n",
    "#del val_df['IE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cb06bd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PI-PROD',\n",
       " 'PI-POKR',\n",
       " 'Prc',\n",
       " 'Psm',\n",
       " 'Pnr',\n",
       " 'Pw',\n",
       " 'PI-PLOD',\n",
       " 'CRj',\n",
       " 'CRk',\n",
       " 'PP',\n",
       " 'WH-KSOM',\n",
       " 'WH-DLUG',\n",
       " 'IP',\n",
       " 'kg ml',\n",
       " 'kg tł',\n",
       " '% tł',\n",
       " 'kg bi',\n",
       " '% bi',\n",
       " 'rc',\n",
       " 'sm',\n",
       " 'nr',\n",
       " 'w',\n",
       " 'og',\n",
       " 'DOLNOŚLĄSKIE',\n",
       " 'KUJAWSKO-POMORSKIE',\n",
       " 'LUBELSKIE',\n",
       " 'LUBUSKIE',\n",
       " 'MAZOWIECKIE',\n",
       " 'MAŁOPOLSKIE',\n",
       " 'OPOLSKIE',\n",
       " 'PODKARPACKIE',\n",
       " 'PODLASKIE',\n",
       " 'POMORSKIE',\n",
       " 'WARMIŃSKO-MAZURSKIE',\n",
       " 'WIELKOPOLSKIE',\n",
       " 'ZACHODNIOPOMORSKIE',\n",
       " 'ŁÓDZKIE',\n",
       " 'ŚLĄSKIE',\n",
       " 'ŚWIĘTOKRZYSKIE',\n",
       " 2015,\n",
       " 2016,\n",
       " 2017,\n",
       " 2018,\n",
       " 2019,\n",
       " 2020,\n",
       " 2021]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ef6a0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-precipitation",
   "metadata": {},
   "source": [
    "## 1.2 Standaryzacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bd3a3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PI-PROD</th>\n",
       "      <th>PI-POKR</th>\n",
       "      <th>Prc</th>\n",
       "      <th>Psm</th>\n",
       "      <th>Pnr</th>\n",
       "      <th>Pw</th>\n",
       "      <th>PI-PLOD</th>\n",
       "      <th>CRj</th>\n",
       "      <th>CRk</th>\n",
       "      <th>PP</th>\n",
       "      <th>...</th>\n",
       "      <th>kg ml</th>\n",
       "      <th>kg tł</th>\n",
       "      <th>% tł</th>\n",
       "      <th>kg bi</th>\n",
       "      <th>% bi</th>\n",
       "      <th>rc</th>\n",
       "      <th>sm</th>\n",
       "      <th>nr</th>\n",
       "      <th>w</th>\n",
       "      <th>og</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>133</td>\n",
       "      <td>115</td>\n",
       "      <td>105</td>\n",
       "      <td>107</td>\n",
       "      <td>111</td>\n",
       "      <td>113</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>103</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>1325</td>\n",
       "      <td>474</td>\n",
       "      <td>-8</td>\n",
       "      <td>429</td>\n",
       "      <td>0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>125</td>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>104</td>\n",
       "      <td>98</td>\n",
       "      <td>123</td>\n",
       "      <td>120</td>\n",
       "      <td>118</td>\n",
       "      <td>120</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>478</td>\n",
       "      <td>523</td>\n",
       "      <td>41</td>\n",
       "      <td>288</td>\n",
       "      <td>16</td>\n",
       "      <td>106.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>123</td>\n",
       "      <td>119</td>\n",
       "      <td>101</td>\n",
       "      <td>108</td>\n",
       "      <td>103</td>\n",
       "      <td>124</td>\n",
       "      <td>116</td>\n",
       "      <td>114</td>\n",
       "      <td>116</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>1091</td>\n",
       "      <td>418</td>\n",
       "      <td>-3</td>\n",
       "      <td>287</td>\n",
       "      <td>-8</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131</td>\n",
       "      <td>113</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>103</td>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>113</td>\n",
       "      <td>116</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>902</td>\n",
       "      <td>516</td>\n",
       "      <td>17</td>\n",
       "      <td>378</td>\n",
       "      <td>10</td>\n",
       "      <td>105.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>121</td>\n",
       "      <td>112</td>\n",
       "      <td>105</td>\n",
       "      <td>94</td>\n",
       "      <td>103</td>\n",
       "      <td>116</td>\n",
       "      <td>120</td>\n",
       "      <td>117</td>\n",
       "      <td>122</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>1040</td>\n",
       "      <td>379</td>\n",
       "      <td>-5</td>\n",
       "      <td>270</td>\n",
       "      <td>-8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>129</td>\n",
       "      <td>113</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>121</td>\n",
       "      <td>120</td>\n",
       "      <td>116</td>\n",
       "      <td>121</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>843</td>\n",
       "      <td>602</td>\n",
       "      <td>30</td>\n",
       "      <td>316</td>\n",
       "      <td>5</td>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>126</td>\n",
       "      <td>118</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>110</td>\n",
       "      <td>116</td>\n",
       "      <td>113</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>783</td>\n",
       "      <td>374</td>\n",
       "      <td>6</td>\n",
       "      <td>348</td>\n",
       "      <td>11</td>\n",
       "      <td>108.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>125</td>\n",
       "      <td>111</td>\n",
       "      <td>96</td>\n",
       "      <td>108</td>\n",
       "      <td>107</td>\n",
       "      <td>111</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>107</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>983</td>\n",
       "      <td>398</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>128</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>111</td>\n",
       "      <td>104</td>\n",
       "      <td>106</td>\n",
       "      <td>115</td>\n",
       "      <td>114</td>\n",
       "      <td>119</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>888</td>\n",
       "      <td>491</td>\n",
       "      <td>15</td>\n",
       "      <td>339</td>\n",
       "      <td>6</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>126</td>\n",
       "      <td>109</td>\n",
       "      <td>88</td>\n",
       "      <td>98</td>\n",
       "      <td>102</td>\n",
       "      <td>114</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>1369</td>\n",
       "      <td>314</td>\n",
       "      <td>-28</td>\n",
       "      <td>380</td>\n",
       "      <td>-7</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PI-PROD  PI-POKR  Prc  Psm  Pnr   Pw  PI-PLOD  CRj  CRk   PP  ...  \\\n",
       "1119      133      115  105  107  111  113      104  105  103   96  ...   \n",
       "1093      125      117  115  104   98  123      120  118  120   99  ...   \n",
       "613       123      119  101  108  103  124      116  114  116  102  ...   \n",
       "3         131      113   98  100  103  117      115  113  116  102  ...   \n",
       "816       121      112  105   94  103  116      120  117  122   99  ...   \n",
       "...       ...      ...  ...  ...  ...  ...      ...  ...  ...  ...  ...   \n",
       "110       129      113   90  100  100  121      120  116  121  105  ...   \n",
       "608       126      118  108  108  110  116      113  107  113  117  ...   \n",
       "273       125      111   96  108  107  111      109  108  107  104  ...   \n",
       "1478      128      109  108  111  104  106      115  114  119   93  ...   \n",
       "1250      126      109   88   98  102  114      111  111  111   99  ...   \n",
       "\n",
       "      kg ml  kg tł  % tł  kg bi  % bi     rc     sm     nr      w     og  \n",
       "1119   1325    474    -8    429     0  107.0  109.0  117.0  111.0  114.0  \n",
       "1093    478    523    41    288    16  106.0  101.0  106.0  120.0  111.0  \n",
       "613    1091    418    -3    287    -8  107.0  107.0  112.0  125.0  118.0  \n",
       "3       902    516    17    378    10  105.0  103.0  110.0  118.0  109.0  \n",
       "816    1040    379    -5    270    -8   90.0   93.0  100.0  117.0  107.0  \n",
       "...     ...    ...   ...    ...   ...    ...    ...    ...    ...    ...  \n",
       "110     843    602    30    316     5  101.0  100.0  114.0  121.0  111.0  \n",
       "608     783    374     6    348    11  108.0  107.0  117.0  115.0  113.0  \n",
       "273     983    398     0    321     0  107.0  106.0  116.0  115.0  111.0  \n",
       "1478    888    491    15    339     6  108.0  108.0  105.0  108.0  111.0  \n",
       "1250   1369    314   -28    380    -7   99.0   98.0  113.0  115.0  105.0  \n",
       "\n",
       "[1500 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[:,:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "indonesian-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_df.iloc[:,:23]=scaler.fit_transform(train_df.iloc[:,:23])\n",
    "test_df.iloc[:,:23]=scaler.fit_transform(test_df.iloc[:,:23])\n",
    "#val_df.iloc[:,14:]=scaler.fit_transform(val_df.iloc[:,14:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcc66d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>w</th>\n",
       "      <th>og</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>0.680709</td>\n",
       "      <td>-1.138843</td>\n",
       "      <td>-0.140075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>-0.819652</td>\n",
       "      <td>0.104636</td>\n",
       "      <td>-0.584915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>-0.001273</td>\n",
       "      <td>0.795458</td>\n",
       "      <td>0.453044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.274066</td>\n",
       "      <td>-0.171692</td>\n",
       "      <td>-0.881474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>-1.638030</td>\n",
       "      <td>-0.309857</td>\n",
       "      <td>-1.178034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.271520</td>\n",
       "      <td>0.242801</td>\n",
       "      <td>-0.584915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0.680709</td>\n",
       "      <td>-0.586185</td>\n",
       "      <td>-0.288355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.544313</td>\n",
       "      <td>-0.586185</td>\n",
       "      <td>-0.584915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>-0.956048</td>\n",
       "      <td>-1.553336</td>\n",
       "      <td>-0.584915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>0.135123</td>\n",
       "      <td>-0.586185</td>\n",
       "      <td>-1.474594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            nr         w        og\n",
       "1119  0.680709 -1.138843 -0.140075\n",
       "1093 -0.819652  0.104636 -0.584915\n",
       "613  -0.001273  0.795458  0.453044\n",
       "3    -0.274066 -0.171692 -0.881474\n",
       "816  -1.638030 -0.309857 -1.178034\n",
       "...        ...       ...       ...\n",
       "110   0.271520  0.242801 -0.584915\n",
       "608   0.680709 -0.586185 -0.288355\n",
       "273   0.544313 -0.586185 -0.584915\n",
       "1478 -0.956048 -1.553336 -0.584915\n",
       "1250  0.135123 -0.586185 -1.474594\n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[:,20:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "humanitarian-sperm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 46)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83dd9a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 46)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d360ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = np.array(train_df)\n",
    "test_df = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8ff5748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93447873, -0.3516274 , -0.26760885, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.31999546, -0.07017537,  0.99231982, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.63361401,  0.21127666, -0.77158032, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.31999546, -0.91453145, -1.40154465, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.15043236, -1.19598348,  0.11036975, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.16318618, -1.19598348, -2.40948759, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b312464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = np.array(train_label)\n",
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b23fc815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97, 104, 103, ..., 104, 101, 102], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "perfect-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS=['mae']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-proportion",
   "metadata": {},
   "source": [
    "# 2 Moduł TALOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fbc6dd",
   "metadata": {},
   "source": [
    "Zamiast dobierać wszystkie hiperparametry na nowo, sprawdzę czy siec preferuje inne w waskim zakresie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-stick",
   "metadata": {},
   "source": [
    "## 2.1 Słownik parametrów do wypróbowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "experimental-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'first_neuron':[160], #\n",
    "     'hidden_neuron':[25],#\n",
    "     'hidden_layers':[1],  #1 must\n",
    "     'batch_size': [64], # 64\n",
    "     'optimizer': ['adam'],# do zrobienia potem\n",
    "     'kernel_initializer': ['ones'], # ones \n",
    "     'epochs': [20000], # never touch it\n",
    "     'dropout': [0],  # po dopasowaniu znowu nie bedzie potrzebne\n",
    "     'activation_layer':['selu'], # selu\n",
    "     'batc_normalization':[True,False], # do zrobienia potem\n",
    "     'last_activation': ['linear']} #never touch it\n",
    "#     \n",
    "#     \n",
    "#    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-thanksgiving",
   "metadata": {},
   "source": [
    "## 2.2 Tworzę funkcję do tworzenia instancji modelu keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "rapid-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerai_model(x_train, y_train, x_val, y_val, params):\n",
    "    print(params)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    ## initial layer\n",
    "    model.add(Dense(params['first_neuron'], input_dim=x_train.shape[1],\n",
    "                    activation='relu',\n",
    "                    kernel_initializer = params['kernel_initializer'] ))\n",
    "    if params['batc_normalization']==True:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    ## hidden layers\n",
    "    for i in range(params['hidden_layers']):\n",
    "        print (f\"adding layer {i+1}\")\n",
    "        model.add(Dense(params['hidden_neuron'], activation='relu',\n",
    "                    kernel_initializer=params['kernel_initializer']))\n",
    "        if params['batc_normalization']==True:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    \n",
    "    ## final layer\n",
    "    model.add(Dense(1, activation=params['last_activation'],\n",
    "                    kernel_initializer=params['kernel_initializer']))\n",
    "    \n",
    "    model.compile(loss='mean_absolute_error', \n",
    "                  optimizer=params['optimizer'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train, \n",
    "                        validation_data=[x_val, y_val],\n",
    "                        batch_size=params['batch_size'],\n",
    "                        epochs=params['epochs'],\n",
    "                        callbacks = [early_stopper(params['epochs'], patience=5,monitor='val_loss')] #,ta.live(),\n",
    "                        )\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-married",
   "metadata": {},
   "source": [
    "## 2.3 Przeprowadzam skan, używając parametrów i funkcji wyżej\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "muslim-picnic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'batc_normalization': True, 'batch_size': 64, 'dropout': 0, 'epochs': 20000, 'first_neuron': 160, 'hidden_layers': 1, 'hidden_neuron': 25, 'kernel_initializer': 'ones', 'last_activation': 'linear', 'optimizer': 'adam'}\n",
      "adding layer 1\n",
      "Train on 1500 samples, validate on 375 samples\n",
      "Epoch 1/20000\n",
      "1500/1500 [==============================] - 1s 992us/sample - loss: 107.3258 - val_loss: 113.0192\n",
      "Epoch 2/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 106.7483 - val_loss: 87.6245\n",
      "Epoch 3/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 106.0840 - val_loss: 90.3234\n",
      "Epoch 4/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 105.4197 - val_loss: 93.8289\n",
      "Epoch 5/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 104.6943 - val_loss: 96.5735\n",
      "Epoch 6/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 103.9506 - val_loss: 98.2862\n",
      "Epoch 7/20000\n",
      "1500/1500 [==============================] - 0s 45us/sample - loss: 103.1521 - val_loss: 99.3229\n",
      "Epoch 8/20000\n",
      "1500/1500 [==============================] - 0s 47us/sample - loss: 102.2574 - val_loss: 99.7925\n",
      "Epoch 9/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 101.3039 - val_loss: 99.8904\n",
      "Epoch 10/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 100.3358 - val_loss: 99.6508\n",
      "Epoch 11/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 99.2727 - val_loss: 99.2350\n",
      "Epoch 12/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 98.0992 - val_loss: 98.5623\n",
      "Epoch 13/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 96.8784 - val_loss: 97.8262\n",
      "Epoch 14/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 95.6001 - val_loss: 96.8937\n",
      "Epoch 15/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 94.2820 - val_loss: 95.8400\n",
      "Epoch 16/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 92.8261 - val_loss: 94.6099\n",
      "Epoch 17/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 91.3072 - val_loss: 93.2971\n",
      "Epoch 18/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 89.7707 - val_loss: 91.8012\n",
      "Epoch 19/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 88.0837 - val_loss: 90.2605\n",
      "Epoch 20/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 86.3898 - val_loss: 88.5963\n",
      "Epoch 21/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 84.6783 - val_loss: 86.8707\n",
      "Epoch 22/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 82.8368 - val_loss: 85.0396\n",
      "Epoch 23/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 80.9266 - val_loss: 83.0915\n",
      "Epoch 24/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 78.9167 - val_loss: 80.6826\n",
      "Epoch 25/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 76.9835 - val_loss: 78.3115\n",
      "Epoch 26/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 74.9493 - val_loss: 75.7771\n",
      "Epoch 27/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 72.6771 - val_loss: 73.4665\n",
      "Epoch 28/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 70.4753 - val_loss: 71.1187\n",
      "Epoch 29/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 68.2198 - val_loss: 68.7080\n",
      "Epoch 30/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 65.7921 - val_loss: 66.2520\n",
      "Epoch 31/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 63.5009 - val_loss: 63.6562\n",
      "Epoch 32/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 60.9159 - val_loss: 61.1016\n",
      "Epoch 33/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 58.3881 - val_loss: 58.4320\n",
      "Epoch 34/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 55.7248 - val_loss: 55.7124\n",
      "Epoch 35/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 53.0812 - val_loss: 52.9877\n",
      "Epoch 36/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 50.3636 - val_loss: 50.1936\n",
      "Epoch 37/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 47.5291 - val_loss: 47.1644\n",
      "Epoch 38/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 44.6579 - val_loss: 44.2007\n",
      "Epoch 39/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 41.6852 - val_loss: 41.2430\n",
      "Epoch 40/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 38.7382 - val_loss: 38.1902\n",
      "Epoch 41/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 35.6737 - val_loss: 35.0839\n",
      "Epoch 42/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 32.5629 - val_loss: 31.8797\n",
      "Epoch 43/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 29.4185 - val_loss: 28.5969\n",
      "Epoch 44/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 26.1487 - val_loss: 25.3308\n",
      "Epoch 45/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 22.9114 - val_loss: 21.9566\n",
      "Epoch 46/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 19.5725 - val_loss: 18.5463\n",
      "Epoch 47/20000\n",
      "1500/1500 [==============================] - 0s 45us/sample - loss: 16.2319 - val_loss: 15.1697\n",
      "Epoch 48/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 12.9958 - val_loss: 11.9307\n",
      "Epoch 49/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 10.0621 - val_loss: 9.2137\n",
      "Epoch 50/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 7.7674 - val_loss: 7.3599\n",
      "Epoch 51/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 6.2663 - val_loss: 6.4249\n",
      "Epoch 52/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 5.6077 - val_loss: 6.0419\n",
      "Epoch 53/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 5.3300 - val_loss: 5.8474\n",
      "Epoch 54/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 5.1633 - val_loss: 5.7070\n",
      "Epoch 55/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 5.0323 - val_loss: 5.5975\n",
      "Epoch 56/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 4.9292 - val_loss: 5.4889\n",
      "Epoch 57/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 4.8497 - val_loss: 5.3903\n",
      "Epoch 58/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 4.7335 - val_loss: 5.2883\n",
      "Epoch 59/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 4.6476 - val_loss: 5.1819\n",
      "Epoch 60/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 4.5142 - val_loss: 5.0636\n",
      "Epoch 61/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 4.4256 - val_loss: 4.9615\n",
      "Epoch 62/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 4.3075 - val_loss: 4.8301\n",
      "Epoch 63/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 4.1993 - val_loss: 4.7103\n",
      "Epoch 64/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 4.1575 - val_loss: 4.6022\n",
      "Epoch 65/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 3.9527 - val_loss: 4.4948\n",
      "Epoch 66/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 3.8951 - val_loss: 4.3795\n",
      "Epoch 67/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 3.8104 - val_loss: 4.2628\n",
      "Epoch 68/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 3.7134 - val_loss: 4.1760\n",
      "Epoch 69/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 3.6084 - val_loss: 4.0906\n",
      "Epoch 70/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 3.5252 - val_loss: 4.0094\n",
      "Epoch 71/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 3.4490 - val_loss: 3.8865\n",
      "Epoch 72/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 3.3472 - val_loss: 3.7798\n",
      "Epoch 73/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 3.3003 - val_loss: 3.7441\n",
      "Epoch 74/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 3.2203 - val_loss: 3.5970\n",
      "Epoch 75/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 3.1587 - val_loss: 3.5273\n",
      "Epoch 76/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 3.1179 - val_loss: 3.4832\n",
      "Epoch 77/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 3.0261 - val_loss: 3.4531\n",
      "Epoch 78/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 2.9215 - val_loss: 3.3130\n",
      "Epoch 79/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 2.9190 - val_loss: 3.3316\n",
      "Epoch 80/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 2.8316 - val_loss: 3.2328\n",
      "Epoch 81/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 2.8029 - val_loss: 3.1808\n",
      "Epoch 82/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 2.6805 - val_loss: 3.0371\n",
      "Epoch 83/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 2.5993 - val_loss: 2.9603\n",
      "Epoch 84/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 2.5299 - val_loss: 2.7991\n",
      "Epoch 85/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 2.4874 - val_loss: 2.7334\n",
      "Epoch 86/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 2.3837 - val_loss: 2.6009\n",
      "Epoch 87/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 2.2608 - val_loss: 2.6388\n",
      "Epoch 88/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 2.2828 - val_loss: 2.5188\n",
      "Epoch 89/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 2.0909 - val_loss: 2.4312\n",
      "Epoch 90/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 2.0332 - val_loss: 2.2882\n",
      "Epoch 91/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 2.0670 - val_loss: 2.3309\n",
      "Epoch 92/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.9768 - val_loss: 2.2510\n",
      "Epoch 93/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 2.0373 - val_loss: 2.1926\n",
      "Epoch 94/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.8856 - val_loss: 2.0680\n",
      "Epoch 95/20000\n",
      "1500/1500 [==============================] - 0s 55us/sample - loss: 1.8778 - val_loss: 2.0104\n",
      "Epoch 96/20000\n",
      "1500/1500 [==============================] - 0s 53us/sample - loss: 1.8782 - val_loss: 1.9436\n",
      "Epoch 97/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.7846 - val_loss: 1.8391\n",
      "Epoch 98/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.8236 - val_loss: 2.0373\n",
      "Epoch 99/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.8661 - val_loss: 1.9012\n",
      "Epoch 100/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.7401 - val_loss: 1.8772\n",
      "Epoch 101/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.7271 - val_loss: 1.8267\n",
      "Epoch 102/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.7607 - val_loss: 1.7059\n",
      "Epoch 103/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.6772 - val_loss: 1.7450\n",
      "Epoch 104/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.6887 - val_loss: 1.7025\n",
      "Epoch 105/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.7713 - val_loss: 1.7532\n",
      "Epoch 106/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.7275 - val_loss: 1.7537\n",
      "Epoch 107/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.7203 - val_loss: 1.6679\n",
      "Epoch 108/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.6718 - val_loss: 1.6239\n",
      "Epoch 109/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.7420 - val_loss: 1.6896\n",
      "Epoch 110/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.6218 - val_loss: 1.6186\n",
      "Epoch 111/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.6885 - val_loss: 1.5413\n",
      "Epoch 112/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.7725 - val_loss: 1.5666\n",
      "Epoch 113/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.6043 - val_loss: 1.6106\n",
      "Epoch 114/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.6715 - val_loss: 1.6497\n",
      "Epoch 115/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.6196 - val_loss: 1.5944\n",
      "Epoch 116/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5718 - val_loss: 1.5981\n",
      "Epoch 117/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5601 - val_loss: 1.5535\n",
      "Epoch 118/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5274 - val_loss: 1.5430\n",
      "Epoch 119/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5752 - val_loss: 1.5449\n",
      "Epoch 120/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6525 - val_loss: 1.5349\n",
      "Epoch 121/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6945 - val_loss: 1.5444\n",
      "Epoch 122/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5534 - val_loss: 1.4959\n",
      "Epoch 123/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.5857 - val_loss: 1.5121\n",
      "Epoch 124/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.5579 - val_loss: 1.4914\n",
      "Epoch 125/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.5107 - val_loss: 1.4611\n",
      "Epoch 126/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.6424 - val_loss: 1.6029\n",
      "Epoch 127/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.5345 - val_loss: 1.6260\n",
      "Epoch 128/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.4830 - val_loss: 1.5821\n",
      "Epoch 129/20000\n",
      "1500/1500 [==============================] - 0s 44us/sample - loss: 1.6056 - val_loss: 1.6431\n",
      "Epoch 130/20000\n",
      "1500/1500 [==============================] - 0s 45us/sample - loss: 1.5608 - val_loss: 1.5921\n",
      "Epoch 131/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.5295 - val_loss: 1.5269\n",
      "Epoch 132/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.6101 - val_loss: 1.5573\n",
      "Epoch 133/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4959 - val_loss: 1.8312\n",
      "Epoch 134/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5433 - val_loss: 1.7814\n",
      "Epoch 135/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4554 - val_loss: 1.6912\n",
      "Epoch 136/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5330 - val_loss: 1.6374\n",
      "Epoch 137/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5570 - val_loss: 1.5504\n",
      "Epoch 138/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4303 - val_loss: 1.5527\n",
      "Epoch 139/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5848 - val_loss: 1.5382\n",
      "Epoch 140/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4807 - val_loss: 1.5436\n",
      "Epoch 141/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4760 - val_loss: 1.4698\n",
      "Epoch 142/20000\n",
      "1500/1500 [==============================] - 0s 44us/sample - loss: 1.5162 - val_loss: 1.5364\n",
      "Epoch 143/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4719 - val_loss: 1.4308\n",
      "Epoch 144/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5706 - val_loss: 1.4940\n",
      "Epoch 145/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5792 - val_loss: 1.4337\n",
      "Epoch 146/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4688 - val_loss: 1.4305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5211 - val_loss: 1.4141\n",
      "Epoch 148/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5176 - val_loss: 1.4583\n",
      "Epoch 149/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4950 - val_loss: 1.4417\n",
      "Epoch 150/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4831 - val_loss: 1.4709\n",
      "Epoch 151/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5556 - val_loss: 1.4366\n",
      "Epoch 152/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5182 - val_loss: 1.4325\n",
      "Epoch 153/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5383 - val_loss: 1.4242\n",
      "Epoch 154/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5480 - val_loss: 1.4594\n",
      "Epoch 155/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5825 - val_loss: 1.4695\n",
      "Epoch 156/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.6656 - val_loss: 1.4203\n",
      "Epoch 157/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5485 - val_loss: 1.4306\n",
      "Epoch 158/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5634 - val_loss: 1.4474\n",
      "Epoch 159/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4681 - val_loss: 1.4191\n",
      "Epoch 160/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4974 - val_loss: 1.4600\n",
      "Epoch 161/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4655 - val_loss: 1.4184\n",
      "Epoch 162/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.6087 - val_loss: 1.4603\n",
      "Epoch 163/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5879 - val_loss: 1.4358\n",
      "Epoch 164/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5199 - val_loss: 1.4328\n",
      "Epoch 165/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4160 - val_loss: 1.4355\n",
      "Epoch 166/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4963 - val_loss: 1.4500\n",
      "Epoch 167/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5862 - val_loss: 1.4250\n",
      "Epoch 168/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4935 - val_loss: 1.4269\n",
      "Epoch 169/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5933 - val_loss: 1.4325\n",
      "Epoch 170/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4878 - val_loss: 1.4528\n",
      "Epoch 171/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4778 - val_loss: 1.4511\n",
      "Epoch 172/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5197 - val_loss: 1.4083\n",
      "Epoch 173/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5171 - val_loss: 1.4276\n",
      "Epoch 174/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5228 - val_loss: 1.4322\n",
      "Epoch 175/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5982 - val_loss: 1.4477\n",
      "Epoch 176/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4476 - val_loss: 1.4315\n",
      "Epoch 177/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5329 - val_loss: 1.4216\n",
      "Epoch 178/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5179 - val_loss: 1.3982\n",
      "Epoch 179/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5016 - val_loss: 1.4291\n",
      "Epoch 180/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4112 - val_loss: 1.4245\n",
      "Epoch 181/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5377 - val_loss: 1.4233\n",
      "Epoch 182/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4606 - val_loss: 1.4155\n",
      "Epoch 183/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.5148 - val_loss: 1.4370\n",
      "Epoch 184/20000\n",
      "1500/1500 [==============================] - 0s 45us/sample - loss: 1.6025 - val_loss: 1.4450\n",
      "Epoch 185/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5404 - val_loss: 1.4163\n",
      "Epoch 186/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5151 - val_loss: 1.4353\n",
      "Epoch 187/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4249 - val_loss: 1.4398\n",
      "Epoch 188/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5445 - val_loss: 1.4161\n",
      "Epoch 189/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5426 - val_loss: 1.4439\n",
      "Epoch 190/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5475 - val_loss: 1.4139\n",
      "Epoch 191/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4647 - val_loss: 1.4148\n",
      "Epoch 192/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5270 - val_loss: 1.4289\n",
      "Epoch 193/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4980 - val_loss: 1.4186\n",
      "Epoch 194/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.5685 - val_loss: 1.4365\n",
      "Epoch 195/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4999 - val_loss: 1.4196\n",
      "Epoch 196/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4069 - val_loss: 1.4029\n",
      "Epoch 197/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5215 - val_loss: 1.4169\n",
      "Epoch 198/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4778 - val_loss: 1.4010\n",
      "Epoch 199/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4743 - val_loss: 1.4501\n",
      "Epoch 200/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3975 - val_loss: 1.4290\n",
      "Epoch 201/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4949 - val_loss: 1.4441\n",
      "Epoch 202/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5377 - val_loss: 1.5407\n",
      "Epoch 203/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4935 - val_loss: 1.4970\n",
      "Epoch 204/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.6002 - val_loss: 1.5224\n",
      "Epoch 205/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5777 - val_loss: 1.4404\n",
      "Epoch 206/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5218 - val_loss: 1.4967\n",
      "Epoch 207/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5223 - val_loss: 1.4573\n",
      "Epoch 208/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5082 - val_loss: 1.4343\n",
      "Epoch 209/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3695 - val_loss: 1.4328\n",
      "Epoch 210/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.5084 - val_loss: 1.4461\n",
      "Epoch 211/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4921 - val_loss: 1.4261\n",
      "Epoch 212/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5327 - val_loss: 1.4334\n",
      "Epoch 213/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6068 - val_loss: 1.4334\n",
      "Epoch 214/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5268 - val_loss: 1.4589\n",
      "Epoch 215/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5592 - val_loss: 1.4132\n",
      "Epoch 216/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5737 - val_loss: 1.4643\n",
      "Epoch 217/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5362 - val_loss: 1.4044\n",
      "Epoch 218/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4876 - val_loss: 1.4488\n",
      "Epoch 219/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4419 - val_loss: 1.4328\n",
      "Epoch 220/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5557 - val_loss: 1.4128\n",
      "Epoch 221/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4842 - val_loss: 1.4224\n",
      "Epoch 222/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5139 - val_loss: 1.3961\n",
      "Epoch 223/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5276 - val_loss: 1.4423\n",
      "Epoch 224/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5746 - val_loss: 1.3966\n",
      "Epoch 225/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5827 - val_loss: 1.4348\n",
      "Epoch 226/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4853 - val_loss: 1.4010\n",
      "Epoch 227/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5998 - val_loss: 1.4288\n",
      "Epoch 228/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4014 - val_loss: 1.4017\n",
      "Epoch 229/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5579 - val_loss: 1.4110\n",
      "Epoch 230/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4125 - val_loss: 1.4024\n",
      "Epoch 231/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4465 - val_loss: 1.3835\n",
      "Epoch 232/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5013 - val_loss: 1.4090\n",
      "Epoch 233/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6021 - val_loss: 1.4257\n",
      "Epoch 234/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4423 - val_loss: 1.3904\n",
      "Epoch 235/20000\n",
      "1500/1500 [==============================] - 0s 44us/sample - loss: 1.4154 - val_loss: 1.4366\n",
      "Epoch 236/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4918 - val_loss: 1.4251\n",
      "Epoch 237/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5068 - val_loss: 1.4111\n",
      "Epoch 238/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4271 - val_loss: 1.4409\n",
      "Epoch 239/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4807 - val_loss: 1.3910\n",
      "Epoch 240/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5340 - val_loss: 1.4946\n",
      "Epoch 241/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4942 - val_loss: 1.5198\n",
      "Epoch 242/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4815 - val_loss: 1.4776\n",
      "Epoch 243/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4565 - val_loss: 1.4495\n",
      "Epoch 244/20000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.881 - 0s 45us/sample - loss: 1.4667 - val_loss: 1.4511\n",
      "Epoch 245/20000\n",
      "1500/1500 [==============================] - 0s 46us/sample - loss: 1.6019 - val_loss: 1.4762\n",
      "Epoch 246/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4696 - val_loss: 1.4252\n",
      "Epoch 247/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4959 - val_loss: 1.4476\n",
      "Epoch 248/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5113 - val_loss: 1.3965\n",
      "Epoch 249/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5101 - val_loss: 1.4325\n",
      "Epoch 250/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4318 - val_loss: 1.4185\n",
      "Epoch 251/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4312 - val_loss: 1.4254\n",
      "Epoch 252/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4474 - val_loss: 1.4067\n",
      "Epoch 253/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4120 - val_loss: 1.4373\n",
      "Epoch 254/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5026 - val_loss: 1.4300\n",
      "Epoch 255/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5473 - val_loss: 1.3791\n",
      "Epoch 256/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4866 - val_loss: 1.4062\n",
      "Epoch 257/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5040 - val_loss: 1.4004\n",
      "Epoch 258/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5421 - val_loss: 1.4009\n",
      "Epoch 259/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5543 - val_loss: 1.4262\n",
      "Epoch 260/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5114 - val_loss: 1.3751\n",
      "Epoch 261/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4575 - val_loss: 1.3987\n",
      "Epoch 262/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.6164 - val_loss: 1.4016\n",
      "Epoch 263/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4645 - val_loss: 1.3780\n",
      "Epoch 264/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5369 - val_loss: 1.3820\n",
      "Epoch 265/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5955 - val_loss: 1.4377\n",
      "Epoch 266/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5000 - val_loss: 1.3749\n",
      "Epoch 267/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4810 - val_loss: 1.4064\n",
      "Epoch 268/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5538 - val_loss: 1.4023\n",
      "Epoch 269/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4327 - val_loss: 1.4381\n",
      "Epoch 270/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5607 - val_loss: 1.3683\n",
      "Epoch 271/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4501 - val_loss: 1.3759\n",
      "Epoch 272/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.6447 - val_loss: 1.4241\n",
      "Epoch 273/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3977 - val_loss: 1.3761\n",
      "Epoch 274/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4676 - val_loss: 1.4115\n",
      "Epoch 275/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5853 - val_loss: 1.4159\n",
      "Epoch 276/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4964 - val_loss: 1.4358\n",
      "Epoch 277/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4951 - val_loss: 1.3597\n",
      "Epoch 278/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5199 - val_loss: 1.4111\n",
      "Epoch 279/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3992 - val_loss: 1.3936\n",
      "Epoch 280/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5797 - val_loss: 1.3737\n",
      "Epoch 281/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5708 - val_loss: 1.3963\n",
      "Epoch 282/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5143 - val_loss: 1.4186\n",
      "Epoch 283/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6105 - val_loss: 1.4109\n",
      "Epoch 284/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4947 - val_loss: 1.3735\n",
      "Epoch 285/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4734 - val_loss: 1.4020\n",
      "Epoch 286/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.4008 - val_loss: 1.3755\n",
      "Epoch 287/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4260 - val_loss: 1.3948\n",
      "Epoch 288/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4403 - val_loss: 1.4329\n",
      "Epoch 289/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4716 - val_loss: 1.7630\n",
      "Epoch 290/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4675 - val_loss: 1.7554\n",
      "Epoch 291/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5143 - val_loss: 1.7061\n",
      "Epoch 292/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4506 - val_loss: 1.5761\n",
      "Epoch 293/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4170 - val_loss: 1.5307\n",
      "Epoch 294/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4666 - val_loss: 1.4842\n",
      "Epoch 295/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4351 - val_loss: 1.4697\n",
      "Epoch 296/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4613 - val_loss: 1.4217\n",
      "Epoch 297/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5073 - val_loss: 1.4279\n",
      "Epoch 298/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4759 - val_loss: 1.3979\n",
      "Epoch 299/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4462 - val_loss: 1.4125\n",
      "Epoch 300/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5716 - val_loss: 1.4466\n",
      "Epoch 301/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5314 - val_loss: 1.3837\n",
      "Epoch 302/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4433 - val_loss: 1.4236\n",
      "Epoch 303/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5218 - val_loss: 1.3807\n",
      "Epoch 304/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5281 - val_loss: 1.4190\n",
      "Epoch 305/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5039 - val_loss: 1.3659\n",
      "Epoch 306/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5316 - val_loss: 1.3986\n",
      "Epoch 307/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4494 - val_loss: 1.4120\n",
      "Epoch 308/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5132 - val_loss: 1.4029\n",
      "Epoch 309/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5564 - val_loss: 1.3680\n",
      "Epoch 310/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.6141 - val_loss: 1.4244\n",
      "Epoch 311/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4801 - val_loss: 1.3557\n",
      "Epoch 312/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4191 - val_loss: 1.3936\n",
      "Epoch 313/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3949 - val_loss: 1.3782\n",
      "Epoch 314/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4057 - val_loss: 1.3919\n",
      "Epoch 315/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4310 - val_loss: 1.3772\n",
      "Epoch 316/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4686 - val_loss: 1.4129\n",
      "Epoch 317/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3861 - val_loss: 1.3916\n",
      "Epoch 318/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4323 - val_loss: 1.3706\n",
      "Epoch 319/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4408 - val_loss: 1.3929\n",
      "Epoch 320/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5732 - val_loss: 1.3953\n",
      "Epoch 321/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4818 - val_loss: 1.3950\n",
      "Epoch 322/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4504 - val_loss: 1.4001\n",
      "Epoch 323/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6011 - val_loss: 1.3774\n",
      "Epoch 324/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4367 - val_loss: 1.4145\n",
      "Epoch 325/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5076 - val_loss: 1.3870\n",
      "Epoch 326/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5083 - val_loss: 1.3754\n",
      "Epoch 327/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4568 - val_loss: 1.3678\n",
      "Epoch 328/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5072 - val_loss: 1.3878\n",
      "Epoch 329/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4912 - val_loss: 1.3675\n",
      "Epoch 330/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5966 - val_loss: 1.4273\n",
      "Epoch 331/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4593 - val_loss: 1.3390\n",
      "Epoch 332/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4900 - val_loss: 1.4239\n",
      "Epoch 333/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5613 - val_loss: 1.3724\n",
      "Epoch 334/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3850 - val_loss: 1.3697\n",
      "Epoch 335/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5253 - val_loss: 1.4007\n",
      "Epoch 336/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4555 - val_loss: 1.3622\n",
      "Epoch 337/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5306 - val_loss: 1.3681\n",
      "Epoch 338/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4642 - val_loss: 1.3505\n",
      "Epoch 339/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5249 - val_loss: 1.4058\n",
      "Epoch 340/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4115 - val_loss: 1.3863\n",
      "Epoch 341/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4989 - val_loss: 1.3690\n",
      "Epoch 342/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4948 - val_loss: 1.4227\n",
      "Epoch 343/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5794 - val_loss: 1.3858\n",
      "Epoch 344/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4278 - val_loss: 1.3695\n",
      "Epoch 345/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5274 - val_loss: 1.3831\n",
      "Epoch 346/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3849 - val_loss: 1.3706\n",
      "Epoch 347/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5463 - val_loss: 1.3688\n",
      "Epoch 348/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5763 - val_loss: 1.4201\n",
      "Epoch 349/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4027 - val_loss: 1.3720\n",
      "Epoch 350/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5948 - val_loss: 1.3545\n",
      "Epoch 351/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4871 - val_loss: 1.3857\n",
      "Epoch 352/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4942 - val_loss: 1.4002\n",
      "Epoch 353/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5048 - val_loss: 1.4003\n",
      "Epoch 354/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5330 - val_loss: 1.4057\n",
      "Epoch 355/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3993 - val_loss: 1.3880\n",
      "Epoch 356/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4321 - val_loss: 1.3908\n",
      "Epoch 357/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5283 - val_loss: 1.4006\n",
      "Epoch 358/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4366 - val_loss: 1.4182\n",
      "Epoch 359/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4659 - val_loss: 1.4023\n",
      "Epoch 360/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5132 - val_loss: 1.3996\n",
      "Epoch 361/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4959 - val_loss: 1.3892\n",
      "Epoch 362/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5520 - val_loss: 1.4297\n",
      "Epoch 363/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4495 - val_loss: 1.4147\n",
      "Epoch 364/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5043 - val_loss: 1.3956\n",
      "Epoch 365/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5908 - val_loss: 1.4294\n",
      "Epoch 366/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4450 - val_loss: 1.4044\n",
      "Epoch 367/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5841 - val_loss: 1.3904\n",
      "Epoch 368/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5350 - val_loss: 1.4176\n",
      "Epoch 369/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4312 - val_loss: 1.3785\n",
      "Epoch 370/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5158 - val_loss: 1.3807\n",
      "Epoch 371/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5388 - val_loss: 1.3965\n",
      "Epoch 372/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5245 - val_loss: 1.4122\n",
      "Epoch 373/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4826 - val_loss: 1.3979\n",
      "Epoch 374/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5431 - val_loss: 1.4026\n",
      "Epoch 375/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3822 - val_loss: 1.3820\n",
      "Epoch 376/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4831 - val_loss: 1.3826\n",
      "Epoch 377/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4828 - val_loss: 1.4060\n",
      "Epoch 378/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5190 - val_loss: 1.3868\n",
      "Epoch 379/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4461 - val_loss: 1.3807\n",
      "Epoch 380/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5311 - val_loss: 1.3860\n",
      "Epoch 381/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4469 - val_loss: 1.3936\n",
      "Epoch 382/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4820 - val_loss: 1.3788\n",
      "Epoch 383/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5706 - val_loss: 1.3738\n",
      "Epoch 384/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3805 - val_loss: 1.4339\n",
      "Epoch 385/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4016 - val_loss: 1.4154\n",
      "Epoch 386/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3639 - val_loss: 1.3861\n",
      "Epoch 387/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5058 - val_loss: 1.3675\n",
      "Epoch 388/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4707 - val_loss: 1.4179\n",
      "Epoch 389/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5010 - val_loss: 1.3955\n",
      "Epoch 390/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5149 - val_loss: 1.3773\n",
      "Epoch 391/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5507 - val_loss: 1.3825\n",
      "Epoch 392/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5706 - val_loss: 1.3929\n",
      "Epoch 393/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4052 - val_loss: 1.3988\n",
      "Epoch 394/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5814 - val_loss: 1.3684\n",
      "Epoch 395/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4033 - val_loss: 1.3644\n",
      "Epoch 396/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4955 - val_loss: 1.3967\n",
      "Epoch 397/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4985 - val_loss: 1.3988\n",
      "Epoch 398/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5080 - val_loss: 1.3999\n",
      "Epoch 399/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4456 - val_loss: 1.3822\n",
      "Epoch 400/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5391 - val_loss: 1.4037\n",
      "Epoch 401/20000\n",
      "1500/1500 [==============================] - 0s 48us/sample - loss: 1.4809 - val_loss: 1.4106\n",
      "Epoch 402/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4780 - val_loss: 1.4240\n",
      "Epoch 403/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4319 - val_loss: 1.3770\n",
      "Epoch 404/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6549 - val_loss: 1.3814\n",
      "Epoch 405/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4754 - val_loss: 1.3584\n",
      "Epoch 406/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3922 - val_loss: 1.3776\n",
      "Epoch 407/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4977 - val_loss: 1.3544\n",
      "Epoch 408/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.6396 - val_loss: 1.4001\n",
      "Epoch 409/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4721 - val_loss: 1.3719\n",
      "Epoch 410/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4799 - val_loss: 1.3748\n",
      "Epoch 411/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5375 - val_loss: 1.3846\n",
      "Epoch 412/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5149 - val_loss: 1.3986\n",
      "Epoch 413/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4274 - val_loss: 1.3534\n",
      "Epoch 414/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4692 - val_loss: 1.4085\n",
      "Epoch 415/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5484 - val_loss: 1.3647\n",
      "Epoch 416/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4444 - val_loss: 1.4050\n",
      "Epoch 417/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4555 - val_loss: 1.3351\n",
      "Epoch 418/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4007 - val_loss: 1.3627\n",
      "Epoch 419/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4820 - val_loss: 1.3818\n",
      "Epoch 420/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4370 - val_loss: 1.3738\n",
      "Epoch 421/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4392 - val_loss: 1.4193\n",
      "Epoch 422/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5149 - val_loss: 1.3794\n",
      "Epoch 423/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4222 - val_loss: 1.3981\n",
      "Epoch 424/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5143 - val_loss: 1.3903\n",
      "Epoch 425/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.6361 - val_loss: 1.3814\n",
      "Epoch 426/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4044 - val_loss: 1.3859\n",
      "Epoch 427/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4399 - val_loss: 1.3857\n",
      "Epoch 428/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4055 - val_loss: 1.4005\n",
      "Epoch 429/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4599 - val_loss: 1.3655\n",
      "Epoch 430/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5833 - val_loss: 1.4118\n",
      "Epoch 431/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4133 - val_loss: 1.3846\n",
      "Epoch 432/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5043 - val_loss: 1.3665\n",
      "Epoch 433/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4929 - val_loss: 1.3820\n",
      "Epoch 434/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5576 - val_loss: 1.4056\n",
      "Epoch 435/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4680 - val_loss: 1.3912\n",
      "Epoch 436/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4771 - val_loss: 1.3811\n",
      "Epoch 437/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5146 - val_loss: 1.3901\n",
      "Epoch 438/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5136 - val_loss: 1.3951\n",
      "Epoch 439/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4980 - val_loss: 1.3921\n",
      "Epoch 440/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4342 - val_loss: 1.3479\n",
      "Epoch 441/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4521 - val_loss: 1.3945\n",
      "Epoch 442/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5678 - val_loss: 1.3671\n",
      "Epoch 443/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4021 - val_loss: 1.3899\n",
      "Epoch 444/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5400 - val_loss: 1.3613\n",
      "Epoch 445/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4674 - val_loss: 1.3893\n",
      "Epoch 446/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4057 - val_loss: 1.3562\n",
      "Epoch 447/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5195 - val_loss: 1.3753\n",
      "Epoch 448/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4349 - val_loss: 1.3772\n",
      "Epoch 449/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4826 - val_loss: 1.3644\n",
      "Epoch 450/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4136 - val_loss: 1.3626\n",
      "Epoch 451/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5378 - val_loss: 1.3637\n",
      "Epoch 452/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5500 - val_loss: 1.3661\n",
      "Epoch 453/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5412 - val_loss: 1.3447\n",
      "Epoch 454/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4599 - val_loss: 1.3619\n",
      "Epoch 455/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4089 - val_loss: 1.3679\n",
      "Epoch 456/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5296 - val_loss: 1.3581\n",
      "Epoch 457/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4828 - val_loss: 1.3578\n",
      "Epoch 458/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5403 - val_loss: 1.4045\n",
      "Epoch 459/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5845 - val_loss: 1.3834\n",
      "Epoch 460/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5697 - val_loss: 1.3784\n",
      "Epoch 461/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5390 - val_loss: 1.3987\n",
      "Epoch 462/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5269 - val_loss: 1.3728\n",
      "Epoch 463/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4182 - val_loss: 1.3519\n",
      "Epoch 464/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4974 - val_loss: 1.3779\n",
      "Epoch 465/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4784 - val_loss: 1.3748\n",
      "Epoch 466/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4452 - val_loss: 1.3948\n",
      "Epoch 467/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5169 - val_loss: 1.3859\n",
      "Epoch 468/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4570 - val_loss: 1.3535\n",
      "Epoch 469/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4417 - val_loss: 1.4177\n",
      "Epoch 470/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5345 - val_loss: 1.3828\n",
      "Epoch 471/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5615 - val_loss: 1.3804\n",
      "Epoch 472/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.7203 - val_loss: 1.4492\n",
      "Epoch 473/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.5293 - val_loss: 1.3545\n",
      "Epoch 474/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4503 - val_loss: 1.3844\n",
      "Epoch 475/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4426 - val_loss: 1.3583\n",
      "Epoch 476/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4255 - val_loss: 1.3566\n",
      "Epoch 477/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4695 - val_loss: 1.3839\n",
      "Epoch 478/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4564 - val_loss: 1.3870\n",
      "Epoch 479/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4372 - val_loss: 1.3807\n",
      "Epoch 480/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5127 - val_loss: 1.3760\n",
      "Epoch 481/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4626 - val_loss: 1.3652\n",
      "Epoch 482/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4957 - val_loss: 1.3723\n",
      "Epoch 483/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4868 - val_loss: 1.3800\n",
      "Epoch 484/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4250 - val_loss: 1.3855\n",
      "Epoch 485/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5315 - val_loss: 1.3913\n",
      "Epoch 486/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4649 - val_loss: 1.3521\n",
      "Epoch 487/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4841 - val_loss: 1.3562\n",
      "Epoch 488/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5289 - val_loss: 1.3938\n",
      "Epoch 489/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5301 - val_loss: 1.3589\n",
      "Epoch 490/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4810 - val_loss: 1.3625\n",
      "Epoch 491/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4827 - val_loss: 1.3593\n",
      "Epoch 492/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4736 - val_loss: 1.3551\n",
      "Epoch 493/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4532 - val_loss: 1.3833\n",
      "Epoch 494/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5063 - val_loss: 1.3613\n",
      "Epoch 495/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4942 - val_loss: 1.3840\n",
      "Epoch 496/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3785 - val_loss: 1.3586\n",
      "Epoch 497/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3672 - val_loss: 1.3898\n",
      "Epoch 498/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4545 - val_loss: 1.3386\n",
      "Epoch 499/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4299 - val_loss: 1.3943\n",
      "Epoch 500/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.5862 - val_loss: 1.3837\n",
      "Epoch 501/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4587 - val_loss: 1.3619\n",
      "Epoch 502/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4829 - val_loss: 1.3940\n",
      "Epoch 503/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5176 - val_loss: 1.3606\n",
      "Epoch 504/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4592 - val_loss: 1.3908\n",
      "Epoch 505/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4956 - val_loss: 1.3654\n",
      "Epoch 506/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4919 - val_loss: 1.3899\n",
      "Epoch 507/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.5744 - val_loss: 1.3651\n",
      "Epoch 508/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.5177 - val_loss: 1.3664\n",
      "Epoch 509/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4400 - val_loss: 1.3759\n",
      "Epoch 510/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4839 - val_loss: 1.3664\n",
      "Epoch 511/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4357 - val_loss: 1.3697\n",
      "Epoch 512/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3647 - val_loss: 1.3842\n",
      "Epoch 513/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5037 - val_loss: 1.3695\n",
      "Epoch 514/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5155 - val_loss: 1.3623\n",
      "Epoch 515/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5552 - val_loss: 1.3731\n",
      "Epoch 516/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5024 - val_loss: 1.3725\n",
      "Epoch 517/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5244 - val_loss: 1.3638\n",
      "Epoch 518/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5566 - val_loss: 1.4158\n",
      "Epoch 519/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4657 - val_loss: 1.3618\n",
      "Epoch 520/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4604 - val_loss: 1.3633\n",
      "Epoch 521/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.5193 - val_loss: 1.3546\n",
      "Epoch 522/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4213 - val_loss: 1.3523\n",
      "Epoch 523/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4212 - val_loss: 1.3788\n",
      "Epoch 524/20000\n",
      "1500/1500 [==============================] - 0s 50us/sample - loss: 1.5176 - val_loss: 1.3690\n",
      "Epoch 525/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4436 - val_loss: 1.3681\n",
      "Epoch 526/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.3850 - val_loss: 1.3413\n",
      "Epoch 527/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.5026 - val_loss: 1.3614\n",
      "Epoch 528/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4805 - val_loss: 1.3505\n",
      "Epoch 529/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4726 - val_loss: 1.3806\n",
      "Epoch 530/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.5269 - val_loss: 1.3674\n",
      "Epoch 531/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.5376 - val_loss: 1.3549\n",
      "Epoch 532/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5314 - val_loss: 1.3611\n",
      "Epoch 533/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4565 - val_loss: 1.3730\n",
      "Epoch 534/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5083 - val_loss: 1.3460\n",
      "Epoch 535/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4804 - val_loss: 1.3487\n",
      "Epoch 536/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4780 - val_loss: 1.4023\n",
      "Epoch 537/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4910 - val_loss: 1.3807\n",
      "Epoch 538/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4418 - val_loss: 1.3755\n",
      "Epoch 539/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4747 - val_loss: 1.3474\n",
      "Epoch 540/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4410 - val_loss: 1.3742\n",
      "Epoch 541/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3602 - val_loss: 1.3575\n",
      "Epoch 542/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4846 - val_loss: 1.3565\n",
      "Epoch 543/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.6266 - val_loss: 1.3719\n",
      "Epoch 544/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5323 - val_loss: 1.3475\n",
      "Epoch 545/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4516 - val_loss: 1.3917\n",
      "Epoch 546/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5821 - val_loss: 1.4095\n",
      "Epoch 547/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6185 - val_loss: 1.3784\n",
      "Epoch 548/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4242 - val_loss: 1.3538\n",
      "Epoch 549/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5276 - val_loss: 1.3875\n",
      "Epoch 550/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4460 - val_loss: 1.3411\n",
      "Epoch 551/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4291 - val_loss: 1.3791\n",
      "Epoch 552/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3853 - val_loss: 1.3551\n",
      "Epoch 553/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.6565 - val_loss: 1.3377\n",
      "Epoch 554/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5318 - val_loss: 1.4031\n",
      "Epoch 555/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4300 - val_loss: 1.3460\n",
      "Epoch 556/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4078 - val_loss: 1.3620\n",
      "Epoch 557/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5469 - val_loss: 1.4140\n",
      "Epoch 558/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5079 - val_loss: 1.3908\n",
      "Epoch 559/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5055 - val_loss: 1.3528\n",
      "Epoch 560/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5600 - val_loss: 1.3759\n",
      "Epoch 561/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5314 - val_loss: 1.3373\n",
      "Epoch 562/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4581 - val_loss: 1.3532\n",
      "Epoch 563/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5008 - val_loss: 1.3633\n",
      "Epoch 564/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5787 - val_loss: 1.4002\n",
      "Epoch 565/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5146 - val_loss: 1.3628\n",
      "Epoch 566/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4142 - val_loss: 1.3581\n",
      "Epoch 567/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4787 - val_loss: 1.3669\n",
      "Epoch 568/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4662 - val_loss: 1.3574\n",
      "Epoch 569/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4703 - val_loss: 1.3643\n",
      "Epoch 570/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4205 - val_loss: 1.3515\n",
      "Epoch 571/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4491 - val_loss: 1.3733\n",
      "Epoch 572/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4215 - val_loss: 1.3649\n",
      "Epoch 573/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5107 - val_loss: 1.3698\n",
      "Epoch 574/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5317 - val_loss: 1.4053\n",
      "Epoch 575/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3852 - val_loss: 1.3646\n",
      "Epoch 576/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3907 - val_loss: 1.3594\n",
      "Epoch 577/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.4574 - val_loss: 1.3519\n",
      "Epoch 578/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5567 - val_loss: 1.4575\n",
      "Epoch 579/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5061 - val_loss: 1.3429\n",
      "Epoch 580/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4117 - val_loss: 1.3560\n",
      "Epoch 581/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5008 - val_loss: 1.4178\n",
      "Epoch 582/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4561 - val_loss: 1.3273\n",
      "Epoch 583/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4845 - val_loss: 1.3351\n",
      "Epoch 584/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4079 - val_loss: 1.3643\n",
      "Epoch 585/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4820 - val_loss: 1.3455\n",
      "Epoch 586/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5563 - val_loss: 1.3821\n",
      "Epoch 587/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4095 - val_loss: 1.3811\n",
      "Epoch 588/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5274 - val_loss: 1.3563\n",
      "Epoch 589/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3810 - val_loss: 1.3516\n",
      "Epoch 590/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5446 - val_loss: 1.4010\n",
      "Epoch 591/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4546 - val_loss: 1.3641\n",
      "Epoch 592/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5467 - val_loss: 1.3672\n",
      "Epoch 593/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5150 - val_loss: 1.3621\n",
      "Epoch 594/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4468 - val_loss: 1.3703\n",
      "Epoch 595/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4888 - val_loss: 1.3639\n",
      "Epoch 596/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5190 - val_loss: 1.3449\n",
      "Epoch 597/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4524 - val_loss: 1.3661\n",
      "Epoch 598/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5376 - val_loss: 1.3578\n",
      "Epoch 599/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4548 - val_loss: 1.3697\n",
      "Epoch 600/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4789 - val_loss: 1.3766\n",
      "Epoch 601/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4553 - val_loss: 1.3785\n",
      "Epoch 602/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5469 - val_loss: 1.3220\n",
      "Epoch 603/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3771 - val_loss: 1.3628\n",
      "Epoch 604/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4504 - val_loss: 1.3403\n",
      "Epoch 605/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4062 - val_loss: 1.3594\n",
      "Epoch 606/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3735 - val_loss: 1.3482\n",
      "Epoch 607/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5125 - val_loss: 1.3675\n",
      "Epoch 608/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3947 - val_loss: 1.3467\n",
      "Epoch 609/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5187 - val_loss: 1.3433\n",
      "Epoch 610/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5517 - val_loss: 1.3556\n",
      "Epoch 611/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.5072 - val_loss: 1.3652\n",
      "Epoch 612/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4406 - val_loss: 1.3493\n",
      "Epoch 613/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5005 - val_loss: 1.3579\n",
      "Epoch 614/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5160 - val_loss: 1.3186\n",
      "Epoch 615/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.4523 - val_loss: 1.3395\n",
      "Epoch 616/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3943 - val_loss: 1.3427\n",
      "Epoch 617/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4460 - val_loss: 1.3517\n",
      "Epoch 618/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5022 - val_loss: 1.3647\n",
      "Epoch 619/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4659 - val_loss: 1.3506\n",
      "Epoch 620/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4231 - val_loss: 1.3472\n",
      "Epoch 621/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4812 - val_loss: 1.3535\n",
      "Epoch 622/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5572 - val_loss: 1.3575\n",
      "Epoch 623/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4364 - val_loss: 1.3674\n",
      "Epoch 624/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5100 - val_loss: 1.3772\n",
      "Epoch 625/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.6015 - val_loss: 1.3699\n",
      "Epoch 626/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5063 - val_loss: 1.3453\n",
      "Epoch 627/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4145 - val_loss: 1.3537\n",
      "Epoch 628/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4750 - val_loss: 1.3479\n",
      "Epoch 629/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4477 - val_loss: 1.3546\n",
      "Epoch 630/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4545 - val_loss: 1.3663\n",
      "Epoch 631/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3118 - val_loss: 1.3571\n",
      "Epoch 632/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4728 - val_loss: 1.3506\n",
      "Epoch 633/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4051 - val_loss: 1.3725\n",
      "Epoch 634/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5255 - val_loss: 1.4054\n",
      "Epoch 635/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5055 - val_loss: 1.3441\n",
      "Epoch 636/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4833 - val_loss: 1.3634\n",
      "Epoch 637/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4536 - val_loss: 1.3545\n",
      "Epoch 638/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4740 - val_loss: 1.3811\n",
      "Epoch 639/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5111 - val_loss: 1.3513\n",
      "Epoch 640/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4597 - val_loss: 1.3707\n",
      "Epoch 641/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4088 - val_loss: 1.3751\n",
      "Epoch 642/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5844 - val_loss: 1.3671\n",
      "Epoch 643/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4251 - val_loss: 1.3769\n",
      "Epoch 644/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4594 - val_loss: 1.3651\n",
      "Epoch 645/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.4451 - val_loss: 1.3781\n",
      "Epoch 646/20000\n",
      "1500/1500 [==============================] - 0s 47us/sample - loss: 1.4182 - val_loss: 1.3821\n",
      "Epoch 647/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4103 - val_loss: 1.3678\n",
      "Epoch 648/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.4909 - val_loss: 1.3708\n",
      "Epoch 649/20000\n",
      "1500/1500 [==============================] - 0s 45us/sample - loss: 1.5535 - val_loss: 1.3645\n",
      "Epoch 650/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.5282 - val_loss: 1.3669\n",
      "Epoch 651/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3972 - val_loss: 1.3777\n",
      "Epoch 652/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4322 - val_loss: 1.3666\n",
      "Epoch 653/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4764 - val_loss: 1.3635\n",
      "Epoch 654/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5084 - val_loss: 1.3413\n",
      "Epoch 655/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4789 - val_loss: 1.3954\n",
      "Epoch 656/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5960 - val_loss: 1.3707\n",
      "Epoch 657/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5074 - val_loss: 1.3573\n",
      "Epoch 658/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4111 - val_loss: 1.3823\n",
      "Epoch 659/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.5171 - val_loss: 1.3519\n",
      "Epoch 660/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4432 - val_loss: 1.3794\n",
      "Epoch 661/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4899 - val_loss: 1.3404\n",
      "Epoch 662/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4547 - val_loss: 1.3941\n",
      "Epoch 663/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4668 - val_loss: 1.3471\n",
      "Epoch 664/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5507 - val_loss: 1.4048\n",
      "Epoch 665/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5647 - val_loss: 1.3621\n",
      "Epoch 666/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4288 - val_loss: 1.3844\n",
      "Epoch 667/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4388 - val_loss: 1.3904\n",
      "Epoch 668/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.6222 - val_loss: 1.3466\n",
      "Epoch 669/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4638 - val_loss: 1.3765\n",
      "Epoch 670/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4150 - val_loss: 1.3515\n",
      "Epoch 671/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4416 - val_loss: 1.3518\n",
      "Epoch 672/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3612 - val_loss: 1.3335\n",
      "Epoch 673/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4237 - val_loss: 1.3692\n",
      "Epoch 674/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4986 - val_loss: 1.3441\n",
      "Epoch 675/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5354 - val_loss: 1.3357\n",
      "Epoch 676/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5076 - val_loss: 1.3829\n",
      "Epoch 677/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4978 - val_loss: 1.3451\n",
      "Epoch 678/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5260 - val_loss: 1.3558\n",
      "Epoch 679/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3793 - val_loss: 1.3642\n",
      "Epoch 680/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4112 - val_loss: 1.3603\n",
      "Epoch 681/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3811 - val_loss: 1.3592\n",
      "Epoch 682/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4725 - val_loss: 1.3434\n",
      "Epoch 683/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4792 - val_loss: 1.3410\n",
      "Epoch 684/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3934 - val_loss: 1.3818\n",
      "Epoch 685/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4675 - val_loss: 1.3589\n",
      "Epoch 686/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4852 - val_loss: 1.3640\n",
      "Epoch 687/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.5246 - val_loss: 1.3568\n",
      "Epoch 688/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4126 - val_loss: 1.3342\n",
      "Epoch 689/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4161 - val_loss: 1.3731\n",
      "Epoch 690/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4500 - val_loss: 1.3400\n",
      "Epoch 691/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4403 - val_loss: 1.3478\n",
      "Epoch 692/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3822 - val_loss: 1.3465\n",
      "Epoch 693/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5334 - val_loss: 1.3623\n",
      "Epoch 694/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4979 - val_loss: 1.3496\n",
      "Epoch 695/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3908 - val_loss: 1.3444\n",
      "Epoch 696/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5350 - val_loss: 1.3621\n",
      "Epoch 697/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4937 - val_loss: 1.3803\n",
      "Epoch 698/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4947 - val_loss: 1.3508\n",
      "Epoch 699/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4467 - val_loss: 1.3493\n",
      "Epoch 700/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4369 - val_loss: 1.3322\n",
      "Epoch 701/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3824 - val_loss: 1.3682\n",
      "Epoch 702/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4170 - val_loss: 1.3564\n",
      "Epoch 703/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4707 - val_loss: 1.3631\n",
      "Epoch 704/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4711 - val_loss: 1.3845\n",
      "Epoch 705/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.3627 - val_loss: 1.3616\n",
      "Epoch 706/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.7109 - val_loss: 1.3557\n",
      "Epoch 707/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3955 - val_loss: 1.3489\n",
      "Epoch 708/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.6294 - val_loss: 1.3413\n",
      "Epoch 709/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4484 - val_loss: 1.3313\n",
      "Epoch 710/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4047 - val_loss: 1.3692\n",
      "Epoch 711/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.5285 - val_loss: 1.3825\n",
      "Epoch 712/20000\n",
      "1500/1500 [==============================] - 0s 45us/sample - loss: 1.4720 - val_loss: 1.3866\n",
      "Epoch 713/20000\n",
      "1500/1500 [==============================] - 0s 45us/sample - loss: 1.4921 - val_loss: 1.3549\n",
      "Epoch 714/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4577 - val_loss: 1.3216\n",
      "Epoch 715/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.4785 - val_loss: 1.3677\n",
      "Epoch 716/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.5408 - val_loss: 1.3562\n",
      "Epoch 717/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3986 - val_loss: 1.3531\n",
      "Epoch 718/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4825 - val_loss: 1.3706\n",
      "Epoch 719/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5078 - val_loss: 1.3707\n",
      "Epoch 720/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4493 - val_loss: 1.3478\n",
      "Epoch 721/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.5355 - val_loss: 1.3842\n",
      "Epoch 722/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3946 - val_loss: 1.3436\n",
      "Epoch 723/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4662 - val_loss: 1.4064\n",
      "Epoch 724/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4289 - val_loss: 1.3788\n",
      "Epoch 725/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5701 - val_loss: 1.3787\n",
      "Epoch 726/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4115 - val_loss: 1.3535\n",
      "Epoch 727/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.5284 - val_loss: 1.3503\n",
      "Epoch 728/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4680 - val_loss: 1.3329\n",
      "Epoch 729/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4378 - val_loss: 1.3326\n",
      "Epoch 730/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4824 - val_loss: 1.3504\n",
      "Epoch 731/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4603 - val_loss: 1.3334\n",
      "Epoch 732/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5183 - val_loss: 1.3321\n",
      "Epoch 733/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4390 - val_loss: 1.3372\n",
      "Epoch 734/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.5694 - val_loss: 1.3280\n",
      "Epoch 735/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.4560 - val_loss: 1.3480\n",
      "Epoch 736/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4925 - val_loss: 1.3462\n",
      "Epoch 737/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.6252 - val_loss: 1.3687\n",
      "Epoch 738/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6341 - val_loss: 1.3530\n",
      "Epoch 739/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5929 - val_loss: 1.3621\n",
      "Epoch 740/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4785 - val_loss: 1.3329\n",
      "Epoch 741/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4591 - val_loss: 1.3564\n",
      "Epoch 742/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3746 - val_loss: 1.3548\n",
      "Epoch 743/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4236 - val_loss: 1.3336\n",
      "Epoch 744/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4612 - val_loss: 1.3236\n",
      "Epoch 745/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4774 - val_loss: 1.3716\n",
      "Epoch 746/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4005 - val_loss: 1.3480\n",
      "Epoch 747/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4844 - val_loss: 1.3194\n",
      "Epoch 748/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3745 - val_loss: 1.3759\n",
      "Epoch 749/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4539 - val_loss: 1.3601\n",
      "Epoch 750/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5387 - val_loss: 1.3973\n",
      "Epoch 751/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4221 - val_loss: 1.3141\n",
      "Epoch 752/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4886 - val_loss: 1.3897\n",
      "Epoch 753/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4824 - val_loss: 1.3212\n",
      "Epoch 754/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5604 - val_loss: 1.3663\n",
      "Epoch 755/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5615 - val_loss: 1.2957\n",
      "Epoch 756/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4167 - val_loss: 1.3501\n",
      "Epoch 757/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4446 - val_loss: 1.3129\n",
      "Epoch 758/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5746 - val_loss: 1.3432\n",
      "Epoch 759/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3795 - val_loss: 1.3372\n",
      "Epoch 760/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3443 - val_loss: 1.3559\n",
      "Epoch 761/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4000 - val_loss: 1.3231\n",
      "Epoch 762/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4538 - val_loss: 1.3234\n",
      "Epoch 763/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3790 - val_loss: 1.3267\n",
      "Epoch 764/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4297 - val_loss: 1.3273\n",
      "Epoch 765/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4540 - val_loss: 1.3139\n",
      "Epoch 766/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5122 - val_loss: 1.3464\n",
      "Epoch 767/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4947 - val_loss: 1.3473\n",
      "Epoch 768/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4868 - val_loss: 1.3245\n",
      "Epoch 769/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5039 - val_loss: 1.3449\n",
      "Epoch 770/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4928 - val_loss: 1.3126\n",
      "Epoch 771/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4085 - val_loss: 1.3450\n",
      "Epoch 772/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3703 - val_loss: 1.3196\n",
      "Epoch 773/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3996 - val_loss: 1.3299\n",
      "Epoch 774/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5129 - val_loss: 1.3450\n",
      "Epoch 775/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5171 - val_loss: 1.3370\n",
      "Epoch 776/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4399 - val_loss: 1.3163\n",
      "Epoch 777/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3584 - val_loss: 1.3345\n",
      "Epoch 778/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4256 - val_loss: 1.3329\n",
      "Epoch 779/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4341 - val_loss: 1.3325\n",
      "Epoch 780/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3601 - val_loss: 1.3299\n",
      "Epoch 781/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3482 - val_loss: 1.3347\n",
      "Epoch 782/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4855 - val_loss: 1.3599\n",
      "Epoch 783/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3469 - val_loss: 1.3249\n",
      "Epoch 784/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4008 - val_loss: 1.3447\n",
      "Epoch 785/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4747 - val_loss: 1.3627\n",
      "Epoch 786/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3973 - val_loss: 1.3214\n",
      "Epoch 787/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4801 - val_loss: 1.3273\n",
      "Epoch 788/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4157 - val_loss: 1.3298\n",
      "Epoch 789/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3645 - val_loss: 1.3238\n",
      "Epoch 790/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4615 - val_loss: 1.3173\n",
      "Epoch 791/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4520 - val_loss: 1.3517\n",
      "Epoch 792/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4044 - val_loss: 1.3883\n",
      "Epoch 793/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4103 - val_loss: 1.3524\n",
      "Epoch 794/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4759 - val_loss: 1.3537\n",
      "Epoch 795/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4565 - val_loss: 1.3302\n",
      "Epoch 796/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5679 - val_loss: 1.3315\n",
      "Epoch 797/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4455 - val_loss: 1.3406\n",
      "Epoch 798/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5454 - val_loss: 1.3041\n",
      "Epoch 799/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.5430 - val_loss: 1.3464\n",
      "Epoch 800/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.4190 - val_loss: 1.3553\n",
      "Epoch 801/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3756 - val_loss: 1.3486\n",
      "Epoch 802/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4340 - val_loss: 1.3397\n",
      "Epoch 803/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5218 - val_loss: 1.3514\n",
      "Epoch 804/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3633 - val_loss: 1.3231\n",
      "Epoch 805/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4472 - val_loss: 1.3589\n",
      "Epoch 806/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5156 - val_loss: 1.3598\n",
      "Epoch 807/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3812 - val_loss: 1.3430\n",
      "Epoch 808/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4235 - val_loss: 1.3633\n",
      "Epoch 809/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6212 - val_loss: 1.3405\n",
      "Epoch 810/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.6581 - val_loss: 1.3662\n",
      "Epoch 811/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4206 - val_loss: 1.3156\n",
      "Epoch 812/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3842 - val_loss: 1.3147\n",
      "Epoch 813/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3844 - val_loss: 1.3602\n",
      "Epoch 814/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4958 - val_loss: 1.3389\n",
      "Epoch 815/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3545 - val_loss: 1.3486\n",
      "Epoch 816/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5344 - val_loss: 1.3345\n",
      "Epoch 817/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5473 - val_loss: 1.3038\n",
      "Epoch 818/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4293 - val_loss: 1.3718\n",
      "Epoch 819/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4912 - val_loss: 1.3551\n",
      "Epoch 820/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4421 - val_loss: 1.3423\n",
      "Epoch 821/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3725 - val_loss: 1.3270\n",
      "Epoch 822/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4665 - val_loss: 1.3098\n",
      "Epoch 823/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3235 - val_loss: 1.3066\n",
      "Epoch 824/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3114 - val_loss: 1.3051\n",
      "Epoch 825/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5082 - val_loss: 1.3339\n",
      "Epoch 826/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5467 - val_loss: 1.3251\n",
      "Epoch 827/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4271 - val_loss: 1.2915\n",
      "Epoch 828/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4669 - val_loss: 1.3076\n",
      "Epoch 829/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5122 - val_loss: 1.3215\n",
      "Epoch 830/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3820 - val_loss: 1.3447\n",
      "Epoch 831/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4104 - val_loss: 1.3342\n",
      "Epoch 832/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3974 - val_loss: 1.3564\n",
      "Epoch 833/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4658 - val_loss: 1.3143\n",
      "Epoch 834/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4712 - val_loss: 1.3876\n",
      "Epoch 835/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4486 - val_loss: 1.3312\n",
      "Epoch 836/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.6119 - val_loss: 1.3244\n",
      "Epoch 837/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5471 - val_loss: 1.3537\n",
      "Epoch 838/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4415 - val_loss: 1.3255\n",
      "Epoch 839/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4119 - val_loss: 1.3497\n",
      "Epoch 840/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4548 - val_loss: 1.3565\n",
      "Epoch 841/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4164 - val_loss: 1.3702\n",
      "Epoch 842/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5006 - val_loss: 1.3435\n",
      "Epoch 843/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4763 - val_loss: 1.3508\n",
      "Epoch 844/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5156 - val_loss: 1.3228\n",
      "Epoch 845/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4672 - val_loss: 1.3265\n",
      "Epoch 846/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5769 - val_loss: 1.3167\n",
      "Epoch 847/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4655 - val_loss: 1.2867\n",
      "Epoch 848/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4688 - val_loss: 1.3544\n",
      "Epoch 849/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5220 - val_loss: 1.3031\n",
      "Epoch 850/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3678 - val_loss: 1.3107\n",
      "Epoch 851/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4386 - val_loss: 1.3008\n",
      "Epoch 852/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4812 - val_loss: 1.3390\n",
      "Epoch 853/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5000 - val_loss: 1.3484\n",
      "Epoch 854/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3708 - val_loss: 1.3474\n",
      "Epoch 855/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5176 - val_loss: 1.3748\n",
      "Epoch 856/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5420 - val_loss: 1.3687\n",
      "Epoch 857/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3912 - val_loss: 1.3495\n",
      "Epoch 858/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5362 - val_loss: 1.3197\n",
      "Epoch 859/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5728 - val_loss: 1.3046\n",
      "Epoch 860/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4388 - val_loss: 1.3687\n",
      "Epoch 861/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5389 - val_loss: 1.3839\n",
      "Epoch 862/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5155 - val_loss: 1.3763\n",
      "Epoch 863/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3567 - val_loss: 1.3626\n",
      "Epoch 864/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4674 - val_loss: 1.3203\n",
      "Epoch 865/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3517 - val_loss: 1.3667\n",
      "Epoch 866/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3803 - val_loss: 1.3530\n",
      "Epoch 867/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5600 - val_loss: 1.3111\n",
      "Epoch 868/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4406 - val_loss: 1.3285\n",
      "Epoch 869/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4971 - val_loss: 1.3222\n",
      "Epoch 870/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4594 - val_loss: 1.3145\n",
      "Epoch 871/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5586 - val_loss: 1.3597\n",
      "Epoch 872/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5741 - val_loss: 1.3422\n",
      "Epoch 873/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3630 - val_loss: 1.3379\n",
      "Epoch 874/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5131 - val_loss: 1.3461\n",
      "Epoch 875/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5530 - val_loss: 1.3394\n",
      "Epoch 876/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5398 - val_loss: 1.3338\n",
      "Epoch 877/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5753 - val_loss: 1.3351\n",
      "Epoch 878/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4299 - val_loss: 1.3068\n",
      "Epoch 879/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5040 - val_loss: 1.3189\n",
      "Epoch 880/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4776 - val_loss: 1.2924\n",
      "Epoch 881/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4563 - val_loss: 1.3181\n",
      "Epoch 882/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4641 - val_loss: 1.3466\n",
      "Epoch 883/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3792 - val_loss: 1.2980\n",
      "Epoch 884/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4724 - val_loss: 1.3521\n",
      "Epoch 885/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4125 - val_loss: 1.3462\n",
      "Epoch 886/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4554 - val_loss: 1.3665\n",
      "Epoch 887/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4245 - val_loss: 1.3333\n",
      "Epoch 888/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3953 - val_loss: 1.3611\n",
      "Epoch 889/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4357 - val_loss: 1.2925\n",
      "Epoch 890/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4072 - val_loss: 1.3290\n",
      "Epoch 891/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4246 - val_loss: 1.3293\n",
      "Epoch 892/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4462 - val_loss: 1.3252\n",
      "Epoch 893/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4787 - val_loss: 1.3265\n",
      "Epoch 894/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4146 - val_loss: 1.3351\n",
      "Epoch 895/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4595 - val_loss: 1.3202\n",
      "Epoch 896/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4266 - val_loss: 1.3049\n",
      "Epoch 897/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5529 - val_loss: 1.3345\n",
      "Epoch 898/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.4044 - val_loss: 1.2902\n",
      "Epoch 899/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4390 - val_loss: 1.3238\n",
      "Epoch 900/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3989 - val_loss: 1.2913\n",
      "Epoch 901/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.4203 - val_loss: 1.3128\n",
      "Epoch 902/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4499 - val_loss: 1.2891\n",
      "Epoch 903/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.4430 - val_loss: 1.2896\n",
      "Epoch 904/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.4035 - val_loss: 1.2954\n",
      "Epoch 905/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.4673 - val_loss: 1.3295\n",
      "Epoch 906/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.5085 - val_loss: 1.3197\n",
      "Epoch 907/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.4758 - val_loss: 1.3178\n",
      "Epoch 908/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.4958 - val_loss: 1.3843\n",
      "Epoch 909/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.5359 - val_loss: 1.3649\n",
      "Epoch 910/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.3506 - val_loss: 1.3506\n",
      "Epoch 911/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.5595 - val_loss: 1.3346\n",
      "Epoch 912/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5743 - val_loss: 1.2980\n",
      "Epoch 913/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4016 - val_loss: 1.3468\n",
      "Epoch 914/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4548 - val_loss: 1.3278\n",
      "Epoch 915/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4029 - val_loss: 1.2980\n",
      "Epoch 916/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4623 - val_loss: 1.3224\n",
      "Epoch 917/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4618 - val_loss: 1.2988\n",
      "Epoch 918/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4898 - val_loss: 1.3351\n",
      "Epoch 919/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4171 - val_loss: 1.3116\n",
      "Epoch 920/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4767 - val_loss: 1.3151\n",
      "Epoch 921/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4454 - val_loss: 1.2831\n",
      "Epoch 922/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4802 - val_loss: 1.2862\n",
      "Epoch 923/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3727 - val_loss: 1.2640\n",
      "Epoch 924/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4473 - val_loss: 1.4967\n",
      "Epoch 925/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5240 - val_loss: 1.9342\n",
      "Epoch 926/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3768 - val_loss: 1.8086\n",
      "Epoch 927/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4370 - val_loss: 1.6206\n",
      "Epoch 928/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4441 - val_loss: 1.5723\n",
      "Epoch 929/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4754 - val_loss: 1.4987\n",
      "Epoch 930/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3224 - val_loss: 1.4492\n",
      "Epoch 931/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4727 - val_loss: 1.3800\n",
      "Epoch 932/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4568 - val_loss: 1.4157\n",
      "Epoch 933/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4196 - val_loss: 1.3203\n",
      "Epoch 934/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4611 - val_loss: 1.3492\n",
      "Epoch 935/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5190 - val_loss: 1.3358\n",
      "Epoch 936/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3422 - val_loss: 1.3213\n",
      "Epoch 937/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3959 - val_loss: 1.2905\n",
      "Epoch 938/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4350 - val_loss: 1.2943\n",
      "Epoch 939/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4321 - val_loss: 1.2961\n",
      "Epoch 940/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3770 - val_loss: 1.3116\n",
      "Epoch 941/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4404 - val_loss: 1.3001\n",
      "Epoch 942/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3831 - val_loss: 1.3007\n",
      "Epoch 943/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5153 - val_loss: 1.2920\n",
      "Epoch 944/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4126 - val_loss: 1.3407\n",
      "Epoch 945/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5533 - val_loss: 1.3122\n",
      "Epoch 946/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4061 - val_loss: 1.2731\n",
      "Epoch 947/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4174 - val_loss: 1.3463\n",
      "Epoch 948/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5239 - val_loss: 1.2884\n",
      "Epoch 949/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4225 - val_loss: 1.3131\n",
      "Epoch 950/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3076 - val_loss: 1.2908\n",
      "Epoch 951/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3546 - val_loss: 1.2945\n",
      "Epoch 952/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4830 - val_loss: 1.3063\n",
      "Epoch 953/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4438 - val_loss: 1.3269\n",
      "Epoch 954/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4126 - val_loss: 1.3129\n",
      "Epoch 955/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4919 - val_loss: 1.3080\n",
      "Epoch 956/20000\n",
      "1500/1500 [==============================] - 0s 46us/sample - loss: 1.4437 - val_loss: 1.3330\n",
      "Epoch 957/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4230 - val_loss: 1.2902\n",
      "Epoch 958/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5184 - val_loss: 1.3220\n",
      "Epoch 959/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4283 - val_loss: 1.3031\n",
      "Epoch 960/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3559 - val_loss: 1.3369\n",
      "Epoch 961/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3556 - val_loss: 1.2941\n",
      "Epoch 962/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4304 - val_loss: 1.2792\n",
      "Epoch 963/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4695 - val_loss: 1.3044\n",
      "Epoch 964/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4146 - val_loss: 1.2968\n",
      "Epoch 965/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5041 - val_loss: 1.3191\n",
      "Epoch 966/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4241 - val_loss: 1.3315\n",
      "Epoch 967/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4773 - val_loss: 1.3177\n",
      "Epoch 968/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.4570 - val_loss: 1.3042\n",
      "Epoch 969/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4589 - val_loss: 1.2829\n",
      "Epoch 970/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4817 - val_loss: 1.3094\n",
      "Epoch 971/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4875 - val_loss: 1.3007\n",
      "Epoch 972/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4010 - val_loss: 1.3004\n",
      "Epoch 973/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3917 - val_loss: 1.2993\n",
      "Epoch 974/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3448 - val_loss: 1.2745\n",
      "Epoch 975/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3860 - val_loss: 1.2909\n",
      "Epoch 976/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4553 - val_loss: 1.3014\n",
      "Epoch 977/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3471 - val_loss: 1.3148\n",
      "Epoch 978/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4597 - val_loss: 1.3014\n",
      "Epoch 979/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3944 - val_loss: 1.3048\n",
      "Epoch 980/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4513 - val_loss: 1.2930\n",
      "Epoch 981/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4566 - val_loss: 1.3459\n",
      "Epoch 982/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3427 - val_loss: 1.2698\n",
      "Epoch 983/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3982 - val_loss: 1.2972\n",
      "Epoch 984/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3595 - val_loss: 1.2936\n",
      "Epoch 985/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4369 - val_loss: 1.3069\n",
      "Epoch 986/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4475 - val_loss: 1.3027\n",
      "Epoch 987/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4013 - val_loss: 1.2850\n",
      "Epoch 988/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6271 - val_loss: 1.3079\n",
      "Epoch 989/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4931 - val_loss: 1.3102\n",
      "Epoch 990/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4417 - val_loss: 1.2890\n",
      "Epoch 991/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4498 - val_loss: 1.2996\n",
      "Epoch 992/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5476 - val_loss: 1.2982\n",
      "Epoch 993/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4710 - val_loss: 1.3049\n",
      "Epoch 994/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5117 - val_loss: 1.3379\n",
      "Epoch 995/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4570 - val_loss: 1.3158\n",
      "Epoch 996/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3564 - val_loss: 1.2999\n",
      "Epoch 997/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4855 - val_loss: 1.3055\n",
      "Epoch 998/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4637 - val_loss: 1.3313\n",
      "Epoch 999/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4133 - val_loss: 1.3280\n",
      "Epoch 1000/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4431 - val_loss: 1.3052\n",
      "Epoch 1001/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4485 - val_loss: 1.2940\n",
      "Epoch 1002/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6044 - val_loss: 1.2894\n",
      "Epoch 1003/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4027 - val_loss: 1.3045\n",
      "Epoch 1004/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4770 - val_loss: 1.3316\n",
      "Epoch 1005/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4089 - val_loss: 1.2905\n",
      "Epoch 1006/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3882 - val_loss: 1.3055\n",
      "Epoch 1007/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3502 - val_loss: 1.3070\n",
      "Epoch 1008/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4995 - val_loss: 1.2790\n",
      "Epoch 1009/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4273 - val_loss: 1.3427\n",
      "Epoch 1010/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4307 - val_loss: 1.3257\n",
      "Epoch 1011/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4422 - val_loss: 1.2756\n",
      "Epoch 1012/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3825 - val_loss: 1.2816\n",
      "Epoch 1013/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4173 - val_loss: 1.2673\n",
      "Epoch 1014/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4385 - val_loss: 1.3095\n",
      "Epoch 1015/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4253 - val_loss: 1.3269\n",
      "Epoch 1016/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4526 - val_loss: 1.2685\n",
      "Epoch 1017/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4740 - val_loss: 1.2771\n",
      "Epoch 1018/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4716 - val_loss: 1.2705\n",
      "Epoch 1019/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4085 - val_loss: 1.2596\n",
      "Epoch 1020/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4009 - val_loss: 1.2906\n",
      "Epoch 1021/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3250 - val_loss: 1.2597\n",
      "Epoch 1022/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4159 - val_loss: 1.2747\n",
      "Epoch 1023/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4548 - val_loss: 1.3013\n",
      "Epoch 1024/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4310 - val_loss: 1.3253\n",
      "Epoch 1025/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4218 - val_loss: 1.2851\n",
      "Epoch 1026/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4307 - val_loss: 1.2897\n",
      "Epoch 1027/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4051 - val_loss: 1.2936\n",
      "Epoch 1028/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4424 - val_loss: 1.2934\n",
      "Epoch 1029/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5246 - val_loss: 1.2702\n",
      "Epoch 1030/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3932 - val_loss: 1.2937\n",
      "Epoch 1031/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3838 - val_loss: 1.2672\n",
      "Epoch 1032/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4279 - val_loss: 1.2824\n",
      "Epoch 1033/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4226 - val_loss: 1.2952\n",
      "Epoch 1034/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4384 - val_loss: 1.2787\n",
      "Epoch 1035/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5188 - val_loss: 1.2792\n",
      "Epoch 1036/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4458 - val_loss: 1.2572\n",
      "Epoch 1037/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4311 - val_loss: 1.2751\n",
      "Epoch 1038/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3364 - val_loss: 1.2888\n",
      "Epoch 1039/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4659 - val_loss: 1.2610\n",
      "Epoch 1040/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4496 - val_loss: 1.2868\n",
      "Epoch 1041/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4993 - val_loss: 1.2809\n",
      "Epoch 1042/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3902 - val_loss: 1.2585\n",
      "Epoch 1043/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5278 - val_loss: 1.2944\n",
      "Epoch 1044/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4680 - val_loss: 1.2913\n",
      "Epoch 1045/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4578 - val_loss: 1.2938\n",
      "Epoch 1046/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4026 - val_loss: 1.2522\n",
      "Epoch 1047/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5313 - val_loss: 1.2800\n",
      "Epoch 1048/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4595 - val_loss: 1.2805\n",
      "Epoch 1049/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5009 - val_loss: 1.3171\n",
      "Epoch 1050/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4721 - val_loss: 1.2819\n",
      "Epoch 1051/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4245 - val_loss: 1.2844\n",
      "Epoch 1052/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4612 - val_loss: 1.3165\n",
      "Epoch 1053/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4394 - val_loss: 1.2622\n",
      "Epoch 1054/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4461 - val_loss: 1.2740\n",
      "Epoch 1055/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3963 - val_loss: 1.3288\n",
      "Epoch 1056/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3526 - val_loss: 1.2718\n",
      "Epoch 1057/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4203 - val_loss: 1.2786\n",
      "Epoch 1058/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4524 - val_loss: 1.2779\n",
      "Epoch 1059/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5302 - val_loss: 1.2998\n",
      "Epoch 1060/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4276 - val_loss: 1.2940\n",
      "Epoch 1061/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5122 - val_loss: 1.2931\n",
      "Epoch 1062/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4217 - val_loss: 1.2809\n",
      "Epoch 1063/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5289 - val_loss: 1.2420\n",
      "Epoch 1064/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5027 - val_loss: 1.3253\n",
      "Epoch 1065/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3916 - val_loss: 1.2724\n",
      "Epoch 1066/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3808 - val_loss: 1.2721\n",
      "Epoch 1067/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3783 - val_loss: 1.2835\n",
      "Epoch 1068/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3970 - val_loss: 1.2735\n",
      "Epoch 1069/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4250 - val_loss: 1.2792\n",
      "Epoch 1070/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4416 - val_loss: 1.2639\n",
      "Epoch 1071/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4823 - val_loss: 1.2938\n",
      "Epoch 1072/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5217 - val_loss: 1.2360\n",
      "Epoch 1073/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4307 - val_loss: 1.3068\n",
      "Epoch 1074/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4331 - val_loss: 1.2517\n",
      "Epoch 1075/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5051 - val_loss: 1.2471\n",
      "Epoch 1076/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4635 - val_loss: 1.2464\n",
      "Epoch 1077/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4878 - val_loss: 1.2930\n",
      "Epoch 1078/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4622 - val_loss: 1.2508\n",
      "Epoch 1079/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4506 - val_loss: 1.2595\n",
      "Epoch 1080/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5202 - val_loss: 1.2441\n",
      "Epoch 1081/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4452 - val_loss: 1.3369\n",
      "Epoch 1082/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4520 - val_loss: 1.2789\n",
      "Epoch 1083/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4711 - val_loss: 1.3060\n",
      "Epoch 1084/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3010 - val_loss: 1.2893\n",
      "Epoch 1085/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4984 - val_loss: 1.2718\n",
      "Epoch 1086/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4792 - val_loss: 1.2387\n",
      "Epoch 1087/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5222 - val_loss: 1.2801\n",
      "Epoch 1088/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3983 - val_loss: 1.2636\n",
      "Epoch 1089/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4299 - val_loss: 1.2650\n",
      "Epoch 1090/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3986 - val_loss: 1.2973\n",
      "Epoch 1091/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4113 - val_loss: 1.2851\n",
      "Epoch 1092/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3069 - val_loss: 1.2844\n",
      "Epoch 1093/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4049 - val_loss: 1.2781\n",
      "Epoch 1094/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3583 - val_loss: 1.2738\n",
      "Epoch 1095/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3651 - val_loss: 1.2725\n",
      "Epoch 1096/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3354 - val_loss: 1.2627\n",
      "Epoch 1097/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4546 - val_loss: 1.2790\n",
      "Epoch 1098/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4397 - val_loss: 1.3283\n",
      "Epoch 1099/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3345 - val_loss: 1.2427\n",
      "Epoch 1100/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4971 - val_loss: 1.2448\n",
      "Epoch 1101/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4116 - val_loss: 1.2960\n",
      "Epoch 1102/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4102 - val_loss: 1.2740\n",
      "Epoch 1103/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3602 - val_loss: 1.2554\n",
      "Epoch 1104/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4114 - val_loss: 1.2737\n",
      "Epoch 1105/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4256 - val_loss: 1.2640\n",
      "Epoch 1106/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4077 - val_loss: 1.2760\n",
      "Epoch 1107/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4822 - val_loss: 1.2883\n",
      "Epoch 1108/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3605 - val_loss: 1.2381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1109/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3841 - val_loss: 1.2659\n",
      "Epoch 1110/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4443 - val_loss: 1.3151\n",
      "Epoch 1111/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3961 - val_loss: 1.2541\n",
      "Epoch 1112/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3707 - val_loss: 1.2626\n",
      "Epoch 1113/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5050 - val_loss: 1.2475\n",
      "Epoch 1114/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4916 - val_loss: 1.2848\n",
      "Epoch 1115/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4786 - val_loss: 1.2694\n",
      "Epoch 1116/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4532 - val_loss: 1.2714\n",
      "Epoch 1117/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5756 - val_loss: 1.2637\n",
      "Epoch 1118/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3319 - val_loss: 1.2744\n",
      "Epoch 1119/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4452 - val_loss: 1.2561\n",
      "Epoch 1120/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4656 - val_loss: 1.2385\n",
      "Epoch 1121/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3405 - val_loss: 1.2355\n",
      "Epoch 1122/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3389 - val_loss: 1.2597\n",
      "Epoch 1123/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5611 - val_loss: 1.2380\n",
      "Epoch 1124/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3505 - val_loss: 1.3069\n",
      "Epoch 1125/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4933 - val_loss: 1.2487\n",
      "Epoch 1126/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5745 - val_loss: 1.2463\n",
      "Epoch 1127/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4647 - val_loss: 1.2534\n",
      "Epoch 1128/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4339 - val_loss: 1.2566\n",
      "Epoch 1129/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4322 - val_loss: 1.2373\n",
      "Epoch 1130/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4267 - val_loss: 1.2638\n",
      "Epoch 1131/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4674 - val_loss: 1.2576\n",
      "Epoch 1132/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5268 - val_loss: 1.2647\n",
      "Epoch 1133/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4442 - val_loss: 1.2733\n",
      "Epoch 1134/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5582 - val_loss: 1.2325\n",
      "Epoch 1135/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5021 - val_loss: 1.2647\n",
      "Epoch 1136/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3801 - val_loss: 1.2185\n",
      "Epoch 1137/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5070 - val_loss: 1.2263\n",
      "Epoch 1138/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4357 - val_loss: 1.2487\n",
      "Epoch 1139/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3594 - val_loss: 1.2534\n",
      "Epoch 1140/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4118 - val_loss: 1.2570\n",
      "Epoch 1141/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4915 - val_loss: 1.2290\n",
      "Epoch 1142/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4120 - val_loss: 1.2633\n",
      "Epoch 1143/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4776 - val_loss: 1.2301\n",
      "Epoch 1144/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4698 - val_loss: 1.2195\n",
      "Epoch 1145/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4575 - val_loss: 1.2845\n",
      "Epoch 1146/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4310 - val_loss: 1.1998\n",
      "Epoch 1147/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3738 - val_loss: 1.2551\n",
      "Epoch 1148/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3467 - val_loss: 1.2380\n",
      "Epoch 1149/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4626 - val_loss: 1.2468\n",
      "Epoch 1150/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3832 - val_loss: 1.2191\n",
      "Epoch 1151/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4176 - val_loss: 1.2267\n",
      "Epoch 1152/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3841 - val_loss: 1.2488\n",
      "Epoch 1153/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5100 - val_loss: 1.2589\n",
      "Epoch 1154/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4708 - val_loss: 1.2753\n",
      "Epoch 1155/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4861 - val_loss: 1.2642\n",
      "Epoch 1156/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3947 - val_loss: 1.2719\n",
      "Epoch 1157/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4244 - val_loss: 1.2232\n",
      "Epoch 1158/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4603 - val_loss: 1.2746\n",
      "Epoch 1159/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4534 - val_loss: 1.2392\n",
      "Epoch 1160/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3733 - val_loss: 1.2166\n",
      "Epoch 1161/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4440 - val_loss: 1.2458\n",
      "Epoch 1162/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3813 - val_loss: 1.2486\n",
      "Epoch 1163/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4840 - val_loss: 1.2289\n",
      "Epoch 1164/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3662 - val_loss: 1.2499\n",
      "Epoch 1165/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4430 - val_loss: 1.2229\n",
      "Epoch 1166/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4168 - val_loss: 1.2524\n",
      "Epoch 1167/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5022 - val_loss: 1.2692\n",
      "Epoch 1168/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5351 - val_loss: 1.2116\n",
      "Epoch 1169/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4003 - val_loss: 1.2318\n",
      "Epoch 1170/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3991 - val_loss: 1.2196\n",
      "Epoch 1171/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5963 - val_loss: 1.2395\n",
      "Epoch 1172/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4213 - val_loss: 1.2193\n",
      "Epoch 1173/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4095 - val_loss: 1.2230\n",
      "Epoch 1174/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3906 - val_loss: 1.2420\n",
      "Epoch 1175/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3511 - val_loss: 1.2426\n",
      "Epoch 1176/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4514 - val_loss: 1.3242\n",
      "Epoch 1177/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3326 - val_loss: 1.2787\n",
      "Epoch 1178/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4951 - val_loss: 1.2133\n",
      "Epoch 1179/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3585 - val_loss: 1.2483\n",
      "Epoch 1180/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4303 - val_loss: 1.2453\n",
      "Epoch 1181/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3563 - val_loss: 1.2530\n",
      "Epoch 1182/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4654 - val_loss: 1.2591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1183/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6245 - val_loss: 1.2932\n",
      "Epoch 1184/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3867 - val_loss: 1.2419\n",
      "Epoch 1185/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4508 - val_loss: 1.2080\n",
      "Epoch 1186/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4893 - val_loss: 1.2144\n",
      "Epoch 1187/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4512 - val_loss: 1.2310\n",
      "Epoch 1188/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4275 - val_loss: 1.2015\n",
      "Epoch 1189/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3864 - val_loss: 1.2252\n",
      "Epoch 1190/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.3855 - val_loss: 1.2232\n",
      "Epoch 1191/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3737 - val_loss: 1.2515\n",
      "Epoch 1192/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4587 - val_loss: 1.2868\n",
      "Epoch 1193/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4012 - val_loss: 1.2299\n",
      "Epoch 1194/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4015 - val_loss: 1.2288\n",
      "Epoch 1195/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4280 - val_loss: 1.2488\n",
      "Epoch 1196/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3249 - val_loss: 1.2121\n",
      "Epoch 1197/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3528 - val_loss: 1.2195\n",
      "Epoch 1198/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3403 - val_loss: 1.2164\n",
      "Epoch 1199/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4013 - val_loss: 1.2297\n",
      "Epoch 1200/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2970 - val_loss: 1.2725\n",
      "Epoch 1201/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3747 - val_loss: 1.2124\n",
      "Epoch 1202/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4356 - val_loss: 1.2468\n",
      "Epoch 1203/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4311 - val_loss: 1.1912\n",
      "Epoch 1204/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3861 - val_loss: 1.2062\n",
      "Epoch 1205/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4643 - val_loss: 1.2361\n",
      "Epoch 1206/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5003 - val_loss: 1.2381\n",
      "Epoch 1207/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4302 - val_loss: 1.2330\n",
      "Epoch 1208/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3816 - val_loss: 1.2071\n",
      "Epoch 1209/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4075 - val_loss: 1.2688\n",
      "Epoch 1210/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3531 - val_loss: 1.2079\n",
      "Epoch 1211/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5751 - val_loss: 1.2272\n",
      "Epoch 1212/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4073 - val_loss: 1.2227\n",
      "Epoch 1213/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3986 - val_loss: 1.2640\n",
      "Epoch 1214/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3395 - val_loss: 1.2140\n",
      "Epoch 1215/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3483 - val_loss: 1.1910\n",
      "Epoch 1216/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4193 - val_loss: 1.2244\n",
      "Epoch 1217/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4410 - val_loss: 1.2382\n",
      "Epoch 1218/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3634 - val_loss: 1.1686\n",
      "Epoch 1219/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3568 - val_loss: 1.2110\n",
      "Epoch 1220/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4979 - val_loss: 1.2145\n",
      "Epoch 1221/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2886 - val_loss: 1.1906\n",
      "Epoch 1222/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4502 - val_loss: 1.2632\n",
      "Epoch 1223/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3109 - val_loss: 1.2208\n",
      "Epoch 1224/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4748 - val_loss: 1.2463\n",
      "Epoch 1225/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3524 - val_loss: 1.2343\n",
      "Epoch 1226/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3145 - val_loss: 1.2501\n",
      "Epoch 1227/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3602 - val_loss: 1.2351\n",
      "Epoch 1228/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2898 - val_loss: 1.2300\n",
      "Epoch 1229/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3202 - val_loss: 1.2270\n",
      "Epoch 1230/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4070 - val_loss: 1.2077\n",
      "Epoch 1231/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4446 - val_loss: 1.2449\n",
      "Epoch 1232/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4426 - val_loss: 1.2193\n",
      "Epoch 1233/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4136 - val_loss: 1.1963\n",
      "Epoch 1234/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2887 - val_loss: 1.2245\n",
      "Epoch 1235/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4994 - val_loss: 1.2070\n",
      "Epoch 1236/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5737 - val_loss: 1.2187\n",
      "Epoch 1237/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4301 - val_loss: 1.2396\n",
      "Epoch 1238/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3026 - val_loss: 1.2015\n",
      "Epoch 1239/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3902 - val_loss: 1.2176\n",
      "Epoch 1240/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6108 - val_loss: 1.1794\n",
      "Epoch 1241/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4324 - val_loss: 1.2085\n",
      "Epoch 1242/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4573 - val_loss: 1.2222\n",
      "Epoch 1243/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3838 - val_loss: 1.2180\n",
      "Epoch 1244/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2897 - val_loss: 1.2043\n",
      "Epoch 1245/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3216 - val_loss: 1.2272\n",
      "Epoch 1246/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4999 - val_loss: 1.2239\n",
      "Epoch 1247/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4253 - val_loss: 1.2381\n",
      "Epoch 1248/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4902 - val_loss: 1.2274\n",
      "Epoch 1249/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4151 - val_loss: 1.1644\n",
      "Epoch 1250/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4597 - val_loss: 1.2413\n",
      "Epoch 1251/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3668 - val_loss: 1.1909\n",
      "Epoch 1252/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4221 - val_loss: 1.2321\n",
      "Epoch 1253/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3313 - val_loss: 1.1894\n",
      "Epoch 1254/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4419 - val_loss: 1.2303\n",
      "Epoch 1255/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5011 - val_loss: 1.2118\n",
      "Epoch 1256/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4664 - val_loss: 1.1874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1257/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3101 - val_loss: 1.2464\n",
      "Epoch 1258/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4277 - val_loss: 1.1785\n",
      "Epoch 1259/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4000 - val_loss: 1.2501\n",
      "Epoch 1260/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4478 - val_loss: 1.2288\n",
      "Epoch 1261/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4117 - val_loss: 1.1882\n",
      "Epoch 1262/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3664 - val_loss: 1.2049\n",
      "Epoch 1263/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4738 - val_loss: 1.2328\n",
      "Epoch 1264/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5061 - val_loss: 1.1950\n",
      "Epoch 1265/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4672 - val_loss: 1.2462\n",
      "Epoch 1266/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3756 - val_loss: 1.2131\n",
      "Epoch 1267/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4418 - val_loss: 1.2443\n",
      "Epoch 1268/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4999 - val_loss: 1.2158\n",
      "Epoch 1269/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3984 - val_loss: 1.2289\n",
      "Epoch 1270/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3602 - val_loss: 1.2067\n",
      "Epoch 1271/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3632 - val_loss: 1.1944\n",
      "Epoch 1272/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5660 - val_loss: 1.2474\n",
      "Epoch 1273/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4592 - val_loss: 1.2172\n",
      "Epoch 1274/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3656 - val_loss: 1.2087\n",
      "Epoch 1275/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4606 - val_loss: 1.2697\n",
      "Epoch 1276/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3492 - val_loss: 1.2239\n",
      "Epoch 1277/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3516 - val_loss: 1.1817\n",
      "Epoch 1278/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4004 - val_loss: 1.2083\n",
      "Epoch 1279/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3369 - val_loss: 1.2033\n",
      "Epoch 1280/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4004 - val_loss: 1.2287\n",
      "Epoch 1281/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4727 - val_loss: 1.2302\n",
      "Epoch 1282/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4081 - val_loss: 1.2196\n",
      "Epoch 1283/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4281 - val_loss: 1.2001\n",
      "Epoch 1284/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3865 - val_loss: 1.1872\n",
      "Epoch 1285/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4011 - val_loss: 1.2194\n",
      "Epoch 1286/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4545 - val_loss: 1.2086\n",
      "Epoch 1287/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4224 - val_loss: 1.2478\n",
      "Epoch 1288/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4408 - val_loss: 1.2320\n",
      "Epoch 1289/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4041 - val_loss: 1.2433\n",
      "Epoch 1290/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3543 - val_loss: 1.2256\n",
      "Epoch 1291/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4279 - val_loss: 1.2480\n",
      "Epoch 1292/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5262 - val_loss: 1.1879\n",
      "Epoch 1293/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5084 - val_loss: 1.2630\n",
      "Epoch 1294/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4239 - val_loss: 1.1681\n",
      "Epoch 1295/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3429 - val_loss: 1.1932\n",
      "Epoch 1296/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4061 - val_loss: 1.2046\n",
      "Epoch 1297/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4599 - val_loss: 1.2252\n",
      "Epoch 1298/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4464 - val_loss: 1.1883\n",
      "Epoch 1299/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3329 - val_loss: 1.1765\n",
      "Epoch 1300/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3715 - val_loss: 1.1766\n",
      "Epoch 1301/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4528 - val_loss: 1.1915\n",
      "Epoch 1302/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5972 - val_loss: 1.2247\n",
      "Epoch 1303/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4294 - val_loss: 1.1672\n",
      "Epoch 1304/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5868 - val_loss: 1.1545\n",
      "Epoch 1305/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4039 - val_loss: 1.2288\n",
      "Epoch 1306/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4128 - val_loss: 1.2239\n",
      "Epoch 1307/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3106 - val_loss: 1.2019\n",
      "Epoch 1308/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3786 - val_loss: 1.2067\n",
      "Epoch 1309/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4254 - val_loss: 1.1649\n",
      "Epoch 1310/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3787 - val_loss: 1.2010\n",
      "Epoch 1311/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3468 - val_loss: 1.1579\n",
      "Epoch 1312/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3772 - val_loss: 1.2119\n",
      "Epoch 1313/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5440 - val_loss: 1.1998\n",
      "Epoch 1314/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3421 - val_loss: 1.1766\n",
      "Epoch 1315/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4406 - val_loss: 1.1897\n",
      "Epoch 1316/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5010 - val_loss: 1.1858\n",
      "Epoch 1317/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4232 - val_loss: 1.2137\n",
      "Epoch 1318/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3779 - val_loss: 1.2122\n",
      "Epoch 1319/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4066 - val_loss: 1.2009\n",
      "Epoch 1320/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4117 - val_loss: 1.1986\n",
      "Epoch 1321/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3173 - val_loss: 1.2076\n",
      "Epoch 1322/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4141 - val_loss: 1.1903\n",
      "Epoch 1323/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3287 - val_loss: 1.2098\n",
      "Epoch 1324/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3405 - val_loss: 1.2140\n",
      "Epoch 1325/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2846 - val_loss: 1.2069\n",
      "Epoch 1326/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4319 - val_loss: 1.1852\n",
      "Epoch 1327/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4456 - val_loss: 1.2079\n",
      "Epoch 1328/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4837 - val_loss: 1.2379\n",
      "Epoch 1329/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4693 - val_loss: 1.3024\n",
      "Epoch 1330/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4338 - val_loss: 1.2013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1331/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3846 - val_loss: 1.2270\n",
      "Epoch 1332/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3610 - val_loss: 1.2013\n",
      "Epoch 1333/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4217 - val_loss: 1.1957\n",
      "Epoch 1334/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3702 - val_loss: 1.2129\n",
      "Epoch 1335/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4999 - val_loss: 1.1819\n",
      "Epoch 1336/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4423 - val_loss: 1.1561\n",
      "Epoch 1337/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2677 - val_loss: 1.2015\n",
      "Epoch 1338/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3775 - val_loss: 1.1715\n",
      "Epoch 1339/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3676 - val_loss: 1.1858\n",
      "Epoch 1340/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3197 - val_loss: 1.1840\n",
      "Epoch 1341/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4634 - val_loss: 1.1631\n",
      "Epoch 1342/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4386 - val_loss: 1.1692\n",
      "Epoch 1343/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5040 - val_loss: 1.2363\n",
      "Epoch 1344/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4883 - val_loss: 1.1672\n",
      "Epoch 1345/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4449 - val_loss: 1.1744\n",
      "Epoch 1346/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4656 - val_loss: 1.1609\n",
      "Epoch 1347/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4512 - val_loss: 1.1909\n",
      "Epoch 1348/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3535 - val_loss: 1.1711\n",
      "Epoch 1349/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4176 - val_loss: 1.1867\n",
      "Epoch 1350/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4746 - val_loss: 1.2266\n",
      "Epoch 1351/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4911 - val_loss: 1.1519\n",
      "Epoch 1352/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5665 - val_loss: 1.2417\n",
      "Epoch 1353/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5052 - val_loss: 1.2418\n",
      "Epoch 1354/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3977 - val_loss: 1.1817\n",
      "Epoch 1355/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5025 - val_loss: 1.2410\n",
      "Epoch 1356/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4282 - val_loss: 1.2273\n",
      "Epoch 1357/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3417 - val_loss: 1.2496\n",
      "Epoch 1358/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4480 - val_loss: 1.2453\n",
      "Epoch 1359/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4242 - val_loss: 1.2216\n",
      "Epoch 1360/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3136 - val_loss: 1.1720\n",
      "Epoch 1361/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4353 - val_loss: 1.1825\n",
      "Epoch 1362/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3718 - val_loss: 1.2175\n",
      "Epoch 1363/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3682 - val_loss: 1.2474\n",
      "Epoch 1364/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5124 - val_loss: 1.2436\n",
      "Epoch 1365/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5158 - val_loss: 1.2843\n",
      "Epoch 1366/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4371 - val_loss: 1.1777\n",
      "Epoch 1367/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4814 - val_loss: 1.1791\n",
      "Epoch 1368/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4337 - val_loss: 1.1958\n",
      "Epoch 1369/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4236 - val_loss: 1.2347\n",
      "Epoch 1370/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4597 - val_loss: 1.2093\n",
      "Epoch 1371/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4495 - val_loss: 1.2567\n",
      "Epoch 1372/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3421 - val_loss: 1.1806\n",
      "Epoch 1373/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4264 - val_loss: 1.1910\n",
      "Epoch 1374/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3592 - val_loss: 1.1851\n",
      "Epoch 1375/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4379 - val_loss: 1.1894\n",
      "Epoch 1376/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2936 - val_loss: 1.1838\n",
      "Epoch 1377/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3707 - val_loss: 1.1787\n",
      "Epoch 1378/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4710 - val_loss: 1.1844\n",
      "Epoch 1379/20000\n",
      "1500/1500 [==============================] - 0s 44us/sample - loss: 1.4820 - val_loss: 1.1977\n",
      "Epoch 1380/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4544 - val_loss: 1.1577\n",
      "Epoch 1381/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3273 - val_loss: 1.1613\n",
      "Epoch 1382/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5476 - val_loss: 1.1565\n",
      "Epoch 1383/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4837 - val_loss: 1.1620\n",
      "Epoch 1384/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3779 - val_loss: 1.1709\n",
      "Epoch 1385/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4526 - val_loss: 1.1653\n",
      "Epoch 1386/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3657 - val_loss: 1.1795\n",
      "Epoch 1387/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3481 - val_loss: 1.1864\n",
      "Epoch 1388/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4044 - val_loss: 1.1521\n",
      "Epoch 1389/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3419 - val_loss: 1.1568\n",
      "Epoch 1390/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4062 - val_loss: 1.1806\n",
      "Epoch 1391/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3724 - val_loss: 1.1755\n",
      "Epoch 1392/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3863 - val_loss: 1.2020\n",
      "Epoch 1393/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4139 - val_loss: 1.1825\n",
      "Epoch 1394/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3668 - val_loss: 1.1761\n",
      "Epoch 1395/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3384 - val_loss: 1.1840\n",
      "Epoch 1396/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5049 - val_loss: 1.1850\n",
      "Epoch 1397/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4003 - val_loss: 1.1422\n",
      "Epoch 1398/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3368 - val_loss: 1.1845\n",
      "Epoch 1399/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3350 - val_loss: 1.1910\n",
      "Epoch 1400/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3509 - val_loss: 1.2360\n",
      "Epoch 1401/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5634 - val_loss: 1.1543\n",
      "Epoch 1402/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4584 - val_loss: 1.1567\n",
      "Epoch 1403/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4617 - val_loss: 1.1865\n",
      "Epoch 1404/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3713 - val_loss: 1.1799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1405/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3125 - val_loss: 1.2047\n",
      "Epoch 1406/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4549 - val_loss: 1.1986\n",
      "Epoch 1407/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3970 - val_loss: 1.1776\n",
      "Epoch 1408/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4926 - val_loss: 1.2240\n",
      "Epoch 1409/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4648 - val_loss: 1.1727\n",
      "Epoch 1410/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3743 - val_loss: 1.1682\n",
      "Epoch 1411/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3128 - val_loss: 1.1971\n",
      "Epoch 1412/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4542 - val_loss: 1.1489\n",
      "Epoch 1413/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4123 - val_loss: 1.1441\n",
      "Epoch 1414/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4084 - val_loss: 1.1298\n",
      "Epoch 1415/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3141 - val_loss: 1.1752\n",
      "Epoch 1416/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3822 - val_loss: 1.1738\n",
      "Epoch 1417/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4291 - val_loss: 1.2175\n",
      "Epoch 1418/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4035 - val_loss: 1.1610\n",
      "Epoch 1419/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4117 - val_loss: 1.1538\n",
      "Epoch 1420/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3247 - val_loss: 1.1707\n",
      "Epoch 1421/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4442 - val_loss: 1.1876\n",
      "Epoch 1422/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4475 - val_loss: 1.2297\n",
      "Epoch 1423/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3503 - val_loss: 1.2364\n",
      "Epoch 1424/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3643 - val_loss: 1.2153\n",
      "Epoch 1425/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3649 - val_loss: 1.2467\n",
      "Epoch 1426/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4512 - val_loss: 1.2949\n",
      "Epoch 1427/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3755 - val_loss: 1.2078\n",
      "Epoch 1428/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4416 - val_loss: 1.2446\n",
      "Epoch 1429/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4001 - val_loss: 1.2261\n",
      "Epoch 1430/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3364 - val_loss: 1.2533\n",
      "Epoch 1431/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4453 - val_loss: 1.2075\n",
      "Epoch 1432/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4582 - val_loss: 1.1967\n",
      "Epoch 1433/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5083 - val_loss: 1.1589\n",
      "Epoch 1434/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3645 - val_loss: 1.2390\n",
      "Epoch 1435/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4053 - val_loss: 1.2075\n",
      "Epoch 1436/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4536 - val_loss: 1.2130\n",
      "Epoch 1437/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4196 - val_loss: 1.1557\n",
      "Epoch 1438/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4150 - val_loss: 1.2630\n",
      "Epoch 1439/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4561 - val_loss: 1.1953\n",
      "Epoch 1440/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4326 - val_loss: 1.2013\n",
      "Epoch 1441/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4481 - val_loss: 1.2350\n",
      "Epoch 1442/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3641 - val_loss: 1.2191\n",
      "Epoch 1443/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4762 - val_loss: 1.2091\n",
      "Epoch 1444/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5143 - val_loss: 1.1563\n",
      "Epoch 1445/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3559 - val_loss: 1.2419\n",
      "Epoch 1446/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3945 - val_loss: 1.1649\n",
      "Epoch 1447/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3799 - val_loss: 1.2366\n",
      "Epoch 1448/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4120 - val_loss: 1.2281\n",
      "Epoch 1449/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4889 - val_loss: 1.2260\n",
      "Epoch 1450/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4554 - val_loss: 1.1616\n",
      "Epoch 1451/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3649 - val_loss: 1.2490\n",
      "Epoch 1452/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4903 - val_loss: 1.1685\n",
      "Epoch 1453/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4249 - val_loss: 1.2065\n",
      "Epoch 1454/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4853 - val_loss: 1.1920\n",
      "Epoch 1455/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4913 - val_loss: 1.2655\n",
      "Epoch 1456/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5091 - val_loss: 1.2022\n",
      "Epoch 1457/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3343 - val_loss: 1.2337\n",
      "Epoch 1458/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5001 - val_loss: 1.2198\n",
      "Epoch 1459/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3928 - val_loss: 1.1759\n",
      "Epoch 1460/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4364 - val_loss: 1.2128\n",
      "Epoch 1461/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4999 - val_loss: 1.1907\n",
      "Epoch 1462/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3692 - val_loss: 1.1856\n",
      "Epoch 1463/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3993 - val_loss: 1.1832\n",
      "Epoch 1464/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2823 - val_loss: 1.2598\n",
      "Epoch 1465/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4311 - val_loss: 1.1912\n",
      "Epoch 1466/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3792 - val_loss: 1.1957\n",
      "Epoch 1467/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4479 - val_loss: 1.2391\n",
      "Epoch 1468/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4626 - val_loss: 1.1666\n",
      "Epoch 1469/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3241 - val_loss: 1.1982\n",
      "Epoch 1470/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4343 - val_loss: 1.2010\n",
      "Epoch 1471/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5082 - val_loss: 1.1705\n",
      "Epoch 1472/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3921 - val_loss: 1.1916\n",
      "Epoch 1473/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3374 - val_loss: 1.2035\n",
      "Epoch 1474/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4052 - val_loss: 1.2550\n",
      "Epoch 1475/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3874 - val_loss: 1.2013\n",
      "Epoch 1476/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4618 - val_loss: 1.1921\n",
      "Epoch 1477/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3612 - val_loss: 1.2176\n",
      "Epoch 1478/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.4722 - val_loss: 1.2292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1479/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3320 - val_loss: 1.2628\n",
      "Epoch 1480/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3751 - val_loss: 1.3349\n",
      "Epoch 1481/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4201 - val_loss: 1.2966\n",
      "Epoch 1482/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3903 - val_loss: 1.2205\n",
      "Epoch 1483/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3589 - val_loss: 1.2781\n",
      "Epoch 1484/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4556 - val_loss: 1.2300\n",
      "Epoch 1485/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.2707 - val_loss: 1.2346\n",
      "Epoch 1486/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3728 - val_loss: 1.3176\n",
      "Epoch 1487/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4034 - val_loss: 1.2402\n",
      "Epoch 1488/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3669 - val_loss: 1.2683\n",
      "Epoch 1489/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4128 - val_loss: 1.3218\n",
      "Epoch 1490/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3882 - val_loss: 1.1681\n",
      "Epoch 1491/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4203 - val_loss: 1.1770\n",
      "Epoch 1492/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3837 - val_loss: 1.1870\n",
      "Epoch 1493/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4727 - val_loss: 1.1764\n",
      "Epoch 1494/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3191 - val_loss: 1.1615\n",
      "Epoch 1495/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3641 - val_loss: 1.1663\n",
      "Epoch 1496/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3971 - val_loss: 1.1627\n",
      "Epoch 1497/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3026 - val_loss: 1.1675\n",
      "Epoch 1498/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4800 - val_loss: 1.1946\n",
      "Epoch 1499/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4263 - val_loss: 1.2090\n",
      "Epoch 1500/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3081 - val_loss: 1.1476\n",
      "Epoch 1501/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4288 - val_loss: 1.1958\n",
      "Epoch 1502/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5063 - val_loss: 1.2276\n",
      "Epoch 1503/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4451 - val_loss: 1.2709\n",
      "Epoch 1504/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3897 - val_loss: 1.2612\n",
      "Epoch 1505/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4083 - val_loss: 1.2678\n",
      "Epoch 1506/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3736 - val_loss: 1.1561\n",
      "Epoch 1507/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4618 - val_loss: 1.1796\n",
      "Epoch 1508/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5007 - val_loss: 1.1605\n",
      "Epoch 1509/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4361 - val_loss: 1.1815\n",
      "Epoch 1510/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5409 - val_loss: 1.1747\n",
      "Epoch 1511/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2890 - val_loss: 1.1784\n",
      "Epoch 1512/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3790 - val_loss: 1.1679\n",
      "Epoch 1513/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5217 - val_loss: 1.1623\n",
      "Epoch 1514/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4073 - val_loss: 1.2169\n",
      "Epoch 1515/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3314 - val_loss: 1.2089\n",
      "Epoch 1516/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3810 - val_loss: 1.1892\n",
      "Epoch 1517/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3443 - val_loss: 1.1974\n",
      "Epoch 1518/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4645 - val_loss: 1.1836\n",
      "Epoch 1519/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3669 - val_loss: 1.1868\n",
      "Epoch 1520/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4086 - val_loss: 1.1890\n",
      "Epoch 1521/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4337 - val_loss: 1.1842\n",
      "Epoch 1522/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3872 - val_loss: 1.2435\n",
      "Epoch 1523/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4570 - val_loss: 1.2721\n",
      "Epoch 1524/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3535 - val_loss: 1.2577\n",
      "Epoch 1525/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3831 - val_loss: 1.1640\n",
      "Epoch 1526/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4235 - val_loss: 1.3041\n",
      "Epoch 1527/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3730 - val_loss: 1.2532\n",
      "Epoch 1528/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4038 - val_loss: 1.2111\n",
      "Epoch 1529/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3443 - val_loss: 1.2755\n",
      "Epoch 1530/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4021 - val_loss: 1.1603\n",
      "Epoch 1531/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4065 - val_loss: 1.1876\n",
      "Epoch 1532/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3545 - val_loss: 1.1647\n",
      "Epoch 1533/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4078 - val_loss: 1.2083\n",
      "Epoch 1534/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3904 - val_loss: 1.2549\n",
      "Epoch 1535/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3184 - val_loss: 1.1508\n",
      "Epoch 1536/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4283 - val_loss: 1.1909\n",
      "Epoch 1537/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3591 - val_loss: 1.2050\n",
      "Epoch 1538/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4008 - val_loss: 1.1310\n",
      "Epoch 1539/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3226 - val_loss: 1.1460\n",
      "Epoch 1540/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3705 - val_loss: 1.1775\n",
      "Epoch 1541/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3588 - val_loss: 1.1476\n",
      "Epoch 1542/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5493 - val_loss: 1.2973\n",
      "Epoch 1543/20000\n",
      "1500/1500 [==============================] - 0s 45us/sample - loss: 1.3630 - val_loss: 1.1844\n",
      "Epoch 1544/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4617 - val_loss: 1.2549\n",
      "Epoch 1545/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3445 - val_loss: 1.1657\n",
      "Epoch 1546/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3661 - val_loss: 1.2064\n",
      "Epoch 1547/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3159 - val_loss: 1.1751\n",
      "Epoch 1548/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3321 - val_loss: 1.1475\n",
      "Epoch 1549/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4108 - val_loss: 1.1827\n",
      "Epoch 1550/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3592 - val_loss: 1.1768\n",
      "Epoch 1551/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3896 - val_loss: 1.1695\n",
      "Epoch 1552/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3906 - val_loss: 1.1613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1553/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3747 - val_loss: 1.1523\n",
      "Epoch 1554/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3845 - val_loss: 1.1814\n",
      "Epoch 1555/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4401 - val_loss: 1.2085\n",
      "Epoch 1556/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4842 - val_loss: 1.2179\n",
      "Epoch 1557/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3210 - val_loss: 1.2612\n",
      "Epoch 1558/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3475 - val_loss: 1.2314\n",
      "Epoch 1559/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3988 - val_loss: 1.2914\n",
      "Epoch 1560/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4487 - val_loss: 1.2867\n",
      "Epoch 1561/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3455 - val_loss: 1.2298\n",
      "Epoch 1562/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4460 - val_loss: 1.3533\n",
      "Epoch 1563/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3890 - val_loss: 1.2063\n",
      "Epoch 1564/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5476 - val_loss: 1.3123\n",
      "Epoch 1565/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3433 - val_loss: 1.2769\n",
      "Epoch 1566/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4302 - val_loss: 1.2256\n",
      "Epoch 1567/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4707 - val_loss: 1.1711\n",
      "Epoch 1568/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4272 - val_loss: 1.2244\n",
      "Epoch 1569/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3962 - val_loss: 1.1402\n",
      "Epoch 1570/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3480 - val_loss: 1.1837\n",
      "Epoch 1571/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4160 - val_loss: 1.1765\n",
      "Epoch 1572/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3756 - val_loss: 1.1906\n",
      "Epoch 1573/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4120 - val_loss: 1.1451\n",
      "Epoch 1574/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4488 - val_loss: 1.1908\n",
      "Epoch 1575/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4751 - val_loss: 1.1395\n",
      "Epoch 1576/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5465 - val_loss: 1.1853\n",
      "Epoch 1577/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3479 - val_loss: 1.2039\n",
      "Epoch 1578/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3726 - val_loss: 1.1743\n",
      "Epoch 1579/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4937 - val_loss: 1.1625\n",
      "Epoch 1580/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3972 - val_loss: 1.1641\n",
      "Epoch 1581/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3409 - val_loss: 1.1396\n",
      "Epoch 1582/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4135 - val_loss: 1.2096\n",
      "Epoch 1583/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4267 - val_loss: 1.1624\n",
      "Epoch 1584/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3248 - val_loss: 1.2548\n",
      "Epoch 1585/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4646 - val_loss: 1.2034\n",
      "Epoch 1586/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3709 - val_loss: 1.2061\n",
      "Epoch 1587/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5579 - val_loss: 1.1867\n",
      "Epoch 1588/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3204 - val_loss: 1.1801\n",
      "Epoch 1589/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3634 - val_loss: 1.1389\n",
      "Epoch 1590/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3471 - val_loss: 1.1302\n",
      "Epoch 1591/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3716 - val_loss: 1.2416\n",
      "Epoch 1592/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3304 - val_loss: 1.2560\n",
      "Epoch 1593/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3302 - val_loss: 1.2477\n",
      "Epoch 1594/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4421 - val_loss: 1.2601\n",
      "Epoch 1595/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4324 - val_loss: 1.2796\n",
      "Epoch 1596/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3563 - val_loss: 1.2236\n",
      "Epoch 1597/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3727 - val_loss: 1.1972\n",
      "Epoch 1598/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3905 - val_loss: 1.2253\n",
      "Epoch 1599/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3983 - val_loss: 1.2135\n",
      "Epoch 1600/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3830 - val_loss: 1.2377\n",
      "Epoch 1601/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5589 - val_loss: 1.2859\n",
      "Epoch 1602/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3669 - val_loss: 1.3130\n",
      "Epoch 1603/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5310 - val_loss: 1.3195\n",
      "Epoch 1604/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4672 - val_loss: 1.2323\n",
      "Epoch 1605/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3638 - val_loss: 1.2253\n",
      "Epoch 1606/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3945 - val_loss: 1.2020\n",
      "Epoch 1607/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4015 - val_loss: 1.1700\n",
      "Epoch 1608/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4207 - val_loss: 1.1765\n",
      "Epoch 1609/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3710 - val_loss: 1.2689\n",
      "Epoch 1610/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5218 - val_loss: 1.1891\n",
      "Epoch 1611/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3706 - val_loss: 1.2333\n",
      "Epoch 1612/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3920 - val_loss: 1.2022\n",
      "Epoch 1613/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4294 - val_loss: 1.2155\n",
      "Epoch 1614/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4104 - val_loss: 1.2597\n",
      "Epoch 1615/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4250 - val_loss: 1.1764\n",
      "Epoch 1616/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3083 - val_loss: 1.3185\n",
      "Epoch 1617/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3997 - val_loss: 1.1852\n",
      "Epoch 1618/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4616 - val_loss: 1.1582\n",
      "Epoch 1619/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4167 - val_loss: 1.1840\n",
      "Epoch 1620/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3967 - val_loss: 1.1850\n",
      "Epoch 1621/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4843 - val_loss: 1.1993\n",
      "Epoch 1622/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3073 - val_loss: 1.1574\n",
      "Epoch 1623/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4213 - val_loss: 1.1405\n",
      "Epoch 1624/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3714 - val_loss: 1.1455\n",
      "Epoch 1625/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3501 - val_loss: 1.1409\n",
      "Epoch 1626/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3757 - val_loss: 1.1485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1627/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3626 - val_loss: 1.1504\n",
      "Epoch 1628/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4285 - val_loss: 1.1638\n",
      "Epoch 1629/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3288 - val_loss: 1.1322\n",
      "Epoch 1630/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5043 - val_loss: 1.1584\n",
      "Epoch 1631/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4495 - val_loss: 1.1936\n",
      "Epoch 1632/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5642 - val_loss: 1.1707\n",
      "Epoch 1633/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3315 - val_loss: 1.1784\n",
      "Epoch 1634/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4351 - val_loss: 1.1679\n",
      "Epoch 1635/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3202 - val_loss: 1.1736\n",
      "Epoch 1636/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4652 - val_loss: 1.1531\n",
      "Epoch 1637/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3054 - val_loss: 1.1622\n",
      "Epoch 1638/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4452 - val_loss: 1.2350\n",
      "Epoch 1639/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3819 - val_loss: 1.2007\n",
      "Epoch 1640/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5043 - val_loss: 1.1834\n",
      "Epoch 1641/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4140 - val_loss: 1.1976\n",
      "Epoch 1642/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4356 - val_loss: 1.1825\n",
      "Epoch 1643/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4260 - val_loss: 1.2205\n",
      "Epoch 1644/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4996 - val_loss: 1.1620\n",
      "Epoch 1645/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4756 - val_loss: 1.1672\n",
      "Epoch 1646/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3413 - val_loss: 1.1940\n",
      "Epoch 1647/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4092 - val_loss: 1.1787\n",
      "Epoch 1648/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5161 - val_loss: 1.1813\n",
      "Epoch 1649/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3622 - val_loss: 1.1685\n",
      "Epoch 1650/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3874 - val_loss: 1.1858\n",
      "Epoch 1651/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4175 - val_loss: 1.1950\n",
      "Epoch 1652/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3913 - val_loss: 1.2112\n",
      "Epoch 1653/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3686 - val_loss: 1.1422\n",
      "Epoch 1654/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4671 - val_loss: 1.2335\n",
      "Epoch 1655/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3218 - val_loss: 1.1646\n",
      "Epoch 1656/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3395 - val_loss: 1.2184\n",
      "Epoch 1657/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3900 - val_loss: 1.2260\n",
      "Epoch 1658/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2560 - val_loss: 1.2266\n",
      "Epoch 1659/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4456 - val_loss: 1.2688\n",
      "Epoch 1660/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3899 - val_loss: 1.2097\n",
      "Epoch 1661/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3542 - val_loss: 1.2248\n",
      "Epoch 1662/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3205 - val_loss: 1.1293\n",
      "Epoch 1663/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3616 - val_loss: 1.2353\n",
      "Epoch 1664/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3981 - val_loss: 1.2024\n",
      "Epoch 1665/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3099 - val_loss: 1.1996\n",
      "Epoch 1666/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4272 - val_loss: 1.1989\n",
      "Epoch 1667/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4375 - val_loss: 1.2235\n",
      "Epoch 1668/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3291 - val_loss: 1.1811\n",
      "Epoch 1669/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3587 - val_loss: 1.1837\n",
      "Epoch 1670/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3460 - val_loss: 1.1387\n",
      "Epoch 1671/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4201 - val_loss: 1.1576\n",
      "Epoch 1672/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3850 - val_loss: 1.2234\n",
      "Epoch 1673/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4501 - val_loss: 1.2256\n",
      "Epoch 1674/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5019 - val_loss: 1.1782\n",
      "Epoch 1675/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3782 - val_loss: 1.2129\n",
      "Epoch 1676/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4061 - val_loss: 1.2304\n",
      "Epoch 1677/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4313 - val_loss: 1.2217\n",
      "Epoch 1678/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4186 - val_loss: 1.1463\n",
      "Epoch 1679/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4009 - val_loss: 1.1465\n",
      "Epoch 1680/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4306 - val_loss: 1.1680\n",
      "Epoch 1681/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4438 - val_loss: 1.1412\n",
      "Epoch 1682/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4071 - val_loss: 1.1706\n",
      "Epoch 1683/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4232 - val_loss: 1.1806\n",
      "Epoch 1684/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4172 - val_loss: 1.1823\n",
      "Epoch 1685/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3508 - val_loss: 1.1576\n",
      "Epoch 1686/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3627 - val_loss: 1.1944\n",
      "Epoch 1687/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3444 - val_loss: 1.2109\n",
      "Epoch 1688/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4640 - val_loss: 1.2497\n",
      "Epoch 1689/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4892 - val_loss: 1.2309\n",
      "Epoch 1690/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5336 - val_loss: 1.1462\n",
      "Epoch 1691/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4156 - val_loss: 1.1411\n",
      "Epoch 1692/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5461 - val_loss: 1.2211\n",
      "Epoch 1693/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3133 - val_loss: 1.1695\n",
      "Epoch 1694/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3676 - val_loss: 1.1685\n",
      "Epoch 1695/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4177 - val_loss: 1.1764\n",
      "Epoch 1696/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5107 - val_loss: 1.1381\n",
      "Epoch 1697/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4172 - val_loss: 1.1586\n",
      "Epoch 1698/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4693 - val_loss: 1.1509\n",
      "Epoch 1699/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4853 - val_loss: 1.1354\n",
      "Epoch 1700/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4556 - val_loss: 1.1666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1701/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4505 - val_loss: 1.1672\n",
      "Epoch 1702/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3580 - val_loss: 1.2316\n",
      "Epoch 1703/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4376 - val_loss: 1.2038\n",
      "Epoch 1704/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3235 - val_loss: 1.1554\n",
      "Epoch 1705/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2753 - val_loss: 1.1747\n",
      "Epoch 1706/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3702 - val_loss: 1.1690\n",
      "Epoch 1707/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3711 - val_loss: 1.2365\n",
      "Epoch 1708/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3394 - val_loss: 1.2329\n",
      "Epoch 1709/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2974 - val_loss: 1.1570\n",
      "Epoch 1710/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3761 - val_loss: 1.1637\n",
      "Epoch 1711/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3968 - val_loss: 1.1546\n",
      "Epoch 1712/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4484 - val_loss: 1.1619\n",
      "Epoch 1713/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3900 - val_loss: 1.1767\n",
      "Epoch 1714/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4592 - val_loss: 1.1315\n",
      "Epoch 1715/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3545 - val_loss: 1.1843\n",
      "Epoch 1716/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4104 - val_loss: 1.1463\n",
      "Epoch 1717/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3509 - val_loss: 1.1798\n",
      "Epoch 1718/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4466 - val_loss: 1.1823\n",
      "Epoch 1719/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3226 - val_loss: 1.1721\n",
      "Epoch 1720/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4741 - val_loss: 1.1393\n",
      "Epoch 1721/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2994 - val_loss: 1.2356\n",
      "Epoch 1722/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4588 - val_loss: 1.2041\n",
      "Epoch 1723/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4299 - val_loss: 1.1949\n",
      "Epoch 1724/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4291 - val_loss: 1.1950\n",
      "Epoch 1725/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3888 - val_loss: 1.1731\n",
      "Epoch 1726/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4084 - val_loss: 1.1299\n",
      "Epoch 1727/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4199 - val_loss: 1.1658\n",
      "Epoch 1728/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4183 - val_loss: 1.1747\n",
      "Epoch 1729/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3768 - val_loss: 1.1693\n",
      "Epoch 1730/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3635 - val_loss: 1.1571\n",
      "Epoch 1731/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.5011 - val_loss: 1.2184\n",
      "Epoch 1732/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3960 - val_loss: 1.1789\n",
      "Epoch 1733/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4441 - val_loss: 1.1535\n",
      "Epoch 1734/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4433 - val_loss: 1.1675\n",
      "Epoch 1735/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3209 - val_loss: 1.2038\n",
      "Epoch 1736/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4684 - val_loss: 1.2651\n",
      "Epoch 1737/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3499 - val_loss: 1.2027\n",
      "Epoch 1738/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4006 - val_loss: 1.2234\n",
      "Epoch 1739/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4863 - val_loss: 1.2349\n",
      "Epoch 1740/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4384 - val_loss: 1.2621\n",
      "Epoch 1741/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4353 - val_loss: 1.2087\n",
      "Epoch 1742/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4725 - val_loss: 1.1783\n",
      "Epoch 1743/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4179 - val_loss: 1.1910\n",
      "Epoch 1744/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3325 - val_loss: 1.2085\n",
      "Epoch 1745/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3967 - val_loss: 1.1610\n",
      "Epoch 1746/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3233 - val_loss: 1.2072\n",
      "Epoch 1747/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3072 - val_loss: 1.2851\n",
      "Epoch 1748/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3235 - val_loss: 1.2328\n",
      "Epoch 1749/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3901 - val_loss: 1.2190\n",
      "Epoch 1750/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4228 - val_loss: 1.1901\n",
      "Epoch 1751/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3858 - val_loss: 1.1574\n",
      "Epoch 1752/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3823 - val_loss: 1.1462\n",
      "Epoch 1753/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3819 - val_loss: 1.1781\n",
      "Epoch 1754/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3329 - val_loss: 1.1419\n",
      "Epoch 1755/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3637 - val_loss: 1.1454\n",
      "Epoch 1756/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4116 - val_loss: 1.1461\n",
      "Epoch 1757/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3710 - val_loss: 1.1385\n",
      "Epoch 1758/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4399 - val_loss: 1.1419\n",
      "Epoch 1759/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3251 - val_loss: 1.1357\n",
      "Epoch 1760/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3932 - val_loss: 1.1368\n",
      "Epoch 1761/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3564 - val_loss: 1.1410\n",
      "Epoch 1762/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3817 - val_loss: 1.1574\n",
      "Epoch 1763/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4320 - val_loss: 1.1639\n",
      "Epoch 1764/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4244 - val_loss: 1.2137\n",
      "Epoch 1765/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3968 - val_loss: 1.1557\n",
      "Epoch 1766/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4908 - val_loss: 1.2044\n",
      "Epoch 1767/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4327 - val_loss: 1.1881\n",
      "Epoch 1768/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4919 - val_loss: 1.1990\n",
      "Epoch 1769/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3535 - val_loss: 1.2324\n",
      "Epoch 1770/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4089 - val_loss: 1.1697\n",
      "Epoch 1771/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4554 - val_loss: 1.2501\n",
      "Epoch 1772/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4286 - val_loss: 1.1845\n",
      "Epoch 1773/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4466 - val_loss: 1.1750\n",
      "Epoch 1774/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4631 - val_loss: 1.1643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1775/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4632 - val_loss: 1.2428\n",
      "Epoch 1776/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3638 - val_loss: 1.1925\n",
      "Epoch 1777/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4479 - val_loss: 1.2600\n",
      "Epoch 1778/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3492 - val_loss: 1.1983\n",
      "Epoch 1779/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4458 - val_loss: 1.1914\n",
      "Epoch 1780/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4417 - val_loss: 1.2534\n",
      "Epoch 1781/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3855 - val_loss: 1.1881\n",
      "Epoch 1782/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4760 - val_loss: 1.2172\n",
      "Epoch 1783/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3555 - val_loss: 1.2331\n",
      "Epoch 1784/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3887 - val_loss: 1.2131\n",
      "Epoch 1785/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3999 - val_loss: 1.1840\n",
      "Epoch 1786/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4928 - val_loss: 1.1942\n",
      "Epoch 1787/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3943 - val_loss: 1.2050\n",
      "Epoch 1788/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4948 - val_loss: 1.3066\n",
      "Epoch 1789/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4220 - val_loss: 1.1604\n",
      "Epoch 1790/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5939 - val_loss: 1.2365\n",
      "Epoch 1791/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3981 - val_loss: 1.1749\n",
      "Epoch 1792/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4172 - val_loss: 1.1824\n",
      "Epoch 1793/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4566 - val_loss: 1.1791\n",
      "Epoch 1794/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3856 - val_loss: 1.2631\n",
      "Epoch 1795/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4566 - val_loss: 1.3410\n",
      "Epoch 1796/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4229 - val_loss: 1.1894\n",
      "Epoch 1797/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4559 - val_loss: 1.2254\n",
      "Epoch 1798/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3623 - val_loss: 1.1975\n",
      "Epoch 1799/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4101 - val_loss: 1.1452\n",
      "Epoch 1800/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5452 - val_loss: 1.3779\n",
      "Epoch 1801/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5343 - val_loss: 1.2129\n",
      "Epoch 1802/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.6135 - val_loss: 1.3116\n",
      "Epoch 1803/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3178 - val_loss: 1.2030\n",
      "Epoch 1804/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4755 - val_loss: 1.2546\n",
      "Epoch 1805/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3295 - val_loss: 1.1991\n",
      "Epoch 1806/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3895 - val_loss: 1.2528\n",
      "Epoch 1807/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3836 - val_loss: 1.2419\n",
      "Epoch 1808/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3125 - val_loss: 1.2432\n",
      "Epoch 1809/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5737 - val_loss: 1.2310\n",
      "Epoch 1810/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3549 - val_loss: 1.3069\n",
      "Epoch 1811/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3599 - val_loss: 1.2225\n",
      "Epoch 1812/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4528 - val_loss: 1.2503\n",
      "Epoch 1813/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4423 - val_loss: 1.2789\n",
      "Epoch 1814/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3196 - val_loss: 1.1949\n",
      "Epoch 1815/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3754 - val_loss: 1.2008\n",
      "Epoch 1816/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3136 - val_loss: 1.2374\n",
      "Epoch 1817/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4527 - val_loss: 1.1696\n",
      "Epoch 1818/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3266 - val_loss: 1.1852\n",
      "Epoch 1819/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3456 - val_loss: 1.2196\n",
      "Epoch 1820/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4089 - val_loss: 1.1903\n",
      "Epoch 1821/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.6256 - val_loss: 1.1517\n",
      "Epoch 1822/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4760 - val_loss: 1.2173\n",
      "Epoch 1823/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4547 - val_loss: 1.1555\n",
      "Epoch 1824/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3255 - val_loss: 1.1788\n",
      "Epoch 1825/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4196 - val_loss: 1.1577\n",
      "Epoch 1826/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4027 - val_loss: 1.1336\n",
      "Epoch 1827/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4487 - val_loss: 1.1768\n",
      "Epoch 1828/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3858 - val_loss: 1.2055\n",
      "Epoch 1829/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3921 - val_loss: 1.1868\n",
      "Epoch 1830/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4153 - val_loss: 1.1969\n",
      "Epoch 1831/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3741 - val_loss: 1.2550\n",
      "Epoch 1832/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4840 - val_loss: 1.1673\n",
      "Epoch 1833/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4209 - val_loss: 1.1237\n",
      "Epoch 1834/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4364 - val_loss: 1.1802\n",
      "Epoch 1835/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3626 - val_loss: 1.1898\n",
      "Epoch 1836/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3079 - val_loss: 1.1568\n",
      "Epoch 1837/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4248 - val_loss: 1.2278\n",
      "Epoch 1838/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3777 - val_loss: 1.2100\n",
      "Epoch 1839/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3567 - val_loss: 1.2201\n",
      "Epoch 1840/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3200 - val_loss: 1.1704\n",
      "Epoch 1841/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4565 - val_loss: 1.1460\n",
      "Epoch 1842/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3073 - val_loss: 1.1595\n",
      "Epoch 1843/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4134 - val_loss: 1.1582\n",
      "Epoch 1844/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3954 - val_loss: 1.1934\n",
      "Epoch 1845/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4535 - val_loss: 1.2208\n",
      "Epoch 1846/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4198 - val_loss: 1.1866\n",
      "Epoch 1847/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2802 - val_loss: 1.2227\n",
      "Epoch 1848/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2976 - val_loss: 1.1688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1849/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3407 - val_loss: 1.1546\n",
      "Epoch 1850/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4295 - val_loss: 1.2137\n",
      "Epoch 1851/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4197 - val_loss: 1.1359\n",
      "Epoch 1852/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3627 - val_loss: 1.1614\n",
      "Epoch 1853/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3460 - val_loss: 1.2051\n",
      "Epoch 1854/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3766 - val_loss: 1.1725\n",
      "Epoch 1855/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4251 - val_loss: 1.2109\n",
      "Epoch 1856/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4667 - val_loss: 1.1829\n",
      "Epoch 1857/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3701 - val_loss: 1.2220\n",
      "Epoch 1858/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4024 - val_loss: 1.2290\n",
      "Epoch 1859/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4101 - val_loss: 1.2406\n",
      "Epoch 1860/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.2952 - val_loss: 1.2648\n",
      "Epoch 1861/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2959 - val_loss: 1.1824\n",
      "Epoch 1862/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.3758 - val_loss: 1.1988\n",
      "Epoch 1863/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.4083 - val_loss: 1.1760\n",
      "Epoch 1864/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4240 - val_loss: 1.1648\n",
      "Epoch 1865/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.4825 - val_loss: 1.2057\n",
      "Epoch 1866/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4905 - val_loss: 1.2090\n",
      "Epoch 1867/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4683 - val_loss: 1.1538\n",
      "Epoch 1868/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4492 - val_loss: 1.1434\n",
      "Epoch 1869/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3350 - val_loss: 1.2269\n",
      "Epoch 1870/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3529 - val_loss: 1.1755\n",
      "Epoch 1871/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5106 - val_loss: 1.1582\n",
      "Epoch 1872/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5220 - val_loss: 1.1437\n",
      "Epoch 1873/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3629 - val_loss: 1.1391\n",
      "Epoch 1874/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4457 - val_loss: 1.1614\n",
      "Epoch 1875/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3519 - val_loss: 1.1675\n",
      "Epoch 1876/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4020 - val_loss: 1.2298\n",
      "Epoch 1877/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4123 - val_loss: 1.1601\n",
      "Epoch 1878/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3441 - val_loss: 1.1535\n",
      "Epoch 1879/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4405 - val_loss: 1.1624\n",
      "Epoch 1880/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5187 - val_loss: 1.1607\n",
      "Epoch 1881/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3541 - val_loss: 1.1561\n",
      "Epoch 1882/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4027 - val_loss: 1.1729\n",
      "Epoch 1883/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3528 - val_loss: 1.1749\n",
      "Epoch 1884/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4925 - val_loss: 1.1324\n",
      "Epoch 1885/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4032 - val_loss: 1.1927\n",
      "Epoch 1886/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4322 - val_loss: 1.1685\n",
      "Epoch 1887/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5127 - val_loss: 1.1546\n",
      "Epoch 1888/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3674 - val_loss: 1.1594\n",
      "Epoch 1889/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3077 - val_loss: 1.1953\n",
      "Epoch 1890/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4373 - val_loss: 1.1390\n",
      "Epoch 1891/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5010 - val_loss: 1.1797\n",
      "Epoch 1892/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4472 - val_loss: 1.1683\n",
      "Epoch 1893/20000\n",
      "1500/1500 [==============================] - 0s 44us/sample - loss: 1.3994 - val_loss: 1.1487\n",
      "Epoch 1894/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4257 - val_loss: 1.2357\n",
      "Epoch 1895/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4727 - val_loss: 1.1449\n",
      "Epoch 1896/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3285 - val_loss: 1.2276\n",
      "Epoch 1897/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3233 - val_loss: 1.1483\n",
      "Epoch 1898/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4728 - val_loss: 1.1609\n",
      "Epoch 1899/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3961 - val_loss: 1.1738\n",
      "Epoch 1900/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5081 - val_loss: 1.1794\n",
      "Epoch 1901/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3756 - val_loss: 1.2298\n",
      "Epoch 1902/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4250 - val_loss: 1.2439\n",
      "Epoch 1903/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3335 - val_loss: 1.1509\n",
      "Epoch 1904/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3160 - val_loss: 1.1622\n",
      "Epoch 1905/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3483 - val_loss: 1.2115\n",
      "Epoch 1906/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3538 - val_loss: 1.1563\n",
      "Epoch 1907/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4369 - val_loss: 1.2368\n",
      "Epoch 1908/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5570 - val_loss: 1.1738\n",
      "Epoch 1909/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3696 - val_loss: 1.2032\n",
      "Epoch 1910/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3800 - val_loss: 1.1461\n",
      "Epoch 1911/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3749 - val_loss: 1.2048\n",
      "Epoch 1912/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4518 - val_loss: 1.2304\n",
      "Epoch 1913/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2620 - val_loss: 1.1303\n",
      "Epoch 1914/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3607 - val_loss: 1.1821\n",
      "Epoch 1915/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3274 - val_loss: 1.1960\n",
      "Epoch 1916/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4565 - val_loss: 1.1762\n",
      "Epoch 1917/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3856 - val_loss: 1.1439\n",
      "Epoch 1918/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3796 - val_loss: 1.2087\n",
      "Epoch 1919/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3616 - val_loss: 1.2366\n",
      "Epoch 1920/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4428 - val_loss: 1.2739\n",
      "Epoch 1921/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.2961 - val_loss: 1.1284\n",
      "Epoch 1922/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4587 - val_loss: 1.1876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1923/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4138 - val_loss: 1.1707\n",
      "Epoch 1924/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3382 - val_loss: 1.1431\n",
      "Epoch 1925/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4045 - val_loss: 1.1537\n",
      "Epoch 1926/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4342 - val_loss: 1.2615\n",
      "Epoch 1927/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4360 - val_loss: 1.2679\n",
      "Epoch 1928/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3127 - val_loss: 1.1912\n",
      "Epoch 1929/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5222 - val_loss: 1.1978\n",
      "Epoch 1930/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3545 - val_loss: 1.1703\n",
      "Epoch 1931/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3857 - val_loss: 1.2744\n",
      "Epoch 1932/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4264 - val_loss: 1.1655\n",
      "Epoch 1933/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5574 - val_loss: 1.1483\n",
      "Epoch 1934/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3522 - val_loss: 1.1770\n",
      "Epoch 1935/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4284 - val_loss: 1.1762\n",
      "Epoch 1936/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5305 - val_loss: 1.1729\n",
      "Epoch 1937/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4310 - val_loss: 1.1459\n",
      "Epoch 1938/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4620 - val_loss: 1.1862\n",
      "Epoch 1939/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4096 - val_loss: 1.1366\n",
      "Epoch 1940/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4197 - val_loss: 1.1466\n",
      "Epoch 1941/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3337 - val_loss: 1.1695\n",
      "Epoch 1942/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3720 - val_loss: 1.2231\n",
      "Epoch 1943/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4831 - val_loss: 1.2096\n",
      "Epoch 1944/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3685 - val_loss: 1.1427\n",
      "Epoch 1945/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3537 - val_loss: 1.1497\n",
      "Epoch 1946/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3994 - val_loss: 1.1648\n",
      "Epoch 1947/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4665 - val_loss: 1.2357\n",
      "Epoch 1948/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3072 - val_loss: 1.1648\n",
      "Epoch 1949/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3698 - val_loss: 1.1600\n",
      "Epoch 1950/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3738 - val_loss: 1.1792\n",
      "Epoch 1951/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4916 - val_loss: 1.1696\n",
      "Epoch 1952/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3371 - val_loss: 1.1483\n",
      "Epoch 1953/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3716 - val_loss: 1.1565\n",
      "Epoch 1954/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3684 - val_loss: 1.1473\n",
      "Epoch 1955/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4669 - val_loss: 1.1252\n",
      "Epoch 1956/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3367 - val_loss: 1.1358\n",
      "Epoch 1957/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4759 - val_loss: 1.2012\n",
      "Epoch 1958/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4035 - val_loss: 1.1489\n",
      "Epoch 1959/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3325 - val_loss: 1.1525\n",
      "Epoch 1960/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4755 - val_loss: 1.1543\n",
      "Epoch 1961/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4385 - val_loss: 1.1469\n",
      "Epoch 1962/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3786 - val_loss: 1.1440\n",
      "Epoch 1963/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4970 - val_loss: 1.2643\n",
      "Epoch 1964/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3775 - val_loss: 1.2135\n",
      "Epoch 1965/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3094 - val_loss: 1.1856\n",
      "Epoch 1966/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3660 - val_loss: 1.1929\n",
      "Epoch 1967/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4752 - val_loss: 1.1960\n",
      "Epoch 1968/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3543 - val_loss: 1.2036\n",
      "Epoch 1969/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4172 - val_loss: 1.1818\n",
      "Epoch 1970/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5119 - val_loss: 1.2634\n",
      "Epoch 1971/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3954 - val_loss: 1.3078\n",
      "Epoch 1972/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3861 - val_loss: 1.2870\n",
      "Epoch 1973/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4300 - val_loss: 1.1630\n",
      "Epoch 1974/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3530 - val_loss: 1.2396\n",
      "Epoch 1975/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2809 - val_loss: 1.1948\n",
      "Epoch 1976/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.2828 - val_loss: 1.1879\n",
      "Epoch 1977/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4127 - val_loss: 1.1619\n",
      "Epoch 1978/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4275 - val_loss: 1.1476\n",
      "Epoch 1979/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3636 - val_loss: 1.1510\n",
      "Epoch 1980/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4461 - val_loss: 1.2055\n",
      "Epoch 1981/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3854 - val_loss: 1.1516\n",
      "Epoch 1982/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4138 - val_loss: 1.2250\n",
      "Epoch 1983/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4592 - val_loss: 1.2947\n",
      "Epoch 1984/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4243 - val_loss: 1.2080\n",
      "Epoch 1985/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4487 - val_loss: 1.2844\n",
      "Epoch 1986/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5123 - val_loss: 1.2324\n",
      "Epoch 1987/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4320 - val_loss: 1.1910\n",
      "Epoch 1988/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3787 - val_loss: 1.2611\n",
      "Epoch 1989/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3735 - val_loss: 1.3284\n",
      "Epoch 1990/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3402 - val_loss: 1.2740\n",
      "Epoch 1991/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3675 - val_loss: 1.2136\n",
      "Epoch 1992/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3488 - val_loss: 1.1776\n",
      "Epoch 1993/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2934 - val_loss: 1.1920\n",
      "Epoch 1994/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4623 - val_loss: 1.1693\n",
      "Epoch 1995/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3238 - val_loss: 1.1287\n",
      "Epoch 1996/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3834 - val_loss: 1.1697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1997/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4097 - val_loss: 1.1512\n",
      "Epoch 1998/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3779 - val_loss: 1.1675\n",
      "Epoch 1999/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4738 - val_loss: 1.1689\n",
      "Epoch 2000/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3473 - val_loss: 1.1304\n",
      "Epoch 2001/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4493 - val_loss: 1.2396\n",
      "Epoch 2002/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4737 - val_loss: 1.1463\n",
      "Epoch 2003/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3839 - val_loss: 1.1308\n",
      "Epoch 2004/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4261 - val_loss: 1.1522\n",
      "Epoch 2005/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5096 - val_loss: 1.1798\n",
      "Epoch 2006/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3939 - val_loss: 1.1454\n",
      "Epoch 2007/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4822 - val_loss: 1.1706\n",
      "Epoch 2008/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4452 - val_loss: 1.1571\n",
      "Epoch 2009/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4302 - val_loss: 1.1382\n",
      "Epoch 2010/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3274 - val_loss: 1.1754\n",
      "Epoch 2011/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3925 - val_loss: 1.1266\n",
      "Epoch 2012/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4711 - val_loss: 1.1995\n",
      "Epoch 2013/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4047 - val_loss: 1.1656\n",
      "Epoch 2014/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3592 - val_loss: 1.1699\n",
      "Epoch 2015/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3485 - val_loss: 1.1520\n",
      "Epoch 2016/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3900 - val_loss: 1.1522\n",
      "Epoch 2017/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3755 - val_loss: 1.1533\n",
      "Epoch 2018/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4184 - val_loss: 1.1476\n",
      "Epoch 2019/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3477 - val_loss: 1.1303\n",
      "Epoch 2020/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4422 - val_loss: 1.1480\n",
      "Epoch 2021/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3942 - val_loss: 1.1781\n",
      "Epoch 2022/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3375 - val_loss: 1.2157\n",
      "Epoch 2023/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4130 - val_loss: 1.1928\n",
      "Epoch 2024/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3747 - val_loss: 1.1730\n",
      "Epoch 2025/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4615 - val_loss: 1.2157\n",
      "Epoch 2026/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5242 - val_loss: 1.2741\n",
      "Epoch 2027/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3270 - val_loss: 1.2148\n",
      "Epoch 2028/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4180 - val_loss: 1.2427\n",
      "Epoch 2029/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4924 - val_loss: 1.1490\n",
      "Epoch 2030/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4440 - val_loss: 1.1985\n",
      "Epoch 2031/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3977 - val_loss: 1.2065\n",
      "Epoch 2032/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3694 - val_loss: 1.2062\n",
      "Epoch 2033/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3342 - val_loss: 1.2796\n",
      "Epoch 2034/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3483 - val_loss: 1.2084\n",
      "Epoch 2035/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4144 - val_loss: 1.2518\n",
      "Epoch 2036/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3209 - val_loss: 1.2242\n",
      "Epoch 2037/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3554 - val_loss: 1.2498\n",
      "Epoch 2038/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4211 - val_loss: 1.2132\n",
      "Epoch 2039/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4627 - val_loss: 1.2735\n",
      "Epoch 2040/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4474 - val_loss: 1.2271\n",
      "Epoch 2041/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3316 - val_loss: 1.1494\n",
      "Epoch 2042/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2987 - val_loss: 1.1950\n",
      "Epoch 2043/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3854 - val_loss: 1.1762\n",
      "Epoch 2044/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4693 - val_loss: 1.2813\n",
      "Epoch 2045/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4010 - val_loss: 1.1892\n",
      "Epoch 2046/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3310 - val_loss: 1.1635\n",
      "Epoch 2047/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3955 - val_loss: 1.1826\n",
      "Epoch 2048/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4665 - val_loss: 1.1925\n",
      "Epoch 2049/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4853 - val_loss: 1.1343\n",
      "Epoch 2050/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3223 - val_loss: 1.2429\n",
      "Epoch 2051/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3802 - val_loss: 1.1800\n",
      "Epoch 2052/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3619 - val_loss: 1.1952\n",
      "Epoch 2053/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4330 - val_loss: 1.1747\n",
      "Epoch 2054/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4356 - val_loss: 1.1797\n",
      "Epoch 2055/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4615 - val_loss: 1.1976\n",
      "Epoch 2056/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4682 - val_loss: 1.1809\n",
      "Epoch 2057/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3495 - val_loss: 1.1913\n",
      "Epoch 2058/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3781 - val_loss: 1.2405\n",
      "Epoch 2059/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2713 - val_loss: 1.1528\n",
      "Epoch 2060/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4114 - val_loss: 1.1894\n",
      "Epoch 2061/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3426 - val_loss: 1.1876\n",
      "Epoch 2062/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3650 - val_loss: 1.1853\n",
      "Epoch 2063/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4737 - val_loss: 1.1518\n",
      "Epoch 2064/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5566 - val_loss: 1.1749\n",
      "Epoch 2065/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4009 - val_loss: 1.1863\n",
      "Epoch 2066/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4889 - val_loss: 1.2001\n",
      "Epoch 2067/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4595 - val_loss: 1.1970\n",
      "Epoch 2068/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4406 - val_loss: 1.1662\n",
      "Epoch 2069/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3956 - val_loss: 1.2074\n",
      "Epoch 2070/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3745 - val_loss: 1.2155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2071/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.4976 - val_loss: 1.2455\n",
      "Epoch 2072/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3985 - val_loss: 1.1977\n",
      "Epoch 2073/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4236 - val_loss: 1.1542\n",
      "Epoch 2074/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3873 - val_loss: 1.1561\n",
      "Epoch 2075/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3582 - val_loss: 1.2343\n",
      "Epoch 2076/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3237 - val_loss: 1.2097\n",
      "Epoch 2077/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4012 - val_loss: 1.1833\n",
      "Epoch 2078/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4213 - val_loss: 1.1381\n",
      "Epoch 2079/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4289 - val_loss: 1.1560\n",
      "Epoch 2080/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3793 - val_loss: 1.1343\n",
      "Epoch 2081/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3959 - val_loss: 1.2308\n",
      "Epoch 2082/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3289 - val_loss: 1.1326\n",
      "Epoch 2083/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3575 - val_loss: 1.1852\n",
      "Epoch 2084/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2999 - val_loss: 1.1713\n",
      "Epoch 2085/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4202 - val_loss: 1.1559\n",
      "Epoch 2086/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5572 - val_loss: 1.1678\n",
      "Epoch 2087/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3544 - val_loss: 1.2118\n",
      "Epoch 2088/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3866 - val_loss: 1.1547\n",
      "Epoch 2089/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3692 - val_loss: 1.2377\n",
      "Epoch 2090/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4768 - val_loss: 1.1762\n",
      "Epoch 2091/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4177 - val_loss: 1.2541\n",
      "Epoch 2092/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3544 - val_loss: 1.1907\n",
      "Epoch 2093/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3711 - val_loss: 1.1889\n",
      "Epoch 2094/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3418 - val_loss: 1.1977\n",
      "Epoch 2095/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3904 - val_loss: 1.1435\n",
      "Epoch 2096/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4283 - val_loss: 1.1509\n",
      "Epoch 2097/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5345 - val_loss: 1.2556\n",
      "Epoch 2098/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3813 - val_loss: 1.1719\n",
      "Epoch 2099/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4449 - val_loss: 1.1766\n",
      "Epoch 2100/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3241 - val_loss: 1.1977\n",
      "Epoch 2101/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5022 - val_loss: 1.1490\n",
      "Epoch 2102/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5174 - val_loss: 1.1550\n",
      "Epoch 2103/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3147 - val_loss: 1.1496\n",
      "Epoch 2104/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.6423 - val_loss: 1.2057\n",
      "Epoch 2105/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4142 - val_loss: 1.1612\n",
      "Epoch 2106/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4512 - val_loss: 1.1862\n",
      "Epoch 2107/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3804 - val_loss: 1.2056\n",
      "Epoch 2108/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4519 - val_loss: 1.1748\n",
      "Epoch 2109/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3420 - val_loss: 1.2156\n",
      "Epoch 2110/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4729 - val_loss: 1.2212\n",
      "Epoch 2111/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3950 - val_loss: 1.2534\n",
      "Epoch 2112/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4004 - val_loss: 1.1684\n",
      "Epoch 2113/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4254 - val_loss: 1.1787\n",
      "Epoch 2114/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4190 - val_loss: 1.1248\n",
      "Epoch 2115/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4616 - val_loss: 1.1548\n",
      "Epoch 2116/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5372 - val_loss: 1.1807\n",
      "Epoch 2117/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4456 - val_loss: 1.2030\n",
      "Epoch 2118/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3967 - val_loss: 1.1508\n",
      "Epoch 2119/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4664 - val_loss: 1.1850\n",
      "Epoch 2120/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4674 - val_loss: 1.2010\n",
      "Epoch 2121/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4141 - val_loss: 1.1821\n",
      "Epoch 2122/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3465 - val_loss: 1.2221\n",
      "Epoch 2123/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4088 - val_loss: 1.1426\n",
      "Epoch 2124/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4877 - val_loss: 1.1389\n",
      "Epoch 2125/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4067 - val_loss: 1.1766\n",
      "Epoch 2126/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2901 - val_loss: 1.1605\n",
      "Epoch 2127/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4167 - val_loss: 1.2138\n",
      "Epoch 2128/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4263 - val_loss: 1.1524\n",
      "Epoch 2129/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4867 - val_loss: 1.2373\n",
      "Epoch 2130/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3798 - val_loss: 1.1624\n",
      "Epoch 2131/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4195 - val_loss: 1.1922\n",
      "Epoch 2132/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4857 - val_loss: 1.1749\n",
      "Epoch 2133/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3053 - val_loss: 1.1286\n",
      "Epoch 2134/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3870 - val_loss: 1.1869\n",
      "Epoch 2135/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3778 - val_loss: 1.1787\n",
      "Epoch 2136/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3510 - val_loss: 1.1335\n",
      "Epoch 2137/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3059 - val_loss: 1.1821\n",
      "Epoch 2138/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5222 - val_loss: 1.1741\n",
      "Epoch 2139/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4446 - val_loss: 1.1722\n",
      "Epoch 2140/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4372 - val_loss: 1.1229\n",
      "Epoch 2141/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4569 - val_loss: 1.2099\n",
      "Epoch 2142/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3837 - val_loss: 1.1530\n",
      "Epoch 2143/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3037 - val_loss: 1.1660\n",
      "Epoch 2144/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4534 - val_loss: 1.1596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2145/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4499 - val_loss: 1.1417\n",
      "Epoch 2146/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5021 - val_loss: 1.1354\n",
      "Epoch 2147/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5454 - val_loss: 1.1652\n",
      "Epoch 2148/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4019 - val_loss: 1.1363\n",
      "Epoch 2149/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4302 - val_loss: 1.2109\n",
      "Epoch 2150/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4017 - val_loss: 1.1873\n",
      "Epoch 2151/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4700 - val_loss: 1.2611\n",
      "Epoch 2152/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4096 - val_loss: 1.2207\n",
      "Epoch 2153/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3780 - val_loss: 1.2044\n",
      "Epoch 2154/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4036 - val_loss: 1.1814\n",
      "Epoch 2155/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4325 - val_loss: 1.2090\n",
      "Epoch 2156/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3863 - val_loss: 1.1848\n",
      "Epoch 2157/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4308 - val_loss: 1.2197\n",
      "Epoch 2158/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3849 - val_loss: 1.2627\n",
      "Epoch 2159/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4290 - val_loss: 1.2534\n",
      "Epoch 2160/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.3805 - val_loss: 1.2015\n",
      "Epoch 2161/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3919 - val_loss: 1.2082\n",
      "Epoch 2162/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4227 - val_loss: 1.1857\n",
      "Epoch 2163/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5523 - val_loss: 1.1432\n",
      "Epoch 2164/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4333 - val_loss: 1.2512\n",
      "Epoch 2165/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3764 - val_loss: 1.1420\n",
      "Epoch 2166/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4026 - val_loss: 1.2073\n",
      "Epoch 2167/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3436 - val_loss: 1.1962\n",
      "Epoch 2168/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4463 - val_loss: 1.1858\n",
      "Epoch 2169/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3463 - val_loss: 1.1880\n",
      "Epoch 2170/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2559 - val_loss: 1.1975\n",
      "Epoch 2171/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4096 - val_loss: 1.1742\n",
      "Epoch 2172/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4634 - val_loss: 1.2088\n",
      "Epoch 2173/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3662 - val_loss: 1.2130\n",
      "Epoch 2174/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4599 - val_loss: 1.1725\n",
      "Epoch 2175/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5250 - val_loss: 1.2564\n",
      "Epoch 2176/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3871 - val_loss: 1.1446\n",
      "Epoch 2177/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5215 - val_loss: 1.1536\n",
      "Epoch 2178/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3140 - val_loss: 1.1691\n",
      "Epoch 2179/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3192 - val_loss: 1.1537\n",
      "Epoch 2180/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3681 - val_loss: 1.2334\n",
      "Epoch 2181/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4318 - val_loss: 1.1798\n",
      "Epoch 2182/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4457 - val_loss: 1.1854\n",
      "Epoch 2183/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4404 - val_loss: 1.1868\n",
      "Epoch 2184/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4110 - val_loss: 1.2624\n",
      "Epoch 2185/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3580 - val_loss: 1.1635\n",
      "Epoch 2186/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4273 - val_loss: 1.1705\n",
      "Epoch 2187/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3895 - val_loss: 1.2168\n",
      "Epoch 2188/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.2993 - val_loss: 1.2080\n",
      "Epoch 2189/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4070 - val_loss: 1.2153\n",
      "Epoch 2190/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3571 - val_loss: 1.2042\n",
      "Epoch 2191/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3729 - val_loss: 1.1579\n",
      "Epoch 2192/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4113 - val_loss: 1.1469\n",
      "Epoch 2193/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3708 - val_loss: 1.2114\n",
      "Epoch 2194/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3478 - val_loss: 1.1433\n",
      "Epoch 2195/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3946 - val_loss: 1.1816\n",
      "Epoch 2196/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5012 - val_loss: 1.1907\n",
      "Epoch 2197/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4556 - val_loss: 1.2091\n",
      "Epoch 2198/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4737 - val_loss: 1.2009\n",
      "Epoch 2199/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3596 - val_loss: 1.2002\n",
      "Epoch 2200/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4179 - val_loss: 1.1808\n",
      "Epoch 2201/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4767 - val_loss: 1.1923\n",
      "Epoch 2202/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3647 - val_loss: 1.1456\n",
      "Epoch 2203/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4395 - val_loss: 1.1622\n",
      "Epoch 2204/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3527 - val_loss: 1.1861\n",
      "Epoch 2205/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4574 - val_loss: 1.1880\n",
      "Epoch 2206/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3764 - val_loss: 1.5668\n",
      "Epoch 2207/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3406 - val_loss: 1.4700\n",
      "Epoch 2208/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4152 - val_loss: 1.3556\n",
      "Epoch 2209/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3147 - val_loss: 1.3513\n",
      "Epoch 2210/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3934 - val_loss: 1.2010\n",
      "Epoch 2211/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5263 - val_loss: 1.2335\n",
      "Epoch 2212/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3121 - val_loss: 1.2420\n",
      "Epoch 2213/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3912 - val_loss: 1.2076\n",
      "Epoch 2214/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3971 - val_loss: 1.1939\n",
      "Epoch 2215/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4030 - val_loss: 1.1567\n",
      "Epoch 2216/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3913 - val_loss: 1.1856\n",
      "Epoch 2217/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3809 - val_loss: 1.1812\n",
      "Epoch 2218/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4452 - val_loss: 1.1910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2219/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3720 - val_loss: 1.1881\n",
      "Epoch 2220/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4632 - val_loss: 1.1606\n",
      "Epoch 2221/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4499 - val_loss: 1.2032\n",
      "Epoch 2222/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3451 - val_loss: 1.2027\n",
      "Epoch 2223/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4546 - val_loss: 1.1655\n",
      "Epoch 2224/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5492 - val_loss: 1.1709\n",
      "Epoch 2225/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3104 - val_loss: 1.2377\n",
      "Epoch 2226/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5512 - val_loss: 1.1718\n",
      "Epoch 2227/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4299 - val_loss: 1.1796\n",
      "Epoch 2228/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3162 - val_loss: 1.1582\n",
      "Epoch 2229/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4550 - val_loss: 1.1726\n",
      "Epoch 2230/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4109 - val_loss: 1.1668\n",
      "Epoch 2231/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4550 - val_loss: 1.1446\n",
      "Epoch 2232/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3629 - val_loss: 1.1819\n",
      "Epoch 2233/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4200 - val_loss: 1.1515\n",
      "Epoch 2234/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4387 - val_loss: 1.1960\n",
      "Epoch 2235/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4237 - val_loss: 1.1921\n",
      "Epoch 2236/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4270 - val_loss: 1.1646\n",
      "Epoch 2237/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4593 - val_loss: 1.1620\n",
      "Epoch 2238/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4228 - val_loss: 1.1777\n",
      "Epoch 2239/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5609 - val_loss: 1.1806\n",
      "Epoch 2240/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4058 - val_loss: 1.1735\n",
      "Epoch 2241/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.2748 - val_loss: 1.1519\n",
      "Epoch 2242/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3101 - val_loss: 1.1857\n",
      "Epoch 2243/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5185 - val_loss: 1.1585\n",
      "Epoch 2244/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3623 - val_loss: 1.1522\n",
      "Epoch 2245/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3597 - val_loss: 1.1965\n",
      "Epoch 2246/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4777 - val_loss: 1.1742\n",
      "Epoch 2247/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4459 - val_loss: 1.1621\n",
      "Epoch 2248/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4176 - val_loss: 1.1667\n",
      "Epoch 2249/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4248 - val_loss: 1.1530\n",
      "Epoch 2250/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3475 - val_loss: 1.1659\n",
      "Epoch 2251/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4326 - val_loss: 1.1788\n",
      "Epoch 2252/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3564 - val_loss: 1.1650\n",
      "Epoch 2253/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3948 - val_loss: 1.1311\n",
      "Epoch 2254/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3511 - val_loss: 1.1838\n",
      "Epoch 2255/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4102 - val_loss: 1.1269\n",
      "Epoch 2256/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3439 - val_loss: 1.1840\n",
      "Epoch 2257/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4280 - val_loss: 1.1353\n",
      "Epoch 2258/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3721 - val_loss: 1.1839\n",
      "Epoch 2259/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3012 - val_loss: 1.1551\n",
      "Epoch 2260/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4297 - val_loss: 1.1759\n",
      "Epoch 2261/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4610 - val_loss: 1.2370\n",
      "Epoch 2262/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3537 - val_loss: 1.1861\n",
      "Epoch 2263/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3885 - val_loss: 1.1821\n",
      "Epoch 2264/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3703 - val_loss: 1.1375\n",
      "Epoch 2265/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2759 - val_loss: 1.1603\n",
      "Epoch 2266/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3724 - val_loss: 1.1743\n",
      "Epoch 2267/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4487 - val_loss: 1.1947\n",
      "Epoch 2268/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4156 - val_loss: 1.1424\n",
      "Epoch 2269/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4397 - val_loss: 1.1928\n",
      "Epoch 2270/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3510 - val_loss: 1.1720\n",
      "Epoch 2271/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4542 - val_loss: 1.1694\n",
      "Epoch 2272/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4726 - val_loss: 1.1774\n",
      "Epoch 2273/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3968 - val_loss: 1.1855\n",
      "Epoch 2274/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4130 - val_loss: 1.1367\n",
      "Epoch 2275/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4118 - val_loss: 1.2057\n",
      "Epoch 2276/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3841 - val_loss: 1.1330\n",
      "Epoch 2277/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5207 - val_loss: 1.1873\n",
      "Epoch 2278/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5429 - val_loss: 1.1965\n",
      "Epoch 2279/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4668 - val_loss: 1.1598\n",
      "Epoch 2280/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5504 - val_loss: 1.1214\n",
      "Epoch 2281/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4180 - val_loss: 1.1949\n",
      "Epoch 2282/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5299 - val_loss: 1.1720\n",
      "Epoch 2283/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5187 - val_loss: 1.1739\n",
      "Epoch 2284/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5082 - val_loss: 1.1470\n",
      "Epoch 2285/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4220 - val_loss: 1.1968\n",
      "Epoch 2286/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4163 - val_loss: 1.1723\n",
      "Epoch 2287/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3995 - val_loss: 1.1398\n",
      "Epoch 2288/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3971 - val_loss: 1.1601\n",
      "Epoch 2289/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5274 - val_loss: 1.1502\n",
      "Epoch 2290/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3369 - val_loss: 1.1805\n",
      "Epoch 2291/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4178 - val_loss: 1.2203\n",
      "Epoch 2292/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3427 - val_loss: 1.1644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2293/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4395 - val_loss: 1.1774\n",
      "Epoch 2294/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4246 - val_loss: 1.1723\n",
      "Epoch 2295/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5583 - val_loss: 1.1547\n",
      "Epoch 2296/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3544 - val_loss: 1.1561\n",
      "Epoch 2297/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3620 - val_loss: 1.1966\n",
      "Epoch 2298/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3841 - val_loss: 1.1722\n",
      "Epoch 2299/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5183 - val_loss: 1.1640\n",
      "Epoch 2300/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3474 - val_loss: 1.1638\n",
      "Epoch 2301/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4600 - val_loss: 1.1747\n",
      "Epoch 2302/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4166 - val_loss: 1.1716\n",
      "Epoch 2303/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3973 - val_loss: 1.1198\n",
      "Epoch 2304/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4006 - val_loss: 1.1911\n",
      "Epoch 2305/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4426 - val_loss: 1.1323\n",
      "Epoch 2306/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3701 - val_loss: 1.1965\n",
      "Epoch 2307/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4041 - val_loss: 1.1361\n",
      "Epoch 2308/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3822 - val_loss: 1.1678\n",
      "Epoch 2309/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3406 - val_loss: 1.2109\n",
      "Epoch 2310/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4319 - val_loss: 1.1362\n",
      "Epoch 2311/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3813 - val_loss: 1.1786\n",
      "Epoch 2312/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4423 - val_loss: 1.1597\n",
      "Epoch 2313/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4486 - val_loss: 1.1660\n",
      "Epoch 2314/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5918 - val_loss: 1.1853\n",
      "Epoch 2315/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4421 - val_loss: 1.1602\n",
      "Epoch 2316/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3713 - val_loss: 1.2181\n",
      "Epoch 2317/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3503 - val_loss: 1.1855\n",
      "Epoch 2318/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4238 - val_loss: 1.1679\n",
      "Epoch 2319/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3937 - val_loss: 1.2382\n",
      "Epoch 2320/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3775 - val_loss: 1.1944\n",
      "Epoch 2321/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2997 - val_loss: 1.1812\n",
      "Epoch 2322/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3453 - val_loss: 1.1697\n",
      "Epoch 2323/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3905 - val_loss: 1.1925\n",
      "Epoch 2324/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3554 - val_loss: 1.2062\n",
      "Epoch 2325/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5698 - val_loss: 1.1706\n",
      "Epoch 2326/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3753 - val_loss: 1.1814\n",
      "Epoch 2327/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3612 - val_loss: 1.1726\n",
      "Epoch 2328/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3831 - val_loss: 1.1944\n",
      "Epoch 2329/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4077 - val_loss: 1.1586\n",
      "Epoch 2330/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3986 - val_loss: 1.1768\n",
      "Epoch 2331/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3715 - val_loss: 1.1554\n",
      "Epoch 2332/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4658 - val_loss: 1.1623\n",
      "Epoch 2333/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3601 - val_loss: 1.1652\n",
      "Epoch 2334/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4157 - val_loss: 1.1788\n",
      "Epoch 2335/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3378 - val_loss: 1.1393\n",
      "Epoch 2336/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3946 - val_loss: 1.1850\n",
      "Epoch 2337/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5059 - val_loss: 1.1736\n",
      "Epoch 2338/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4545 - val_loss: 1.1865\n",
      "Epoch 2339/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4956 - val_loss: 1.1533\n",
      "Epoch 2340/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3871 - val_loss: 1.1859\n",
      "Epoch 2341/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4735 - val_loss: 1.1736\n",
      "Epoch 2342/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3653 - val_loss: 1.1723\n",
      "Epoch 2343/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4647 - val_loss: 1.2033\n",
      "Epoch 2344/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3864 - val_loss: 1.1657\n",
      "Epoch 2345/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4416 - val_loss: 1.2127\n",
      "Epoch 2346/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4196 - val_loss: 1.1916\n",
      "Epoch 2347/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4936 - val_loss: 1.1891\n",
      "Epoch 2348/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.6672 - val_loss: 1.2235\n",
      "Epoch 2349/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3676 - val_loss: 1.1622\n",
      "Epoch 2350/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3901 - val_loss: 1.2048\n",
      "Epoch 2351/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3594 - val_loss: 1.1572\n",
      "Epoch 2352/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3464 - val_loss: 1.1933\n",
      "Epoch 2353/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3877 - val_loss: 1.1798\n",
      "Epoch 2354/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3574 - val_loss: 1.1843\n",
      "Epoch 2355/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4234 - val_loss: 1.1814\n",
      "Epoch 2356/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4185 - val_loss: 1.2303\n",
      "Epoch 2357/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4604 - val_loss: 1.2031\n",
      "Epoch 2358/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4357 - val_loss: 1.1481\n",
      "Epoch 2359/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5194 - val_loss: 1.1752\n",
      "Epoch 2360/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3019 - val_loss: 1.1627\n",
      "Epoch 2361/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4616 - val_loss: 1.2506\n",
      "Epoch 2362/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4041 - val_loss: 1.1690\n",
      "Epoch 2363/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3928 - val_loss: 1.1434\n",
      "Epoch 2364/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3638 - val_loss: 1.1787\n",
      "Epoch 2365/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4881 - val_loss: 1.1846\n",
      "Epoch 2366/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3237 - val_loss: 1.1655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2367/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2569 - val_loss: 1.2116\n",
      "Epoch 2368/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4143 - val_loss: 1.1653\n",
      "Epoch 2369/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3846 - val_loss: 1.1687\n",
      "Epoch 2370/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3606 - val_loss: 1.1600\n",
      "Epoch 2371/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4453 - val_loss: 1.1458\n",
      "Epoch 2372/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5148 - val_loss: 1.1652\n",
      "Epoch 2373/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3700 - val_loss: 1.1340\n",
      "Epoch 2374/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4042 - val_loss: 1.1700\n",
      "Epoch 2375/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.2826 - val_loss: 1.1968\n",
      "Epoch 2376/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4731 - val_loss: 1.1717\n",
      "Epoch 2377/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6076 - val_loss: 1.1644\n",
      "Epoch 2378/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4054 - val_loss: 1.1831\n",
      "Epoch 2379/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3209 - val_loss: 1.1574\n",
      "Epoch 2380/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3751 - val_loss: 1.1526\n",
      "Epoch 2381/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4138 - val_loss: 1.2004\n",
      "Epoch 2382/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3240 - val_loss: 1.1387\n",
      "Epoch 2383/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3959 - val_loss: 1.1530\n",
      "Epoch 2384/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4362 - val_loss: 1.2240\n",
      "Epoch 2385/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3581 - val_loss: 1.1684\n",
      "Epoch 2386/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3643 - val_loss: 1.1325\n",
      "Epoch 2387/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3370 - val_loss: 1.1914\n",
      "Epoch 2388/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4329 - val_loss: 1.2120\n",
      "Epoch 2389/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4745 - val_loss: 1.1489\n",
      "Epoch 2390/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3743 - val_loss: 1.1797\n",
      "Epoch 2391/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3223 - val_loss: 1.1799\n",
      "Epoch 2392/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5087 - val_loss: 1.1695\n",
      "Epoch 2393/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.2818 - val_loss: 1.1756\n",
      "Epoch 2394/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3832 - val_loss: 1.1550\n",
      "Epoch 2395/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3617 - val_loss: 1.1659\n",
      "Epoch 2396/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4359 - val_loss: 1.1520\n",
      "Epoch 2397/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3277 - val_loss: 1.1706\n",
      "Epoch 2398/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4319 - val_loss: 1.1728\n",
      "Epoch 2399/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3485 - val_loss: 1.1207\n",
      "Epoch 2400/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5071 - val_loss: 1.1628\n",
      "Epoch 2401/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3578 - val_loss: 1.1649\n",
      "Epoch 2402/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3763 - val_loss: 1.1723\n",
      "Epoch 2403/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4659 - val_loss: 1.1826\n",
      "Epoch 2404/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3130 - val_loss: 1.1453\n",
      "Epoch 2405/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3154 - val_loss: 1.1775\n",
      "Epoch 2406/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4631 - val_loss: 1.1693\n",
      "Epoch 2407/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3664 - val_loss: 1.1697\n",
      "Epoch 2408/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4066 - val_loss: 1.1543\n",
      "Epoch 2409/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5289 - val_loss: 1.2195\n",
      "Epoch 2410/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5592 - val_loss: 1.1769\n",
      "Epoch 2411/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3421 - val_loss: 1.1465\n",
      "Epoch 2412/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4645 - val_loss: 1.1545\n",
      "Epoch 2413/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5220 - val_loss: 1.1765\n",
      "Epoch 2414/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3573 - val_loss: 1.1748\n",
      "Epoch 2415/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3489 - val_loss: 1.1449\n",
      "Epoch 2416/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3579 - val_loss: 1.2381\n",
      "Epoch 2417/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3999 - val_loss: 1.1793\n",
      "Epoch 2418/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4524 - val_loss: 1.1714\n",
      "Epoch 2419/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4327 - val_loss: 1.2242\n",
      "Epoch 2420/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4076 - val_loss: 1.1542\n",
      "Epoch 2421/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4517 - val_loss: 1.2148\n",
      "Epoch 2422/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4629 - val_loss: 1.2174\n",
      "Epoch 2423/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4137 - val_loss: 1.2063\n",
      "Epoch 2424/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3592 - val_loss: 1.1564\n",
      "Epoch 2425/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3149 - val_loss: 1.1534\n",
      "Epoch 2426/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3853 - val_loss: 1.1894\n",
      "Epoch 2427/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3163 - val_loss: 1.1916\n",
      "Epoch 2428/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4436 - val_loss: 1.1757\n",
      "Epoch 2429/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3420 - val_loss: 1.1962\n",
      "Epoch 2430/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4864 - val_loss: 1.1348\n",
      "Epoch 2431/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4378 - val_loss: 1.1961\n",
      "Epoch 2432/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3999 - val_loss: 1.2149\n",
      "Epoch 2433/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4469 - val_loss: 1.1955\n",
      "Epoch 2434/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4178 - val_loss: 1.1894\n",
      "Epoch 2435/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3613 - val_loss: 1.1675\n",
      "Epoch 2436/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4291 - val_loss: 1.1339\n",
      "Epoch 2437/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3891 - val_loss: 1.1624\n",
      "Epoch 2438/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4326 - val_loss: 1.1766\n",
      "Epoch 2439/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3240 - val_loss: 1.1867\n",
      "Epoch 2440/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5370 - val_loss: 1.1454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2441/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4054 - val_loss: 1.1743\n",
      "Epoch 2442/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4772 - val_loss: 1.2789\n",
      "Epoch 2443/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5222 - val_loss: 1.1889\n",
      "Epoch 2444/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3517 - val_loss: 1.1710\n",
      "Epoch 2445/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4690 - val_loss: 1.2070\n",
      "Epoch 2446/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4265 - val_loss: 1.1904\n",
      "Epoch 2447/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5005 - val_loss: 1.2151\n",
      "Epoch 2448/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4854 - val_loss: 1.2170\n",
      "Epoch 2449/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4027 - val_loss: 1.1790\n",
      "Epoch 2450/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4250 - val_loss: 1.1623\n",
      "Epoch 2451/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4161 - val_loss: 1.1589\n",
      "Epoch 2452/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3515 - val_loss: 1.1804\n",
      "Epoch 2453/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4823 - val_loss: 1.1853\n",
      "Epoch 2454/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2974 - val_loss: 1.1923\n",
      "Epoch 2455/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4984 - val_loss: 1.2059\n",
      "Epoch 2456/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3220 - val_loss: 1.1590\n",
      "Epoch 2457/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2769 - val_loss: 1.1672\n",
      "Epoch 2458/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4850 - val_loss: 1.1626\n",
      "Epoch 2459/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5758 - val_loss: 1.2387\n",
      "Epoch 2460/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4782 - val_loss: 1.1640\n",
      "Epoch 2461/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3842 - val_loss: 1.2016\n",
      "Epoch 2462/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3442 - val_loss: 1.1802\n",
      "Epoch 2463/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4221 - val_loss: 1.1555\n",
      "Epoch 2464/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4852 - val_loss: 1.1953\n",
      "Epoch 2465/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4656 - val_loss: 1.1476\n",
      "Epoch 2466/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3995 - val_loss: 1.1850\n",
      "Epoch 2467/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3235 - val_loss: 1.1512\n",
      "Epoch 2468/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3219 - val_loss: 1.1793\n",
      "Epoch 2469/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3761 - val_loss: 1.1553\n",
      "Epoch 2470/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3736 - val_loss: 1.2050\n",
      "Epoch 2471/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2901 - val_loss: 1.1764\n",
      "Epoch 2472/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4267 - val_loss: 1.1433\n",
      "Epoch 2473/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4550 - val_loss: 1.1563\n",
      "Epoch 2474/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4401 - val_loss: 1.2006\n",
      "Epoch 2475/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3028 - val_loss: 1.1368\n",
      "Epoch 2476/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3673 - val_loss: 1.1827\n",
      "Epoch 2477/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4028 - val_loss: 1.1978\n",
      "Epoch 2478/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4628 - val_loss: 1.2134\n",
      "Epoch 2479/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5044 - val_loss: 1.1960\n",
      "Epoch 2480/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4090 - val_loss: 1.1489\n",
      "Epoch 2481/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5042 - val_loss: 1.1672\n",
      "Epoch 2482/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4122 - val_loss: 1.1642\n",
      "Epoch 2483/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3738 - val_loss: 1.2336\n",
      "Epoch 2484/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3569 - val_loss: 1.1544\n",
      "Epoch 2485/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3987 - val_loss: 1.1615\n",
      "Epoch 2486/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3838 - val_loss: 1.1697\n",
      "Epoch 2487/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4172 - val_loss: 1.1794\n",
      "Epoch 2488/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3647 - val_loss: 1.2076\n",
      "Epoch 2489/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3972 - val_loss: 1.1954\n",
      "Epoch 2490/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3765 - val_loss: 1.1813\n",
      "Epoch 2491/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4861 - val_loss: 1.1447\n",
      "Epoch 2492/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.3869 - val_loss: 1.1911\n",
      "Epoch 2493/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3988 - val_loss: 1.1844\n",
      "Epoch 2494/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4680 - val_loss: 1.1852\n",
      "Epoch 2495/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4179 - val_loss: 1.1869\n",
      "Epoch 2496/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4189 - val_loss: 1.1920\n",
      "Epoch 2497/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4096 - val_loss: 1.1532\n",
      "Epoch 2498/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2935 - val_loss: 1.1697\n",
      "Epoch 2499/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4307 - val_loss: 1.1679\n",
      "Epoch 2500/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3438 - val_loss: 1.2155\n",
      "Epoch 2501/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5111 - val_loss: 1.2363\n",
      "Epoch 2502/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2911 - val_loss: 1.1578\n",
      "Epoch 2503/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4907 - val_loss: 1.1732\n",
      "Epoch 2504/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3564 - val_loss: 1.1781\n",
      "Epoch 2505/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3598 - val_loss: 1.1372\n",
      "Epoch 2506/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3053 - val_loss: 1.1841\n",
      "Epoch 2507/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3687 - val_loss: 1.1582\n",
      "Epoch 2508/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5141 - val_loss: 1.1679\n",
      "Epoch 2509/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4683 - val_loss: 1.1783\n",
      "Epoch 2510/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3803 - val_loss: 1.2242\n",
      "Epoch 2511/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3567 - val_loss: 1.1601\n",
      "Epoch 2512/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3715 - val_loss: 1.1632\n",
      "Epoch 2513/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2666 - val_loss: 1.1650\n",
      "Epoch 2514/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3540 - val_loss: 1.1439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2515/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3818 - val_loss: 1.1892\n",
      "Epoch 2516/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4428 - val_loss: 1.1917\n",
      "Epoch 2517/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3332 - val_loss: 1.1785\n",
      "Epoch 2518/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3371 - val_loss: 1.1595\n",
      "Epoch 2519/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4145 - val_loss: 1.1531\n",
      "Epoch 2520/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3528 - val_loss: 1.1620\n",
      "Epoch 2521/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4269 - val_loss: 1.2021\n",
      "Epoch 2522/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4110 - val_loss: 1.1782\n",
      "Epoch 2523/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4248 - val_loss: 1.1660\n",
      "Epoch 2524/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3548 - val_loss: 1.1470\n",
      "Epoch 2525/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4337 - val_loss: 1.1773\n",
      "Epoch 2526/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3900 - val_loss: 1.1716\n",
      "Epoch 2527/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4112 - val_loss: 1.1689\n",
      "Epoch 2528/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3860 - val_loss: 1.1738\n",
      "Epoch 2529/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3666 - val_loss: 1.1544\n",
      "Epoch 2530/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5029 - val_loss: 1.1984\n",
      "Epoch 2531/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3479 - val_loss: 1.1269\n",
      "Epoch 2532/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4843 - val_loss: 1.2275\n",
      "Epoch 2533/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3975 - val_loss: 1.1661\n",
      "Epoch 2534/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3591 - val_loss: 1.1572\n",
      "Epoch 2535/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3847 - val_loss: 1.1850\n",
      "Epoch 2536/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2557 - val_loss: 1.1629\n",
      "Epoch 2537/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2805 - val_loss: 1.1812\n",
      "Epoch 2538/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3475 - val_loss: 1.1577\n",
      "Epoch 2539/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3742 - val_loss: 1.1732\n",
      "Epoch 2540/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4187 - val_loss: 1.1952\n",
      "Epoch 2541/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4297 - val_loss: 1.1859\n",
      "Epoch 2542/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3469 - val_loss: 1.1827\n",
      "Epoch 2543/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3717 - val_loss: 1.1700\n",
      "Epoch 2544/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3890 - val_loss: 1.2193\n",
      "Epoch 2545/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3121 - val_loss: 1.1816\n",
      "Epoch 2546/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.2877 - val_loss: 1.1867\n",
      "Epoch 2547/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3995 - val_loss: 1.1729\n",
      "Epoch 2548/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4297 - val_loss: 1.1758\n",
      "Epoch 2549/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4699 - val_loss: 1.1508\n",
      "Epoch 2550/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4200 - val_loss: 1.1598\n",
      "Epoch 2551/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3972 - val_loss: 1.1565\n",
      "Epoch 2552/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4013 - val_loss: 1.1942\n",
      "Epoch 2553/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4374 - val_loss: 1.1915\n",
      "Epoch 2554/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4495 - val_loss: 1.1741\n",
      "Epoch 2555/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3601 - val_loss: 1.2467\n",
      "Epoch 2556/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5295 - val_loss: 1.2028\n",
      "Epoch 2557/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3975 - val_loss: 1.1586\n",
      "Epoch 2558/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3947 - val_loss: 1.1609\n",
      "Epoch 2559/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3143 - val_loss: 1.1976\n",
      "Epoch 2560/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4126 - val_loss: 1.1491\n",
      "Epoch 2561/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3725 - val_loss: 1.1619\n",
      "Epoch 2562/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3909 - val_loss: 1.1898\n",
      "Epoch 2563/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.5039 - val_loss: 1.2014\n",
      "Epoch 2564/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4462 - val_loss: 1.1405\n",
      "Epoch 2565/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4494 - val_loss: 1.1466\n",
      "Epoch 2566/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3481 - val_loss: 1.1571\n",
      "Epoch 2567/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4633 - val_loss: 1.1737\n",
      "Epoch 2568/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4652 - val_loss: 1.2181\n",
      "Epoch 2569/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4138 - val_loss: 1.1532\n",
      "Epoch 2570/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3371 - val_loss: 1.1669\n",
      "Epoch 2571/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3599 - val_loss: 1.1585\n",
      "Epoch 2572/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3679 - val_loss: 1.2010\n",
      "Epoch 2573/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4836 - val_loss: 1.1830\n",
      "Epoch 2574/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4130 - val_loss: 1.1958\n",
      "Epoch 2575/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4775 - val_loss: 1.1888\n",
      "Epoch 2576/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3947 - val_loss: 1.1395\n",
      "Epoch 2577/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3774 - val_loss: 1.1761\n",
      "Epoch 2578/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3754 - val_loss: 1.1801\n",
      "Epoch 2579/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3010 - val_loss: 1.1361\n",
      "Epoch 2580/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3260 - val_loss: 1.1564\n",
      "Epoch 2581/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3345 - val_loss: 1.1607\n",
      "Epoch 2582/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3351 - val_loss: 1.1888\n",
      "Epoch 2583/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3600 - val_loss: 1.1739\n",
      "Epoch 2584/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5017 - val_loss: 1.1744\n",
      "Epoch 2585/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4382 - val_loss: 1.1596\n",
      "Epoch 2586/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6053 - val_loss: 1.1813\n",
      "Epoch 2587/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3439 - val_loss: 1.1474\n",
      "Epoch 2588/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4889 - val_loss: 1.1871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2589/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4350 - val_loss: 1.1739\n",
      "Epoch 2590/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4137 - val_loss: 1.1791\n",
      "Epoch 2591/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4374 - val_loss: 1.1808\n",
      "Epoch 2592/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3993 - val_loss: 1.1936\n",
      "Epoch 2593/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3548 - val_loss: 1.1345\n",
      "Epoch 2594/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3599 - val_loss: 1.1521\n",
      "Epoch 2595/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3019 - val_loss: 1.1815\n",
      "Epoch 2596/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5213 - val_loss: 1.1470\n",
      "Epoch 2597/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4331 - val_loss: 1.1961\n",
      "Epoch 2598/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4976 - val_loss: 1.1718\n",
      "Epoch 2599/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4408 - val_loss: 1.1718\n",
      "Epoch 2600/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3546 - val_loss: 1.1577\n",
      "Epoch 2601/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4849 - val_loss: 1.1913\n",
      "Epoch 2602/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4131 - val_loss: 1.1558\n",
      "Epoch 2603/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3287 - val_loss: 1.1695\n",
      "Epoch 2604/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4317 - val_loss: 1.1307\n",
      "Epoch 2605/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2668 - val_loss: 1.1703\n",
      "Epoch 2606/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4632 - val_loss: 1.1256\n",
      "Epoch 2607/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4357 - val_loss: 1.2180\n",
      "Epoch 2608/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3810 - val_loss: 1.1367\n",
      "Epoch 2609/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5127 - val_loss: 1.1621\n",
      "Epoch 2610/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4950 - val_loss: 1.2107\n",
      "Epoch 2611/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4509 - val_loss: 1.1598\n",
      "Epoch 2612/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5101 - val_loss: 1.1715\n",
      "Epoch 2613/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3683 - val_loss: 1.1666\n",
      "Epoch 2614/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3763 - val_loss: 1.1437\n",
      "Epoch 2615/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3816 - val_loss: 1.1752\n",
      "Epoch 2616/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3583 - val_loss: 1.1470\n",
      "Epoch 2617/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4412 - val_loss: 1.1857\n",
      "Epoch 2618/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3384 - val_loss: 1.2083\n",
      "Epoch 2619/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4590 - val_loss: 1.2241\n",
      "Epoch 2620/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4492 - val_loss: 1.1700\n",
      "Epoch 2621/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2719 - val_loss: 1.1705\n",
      "Epoch 2622/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5631 - val_loss: 1.1862\n",
      "Epoch 2623/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4370 - val_loss: 1.1627\n",
      "Epoch 2624/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4138 - val_loss: 1.1761\n",
      "Epoch 2625/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4642 - val_loss: 1.1583\n",
      "Epoch 2626/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4434 - val_loss: 1.1642\n",
      "Epoch 2627/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3647 - val_loss: 1.1764\n",
      "Epoch 2628/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3753 - val_loss: 1.1546\n",
      "Epoch 2629/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3473 - val_loss: 1.1770\n",
      "Epoch 2630/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4862 - val_loss: 1.1604\n",
      "Epoch 2631/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4108 - val_loss: 1.1988\n",
      "Epoch 2632/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5379 - val_loss: 1.1885\n",
      "Epoch 2633/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3748 - val_loss: 1.1860\n",
      "Epoch 2634/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3137 - val_loss: 1.1890\n",
      "Epoch 2635/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4035 - val_loss: 1.1762\n",
      "Epoch 2636/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4091 - val_loss: 1.1958\n",
      "Epoch 2637/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3551 - val_loss: 1.1936\n",
      "Epoch 2638/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3722 - val_loss: 1.1648\n",
      "Epoch 2639/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4372 - val_loss: 1.1682\n",
      "Epoch 2640/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4684 - val_loss: 1.1898\n",
      "Epoch 2641/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4171 - val_loss: 1.1382\n",
      "Epoch 2642/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4334 - val_loss: 1.1530\n",
      "Epoch 2643/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3288 - val_loss: 1.1548\n",
      "Epoch 2644/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3048 - val_loss: 1.1694\n",
      "Epoch 2645/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4949 - val_loss: 1.1464\n",
      "Epoch 2646/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3752 - val_loss: 1.1958\n",
      "Epoch 2647/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4031 - val_loss: 1.1510\n",
      "Epoch 2648/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3976 - val_loss: 1.2228\n",
      "Epoch 2649/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3468 - val_loss: 1.1571\n",
      "Epoch 2650/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5167 - val_loss: 1.1709\n",
      "Epoch 2651/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3401 - val_loss: 1.2079\n",
      "Epoch 2652/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3859 - val_loss: 1.1644\n",
      "Epoch 2653/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4695 - val_loss: 1.1829\n",
      "Epoch 2654/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4749 - val_loss: 1.1800\n",
      "Epoch 2655/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4487 - val_loss: 1.1685\n",
      "Epoch 2656/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3582 - val_loss: 1.1466\n",
      "Epoch 2657/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.2891 - val_loss: 1.1423\n",
      "Epoch 2658/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4598 - val_loss: 1.1567\n",
      "Epoch 2659/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4776 - val_loss: 1.1802\n",
      "Epoch 2660/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3679 - val_loss: 1.1500\n",
      "Epoch 2661/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5231 - val_loss: 1.1571\n",
      "Epoch 2662/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4512 - val_loss: 1.1491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2663/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3391 - val_loss: 1.1775\n",
      "Epoch 2664/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4213 - val_loss: 1.1725\n",
      "Epoch 2665/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3312 - val_loss: 1.2229\n",
      "Epoch 2666/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3634 - val_loss: 1.1630\n",
      "Epoch 2667/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3646 - val_loss: 1.2007\n",
      "Epoch 2668/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5083 - val_loss: 1.1876\n",
      "Epoch 2669/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4169 - val_loss: 1.1924\n",
      "Epoch 2670/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4135 - val_loss: 1.1731\n",
      "Epoch 2671/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4654 - val_loss: 1.1603\n",
      "Epoch 2672/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4969 - val_loss: 1.1928\n",
      "Epoch 2673/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3956 - val_loss: 1.1934\n",
      "Epoch 2674/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3565 - val_loss: 1.1544\n",
      "Epoch 2675/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3991 - val_loss: 1.1814\n",
      "Epoch 2676/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3975 - val_loss: 1.1976\n",
      "Epoch 2677/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4159 - val_loss: 1.2023\n",
      "Epoch 2678/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3175 - val_loss: 1.1602\n",
      "Epoch 2679/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5079 - val_loss: 1.1817\n",
      "Epoch 2680/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3751 - val_loss: 1.1994\n",
      "Epoch 2681/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3511 - val_loss: 1.2270\n",
      "Epoch 2682/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3347 - val_loss: 1.1714\n",
      "Epoch 2683/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4186 - val_loss: 1.2537\n",
      "Epoch 2684/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2774 - val_loss: 1.1621\n",
      "Epoch 2685/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5296 - val_loss: 1.2177\n",
      "Epoch 2686/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4139 - val_loss: 1.1694\n",
      "Epoch 2687/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3981 - val_loss: 1.1827\n",
      "Epoch 2688/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3998 - val_loss: 1.2309\n",
      "Epoch 2689/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4395 - val_loss: 1.1965\n",
      "Epoch 2690/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4147 - val_loss: 1.1908\n",
      "Epoch 2691/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5039 - val_loss: 1.1834\n",
      "Epoch 2692/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3978 - val_loss: 1.1672\n",
      "Epoch 2693/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3727 - val_loss: 1.1794\n",
      "Epoch 2694/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3610 - val_loss: 1.1972\n",
      "Epoch 2695/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4097 - val_loss: 1.1776\n",
      "Epoch 2696/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5122 - val_loss: 1.2383\n",
      "Epoch 2697/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3973 - val_loss: 1.1735\n",
      "Epoch 2698/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3548 - val_loss: 1.1721\n",
      "Epoch 2699/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4097 - val_loss: 1.1776\n",
      "Epoch 2700/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3451 - val_loss: 1.1564\n",
      "Epoch 2701/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3591 - val_loss: 1.1813\n",
      "Epoch 2702/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3107 - val_loss: 1.1795\n",
      "Epoch 2703/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3516 - val_loss: 1.1630\n",
      "Epoch 2704/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5615 - val_loss: 1.2489\n",
      "Epoch 2705/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5589 - val_loss: 1.1583\n",
      "Epoch 2706/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4339 - val_loss: 1.1881\n",
      "Epoch 2707/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4026 - val_loss: 1.1815\n",
      "Epoch 2708/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4424 - val_loss: 1.2016\n",
      "Epoch 2709/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4401 - val_loss: 1.1690\n",
      "Epoch 2710/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2804 - val_loss: 1.1325\n",
      "Epoch 2711/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5151 - val_loss: 1.2216\n",
      "Epoch 2712/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5619 - val_loss: 1.1455\n",
      "Epoch 2713/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3699 - val_loss: 1.1818\n",
      "Epoch 2714/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4411 - val_loss: 1.2188\n",
      "Epoch 2715/20000\n",
      "1500/1500 [==============================] - 0s 44us/sample - loss: 1.4080 - val_loss: 1.1373\n",
      "Epoch 2716/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3696 - val_loss: 1.1763\n",
      "Epoch 2717/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4066 - val_loss: 1.1477\n",
      "Epoch 2718/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2620 - val_loss: 1.2005\n",
      "Epoch 2719/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3847 - val_loss: 1.1860\n",
      "Epoch 2720/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3950 - val_loss: 1.1664\n",
      "Epoch 2721/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4645 - val_loss: 1.1493\n",
      "Epoch 2722/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4047 - val_loss: 1.2007\n",
      "Epoch 2723/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3795 - val_loss: 1.1475\n",
      "Epoch 2724/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4541 - val_loss: 1.1299\n",
      "Epoch 2725/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4797 - val_loss: 1.1604\n",
      "Epoch 2726/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5809 - val_loss: 1.1439\n",
      "Epoch 2727/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4090 - val_loss: 1.1683\n",
      "Epoch 2728/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4021 - val_loss: 1.1475\n",
      "Epoch 2729/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3390 - val_loss: 1.1593\n",
      "Epoch 2730/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3398 - val_loss: 1.1869\n",
      "Epoch 2731/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3343 - val_loss: 1.1591\n",
      "Epoch 2732/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3693 - val_loss: 1.1389\n",
      "Epoch 2733/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4351 - val_loss: 1.1671\n",
      "Epoch 2734/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4830 - val_loss: 1.1591\n",
      "Epoch 2735/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3925 - val_loss: 1.1301\n",
      "Epoch 2736/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4268 - val_loss: 1.1320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2737/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4066 - val_loss: 1.1561\n",
      "Epoch 2738/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3454 - val_loss: 1.1588\n",
      "Epoch 2739/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3261 - val_loss: 1.1668\n",
      "Epoch 2740/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5007 - val_loss: 1.1994\n",
      "Epoch 2741/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3339 - val_loss: 1.1683\n",
      "Epoch 2742/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3554 - val_loss: 1.2028\n",
      "Epoch 2743/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4159 - val_loss: 1.2029\n",
      "Epoch 2744/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4471 - val_loss: 1.1644\n",
      "Epoch 2745/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3503 - val_loss: 1.2223\n",
      "Epoch 2746/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3644 - val_loss: 1.1691\n",
      "Epoch 2747/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4415 - val_loss: 1.1743\n",
      "Epoch 2748/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2732 - val_loss: 1.1706\n",
      "Epoch 2749/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3631 - val_loss: 1.2125\n",
      "Epoch 2750/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4616 - val_loss: 1.1779\n",
      "Epoch 2751/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4855 - val_loss: 1.1392\n",
      "Epoch 2752/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3852 - val_loss: 1.1823\n",
      "Epoch 2753/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3915 - val_loss: 1.1749\n",
      "Epoch 2754/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3458 - val_loss: 1.1427\n",
      "Epoch 2755/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4508 - val_loss: 1.1561\n",
      "Epoch 2756/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4307 - val_loss: 1.1472\n",
      "Epoch 2757/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4828 - val_loss: 1.1497\n",
      "Epoch 2758/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4326 - val_loss: 1.1440\n",
      "Epoch 2759/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4656 - val_loss: 1.1179\n",
      "Epoch 2760/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4134 - val_loss: 1.1427\n",
      "Epoch 2761/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4393 - val_loss: 1.1371\n",
      "Epoch 2762/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3907 - val_loss: 1.1436\n",
      "Epoch 2763/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4393 - val_loss: 1.1470\n",
      "Epoch 2764/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3379 - val_loss: 1.1328\n",
      "Epoch 2765/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2891 - val_loss: 1.1280\n",
      "Epoch 2766/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3538 - val_loss: 1.1631\n",
      "Epoch 2767/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5641 - val_loss: 1.1661\n",
      "Epoch 2768/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4631 - val_loss: 1.1559\n",
      "Epoch 2769/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3627 - val_loss: 1.1624\n",
      "Epoch 2770/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3212 - val_loss: 1.1971\n",
      "Epoch 2771/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4537 - val_loss: 1.1523\n",
      "Epoch 2772/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3864 - val_loss: 1.1539\n",
      "Epoch 2773/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4980 - val_loss: 1.1811\n",
      "Epoch 2774/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4196 - val_loss: 1.1639\n",
      "Epoch 2775/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3786 - val_loss: 1.1841\n",
      "Epoch 2776/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3693 - val_loss: 1.1335\n",
      "Epoch 2777/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3431 - val_loss: 1.1560\n",
      "Epoch 2778/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3824 - val_loss: 1.1817\n",
      "Epoch 2779/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3805 - val_loss: 1.1949\n",
      "Epoch 2780/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4573 - val_loss: 1.2410\n",
      "Epoch 2781/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3150 - val_loss: 1.1767\n",
      "Epoch 2782/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3994 - val_loss: 1.2261\n",
      "Epoch 2783/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4415 - val_loss: 1.2141\n",
      "Epoch 2784/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3579 - val_loss: 1.1570\n",
      "Epoch 2785/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4796 - val_loss: 1.2421\n",
      "Epoch 2786/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4210 - val_loss: 1.2330\n",
      "Epoch 2787/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4067 - val_loss: 1.2968\n",
      "Epoch 2788/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3981 - val_loss: 1.2162\n",
      "Epoch 2789/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3300 - val_loss: 1.2287\n",
      "Epoch 2790/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4306 - val_loss: 1.1933\n",
      "Epoch 2791/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4730 - val_loss: 1.2232\n",
      "Epoch 2792/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3477 - val_loss: 1.1782\n",
      "Epoch 2793/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4553 - val_loss: 1.1690\n",
      "Epoch 2794/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4370 - val_loss: 1.1234\n",
      "Epoch 2795/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5468 - val_loss: 1.1354\n",
      "Epoch 2796/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3787 - val_loss: 1.1265\n",
      "Epoch 2797/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4733 - val_loss: 1.1564\n",
      "Epoch 2798/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3582 - val_loss: 1.1469\n",
      "Epoch 2799/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3637 - val_loss: 1.1556\n",
      "Epoch 2800/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3957 - val_loss: 1.1447\n",
      "Epoch 2801/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3928 - val_loss: 1.1812\n",
      "Epoch 2802/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4357 - val_loss: 1.1394\n",
      "Epoch 2803/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4011 - val_loss: 1.2147\n",
      "Epoch 2804/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4036 - val_loss: 1.1369\n",
      "Epoch 2805/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3767 - val_loss: 1.1455\n",
      "Epoch 2806/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4855 - val_loss: 1.1459\n",
      "Epoch 2807/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4854 - val_loss: 1.1326\n",
      "Epoch 2808/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3554 - val_loss: 1.1597\n",
      "Epoch 2809/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3896 - val_loss: 1.1477\n",
      "Epoch 2810/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3397 - val_loss: 1.1878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2811/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3709 - val_loss: 1.1632\n",
      "Epoch 2812/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6096 - val_loss: 1.1439\n",
      "Epoch 2813/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4783 - val_loss: 1.1920\n",
      "Epoch 2814/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3190 - val_loss: 1.1379\n",
      "Epoch 2815/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4047 - val_loss: 1.1564\n",
      "Epoch 2816/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4536 - val_loss: 1.1732\n",
      "Epoch 2817/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4031 - val_loss: 1.1776\n",
      "Epoch 2818/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3811 - val_loss: 1.1578\n",
      "Epoch 2819/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4117 - val_loss: 1.1610\n",
      "Epoch 2820/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3502 - val_loss: 1.1455\n",
      "Epoch 2821/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3656 - val_loss: 1.1767\n",
      "Epoch 2822/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3285 - val_loss: 1.1427\n",
      "Epoch 2823/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4160 - val_loss: 1.1449\n",
      "Epoch 2824/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5182 - val_loss: 1.1915\n",
      "Epoch 2825/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4571 - val_loss: 1.1419\n",
      "Epoch 2826/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4260 - val_loss: 1.1525\n",
      "Epoch 2827/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.2557 - val_loss: 1.1775\n",
      "Epoch 2828/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4377 - val_loss: 1.1445\n",
      "Epoch 2829/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4631 - val_loss: 1.1296\n",
      "Epoch 2830/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4654 - val_loss: 1.1521\n",
      "Epoch 2831/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4884 - val_loss: 1.1566\n",
      "Epoch 2832/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4114 - val_loss: 1.1542\n",
      "Epoch 2833/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4090 - val_loss: 1.1355\n",
      "Epoch 2834/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4248 - val_loss: 1.1585\n",
      "Epoch 2835/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3592 - val_loss: 1.1572\n",
      "Epoch 2836/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3667 - val_loss: 1.1429\n",
      "Epoch 2837/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4793 - val_loss: 1.1448\n",
      "Epoch 2838/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3691 - val_loss: 1.1324\n",
      "Epoch 2839/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5651 - val_loss: 1.1226\n",
      "Epoch 2840/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3698 - val_loss: 1.1683\n",
      "Epoch 2841/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3684 - val_loss: 1.1550\n",
      "Epoch 2842/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4447 - val_loss: 1.1598\n",
      "Epoch 2843/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4883 - val_loss: 1.1553\n",
      "Epoch 2844/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3574 - val_loss: 1.1856\n",
      "Epoch 2845/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3591 - val_loss: 1.1522\n",
      "Epoch 2846/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3764 - val_loss: 1.1839\n",
      "Epoch 2847/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4181 - val_loss: 1.1590\n",
      "Epoch 2848/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3342 - val_loss: 1.1728\n",
      "Epoch 2849/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4177 - val_loss: 1.1995\n",
      "Epoch 2850/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4948 - val_loss: 1.2405\n",
      "Epoch 2851/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3596 - val_loss: 1.1475\n",
      "Epoch 2852/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2731 - val_loss: 1.1730\n",
      "Epoch 2853/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4145 - val_loss: 1.1627\n",
      "Epoch 2854/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4875 - val_loss: 1.2744\n",
      "Epoch 2855/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2997 - val_loss: 1.2439\n",
      "Epoch 2856/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3592 - val_loss: 1.2158\n",
      "Epoch 2857/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3774 - val_loss: 1.2331\n",
      "Epoch 2858/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3237 - val_loss: 1.2697\n",
      "Epoch 2859/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4027 - val_loss: 1.2099\n",
      "Epoch 2860/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3498 - val_loss: 1.1693\n",
      "Epoch 2861/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3220 - val_loss: 1.2106\n",
      "Epoch 2862/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3381 - val_loss: 1.2128\n",
      "Epoch 2863/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3979 - val_loss: 1.2048\n",
      "Epoch 2864/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4615 - val_loss: 1.1982\n",
      "Epoch 2865/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4959 - val_loss: 1.2945\n",
      "Epoch 2866/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4385 - val_loss: 1.2803\n",
      "Epoch 2867/20000\n",
      "1500/1500 [==============================] - 0s 44us/sample - loss: 1.3947 - val_loss: 1.1981\n",
      "Epoch 2868/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3677 - val_loss: 1.1633\n",
      "Epoch 2869/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3590 - val_loss: 1.1653\n",
      "Epoch 2870/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3235 - val_loss: 1.1717\n",
      "Epoch 2871/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4132 - val_loss: 1.1631\n",
      "Epoch 2872/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4259 - val_loss: 1.1671\n",
      "Epoch 2873/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3342 - val_loss: 1.1495\n",
      "Epoch 2874/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.4369 - val_loss: 1.1884\n",
      "Epoch 2875/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3538 - val_loss: 1.1597\n",
      "Epoch 2876/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3913 - val_loss: 1.2117\n",
      "Epoch 2877/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3776 - val_loss: 1.1820\n",
      "Epoch 2878/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3731 - val_loss: 1.1351\n",
      "Epoch 2879/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3861 - val_loss: 1.1738\n",
      "Epoch 2880/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5641 - val_loss: 1.1846\n",
      "Epoch 2881/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3330 - val_loss: 1.1696\n",
      "Epoch 2882/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4644 - val_loss: 1.2208\n",
      "Epoch 2883/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.2948 - val_loss: 1.1699\n",
      "Epoch 2884/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3471 - val_loss: 1.1830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2885/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4684 - val_loss: 1.2022\n",
      "Epoch 2886/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4842 - val_loss: 1.1404\n",
      "Epoch 2887/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4473 - val_loss: 1.1817\n",
      "Epoch 2888/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3990 - val_loss: 1.1610\n",
      "Epoch 2889/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3798 - val_loss: 1.1491\n",
      "Epoch 2890/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4536 - val_loss: 1.1447\n",
      "Epoch 2891/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4088 - val_loss: 1.1924\n",
      "Epoch 2892/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3105 - val_loss: 1.1913\n",
      "Epoch 2893/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4477 - val_loss: 1.1465\n",
      "Epoch 2894/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3243 - val_loss: 1.1917\n",
      "Epoch 2895/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3587 - val_loss: 1.2265\n",
      "Epoch 2896/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3475 - val_loss: 1.2170\n",
      "Epoch 2897/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3366 - val_loss: 1.1400\n",
      "Epoch 2898/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4072 - val_loss: 1.1586\n",
      "Epoch 2899/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3687 - val_loss: 1.2020\n",
      "Epoch 2900/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4423 - val_loss: 1.2045\n",
      "Epoch 2901/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3541 - val_loss: 1.1506\n",
      "Epoch 2902/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3379 - val_loss: 1.1752\n",
      "Epoch 2903/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3804 - val_loss: 1.1546\n",
      "Epoch 2904/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5204 - val_loss: 1.2197\n",
      "Epoch 2905/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3676 - val_loss: 1.1548\n",
      "Epoch 2906/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4545 - val_loss: 1.1769\n",
      "Epoch 2907/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4697 - val_loss: 1.2767\n",
      "Epoch 2908/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4096 - val_loss: 1.1970\n",
      "Epoch 2909/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3516 - val_loss: 1.2012\n",
      "Epoch 2910/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3061 - val_loss: 1.2047\n",
      "Epoch 2911/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4192 - val_loss: 1.2104\n",
      "Epoch 2912/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4184 - val_loss: 1.1905\n",
      "Epoch 2913/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4276 - val_loss: 1.2053\n",
      "Epoch 2914/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4793 - val_loss: 1.1696\n",
      "Epoch 2915/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3395 - val_loss: 1.1767\n",
      "Epoch 2916/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3650 - val_loss: 1.1611\n",
      "Epoch 2917/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4101 - val_loss: 1.1670\n",
      "Epoch 2918/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3472 - val_loss: 1.1337\n",
      "Epoch 2919/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4335 - val_loss: 1.1729\n",
      "Epoch 2920/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4217 - val_loss: 1.1563\n",
      "Epoch 2921/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4387 - val_loss: 1.1775\n",
      "Epoch 2922/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4181 - val_loss: 1.1658\n",
      "Epoch 2923/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3388 - val_loss: 1.2167\n",
      "Epoch 2924/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4275 - val_loss: 1.1919\n",
      "Epoch 2925/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3500 - val_loss: 1.1808\n",
      "Epoch 2926/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3734 - val_loss: 1.1901\n",
      "Epoch 2927/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3829 - val_loss: 1.1434\n",
      "Epoch 2928/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3506 - val_loss: 1.2201\n",
      "Epoch 2929/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4365 - val_loss: 1.1816\n",
      "Epoch 2930/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3076 - val_loss: 1.2079\n",
      "Epoch 2931/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4183 - val_loss: 1.1634\n",
      "Epoch 2932/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4083 - val_loss: 1.1766\n",
      "Epoch 2933/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3242 - val_loss: 1.1507\n",
      "Epoch 2934/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4682 - val_loss: 1.1554\n",
      "Epoch 2935/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3914 - val_loss: 1.1329\n",
      "Epoch 2936/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3470 - val_loss: 1.1791\n",
      "Epoch 2937/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3279 - val_loss: 1.1788\n",
      "Epoch 2938/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3333 - val_loss: 1.1828\n",
      "Epoch 2939/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3822 - val_loss: 1.2379\n",
      "Epoch 2940/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4252 - val_loss: 1.2211\n",
      "Epoch 2941/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3658 - val_loss: 1.2325\n",
      "Epoch 2942/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3197 - val_loss: 1.1907\n",
      "Epoch 2943/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4310 - val_loss: 1.2112\n",
      "Epoch 2944/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3454 - val_loss: 1.1789\n",
      "Epoch 2945/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3712 - val_loss: 1.1783\n",
      "Epoch 2946/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3471 - val_loss: 1.1843\n",
      "Epoch 2947/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4255 - val_loss: 1.2059\n",
      "Epoch 2948/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5560 - val_loss: 1.2064\n",
      "Epoch 2949/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2908 - val_loss: 1.1704\n",
      "Epoch 2950/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3690 - val_loss: 1.1400\n",
      "Epoch 2951/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3661 - val_loss: 1.1974\n",
      "Epoch 2952/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4636 - val_loss: 1.1993\n",
      "Epoch 2953/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3870 - val_loss: 1.2064\n",
      "Epoch 2954/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4787 - val_loss: 1.1501\n",
      "Epoch 2955/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5096 - val_loss: 1.1853\n",
      "Epoch 2956/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5182 - val_loss: 1.1453\n",
      "Epoch 2957/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4642 - val_loss: 1.1546\n",
      "Epoch 2958/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3883 - val_loss: 1.1271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2959/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3335 - val_loss: 1.1580\n",
      "Epoch 2960/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4759 - val_loss: 1.1591\n",
      "Epoch 2961/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4533 - val_loss: 1.1649\n",
      "Epoch 2962/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3440 - val_loss: 1.2641\n",
      "Epoch 2963/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4463 - val_loss: 1.1547\n",
      "Epoch 2964/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4004 - val_loss: 1.1692\n",
      "Epoch 2965/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3712 - val_loss: 1.1854\n",
      "Epoch 2966/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3505 - val_loss: 1.2035\n",
      "Epoch 2967/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3267 - val_loss: 1.1644\n",
      "Epoch 2968/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5151 - val_loss: 1.2295\n",
      "Epoch 2969/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3188 - val_loss: 1.1972\n",
      "Epoch 2970/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4135 - val_loss: 1.2161\n",
      "Epoch 2971/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2550 - val_loss: 1.1493\n",
      "Epoch 2972/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3436 - val_loss: 1.2086\n",
      "Epoch 2973/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4204 - val_loss: 1.1943\n",
      "Epoch 2974/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3318 - val_loss: 1.1999\n",
      "Epoch 2975/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4288 - val_loss: 1.2078\n",
      "Epoch 2976/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3725 - val_loss: 1.1668\n",
      "Epoch 2977/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3268 - val_loss: 1.1876\n",
      "Epoch 2978/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5537 - val_loss: 1.2462\n",
      "Epoch 2979/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4476 - val_loss: 1.1521\n",
      "Epoch 2980/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3448 - val_loss: 1.1899\n",
      "Epoch 2981/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2671 - val_loss: 1.1633\n",
      "Epoch 2982/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3998 - val_loss: 1.1957\n",
      "Epoch 2983/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3191 - val_loss: 1.1835\n",
      "Epoch 2984/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3931 - val_loss: 1.1618\n",
      "Epoch 2985/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5590 - val_loss: 1.2218\n",
      "Epoch 2986/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4956 - val_loss: 1.1871\n",
      "Epoch 2987/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3704 - val_loss: 1.1570\n",
      "Epoch 2988/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3707 - val_loss: 1.1653\n",
      "Epoch 2989/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3652 - val_loss: 1.2062\n",
      "Epoch 2990/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3770 - val_loss: 1.1417\n",
      "Epoch 2991/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3342 - val_loss: 1.1993\n",
      "Epoch 2992/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3794 - val_loss: 1.1438\n",
      "Epoch 2993/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5450 - val_loss: 1.1623\n",
      "Epoch 2994/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4682 - val_loss: 1.1496\n",
      "Epoch 2995/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3559 - val_loss: 1.1493\n",
      "Epoch 2996/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4206 - val_loss: 1.1521\n",
      "Epoch 2997/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3896 - val_loss: 1.2132\n",
      "Epoch 2998/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4464 - val_loss: 1.1603\n",
      "Epoch 2999/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4829 - val_loss: 1.2372\n",
      "Epoch 3000/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4041 - val_loss: 1.1482\n",
      "Epoch 3001/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4466 - val_loss: 1.1539\n",
      "Epoch 3002/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4437 - val_loss: 1.1895\n",
      "Epoch 3003/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3640 - val_loss: 1.1529\n",
      "Epoch 3004/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4152 - val_loss: 1.1746\n",
      "Epoch 3005/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3880 - val_loss: 1.2185\n",
      "Epoch 3006/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4304 - val_loss: 1.1303\n",
      "Epoch 3007/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3695 - val_loss: 1.1984\n",
      "Epoch 3008/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3652 - val_loss: 1.2018\n",
      "Epoch 3009/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3733 - val_loss: 1.1724\n",
      "Epoch 3010/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3409 - val_loss: 1.1929\n",
      "Epoch 3011/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4303 - val_loss: 1.1331\n",
      "Epoch 3012/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3572 - val_loss: 1.1657\n",
      "Epoch 3013/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3472 - val_loss: 1.1675\n",
      "Epoch 3014/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3987 - val_loss: 1.1703\n",
      "Epoch 3015/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4907 - val_loss: 1.1633\n",
      "Epoch 3016/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3685 - val_loss: 1.1843\n",
      "Epoch 3017/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.3585 - val_loss: 1.1952\n",
      "Epoch 3018/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4294 - val_loss: 1.2174\n",
      "Epoch 3019/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2840 - val_loss: 1.1914\n",
      "Epoch 3020/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3134 - val_loss: 1.1779\n",
      "Epoch 3021/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2942 - val_loss: 1.1999\n",
      "Epoch 3022/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4989 - val_loss: 1.4208\n",
      "Epoch 3023/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4237 - val_loss: 1.4453\n",
      "Epoch 3024/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4121 - val_loss: 1.3639\n",
      "Epoch 3025/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3253 - val_loss: 1.2934\n",
      "Epoch 3026/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4636 - val_loss: 1.2879\n",
      "Epoch 3027/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4200 - val_loss: 1.2385\n",
      "Epoch 3028/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4298 - val_loss: 1.2213\n",
      "Epoch 3029/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3728 - val_loss: 1.2165\n",
      "Epoch 3030/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4310 - val_loss: 1.1677\n",
      "Epoch 3031/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3742 - val_loss: 1.1613\n",
      "Epoch 3032/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3820 - val_loss: 1.1127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3033/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4033 - val_loss: 1.1698\n",
      "Epoch 3034/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4357 - val_loss: 1.1385\n",
      "Epoch 3035/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3814 - val_loss: 1.1844\n",
      "Epoch 3036/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3109 - val_loss: 1.1770\n",
      "Epoch 3037/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4123 - val_loss: 1.1538\n",
      "Epoch 3038/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3829 - val_loss: 1.1658\n",
      "Epoch 3039/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3789 - val_loss: 1.1643\n",
      "Epoch 3040/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3372 - val_loss: 1.1662\n",
      "Epoch 3041/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2999 - val_loss: 1.1916\n",
      "Epoch 3042/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5260 - val_loss: 1.2012\n",
      "Epoch 3043/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2675 - val_loss: 1.1722\n",
      "Epoch 3044/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3725 - val_loss: 1.1612\n",
      "Epoch 3045/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4764 - val_loss: 1.1944\n",
      "Epoch 3046/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4437 - val_loss: 1.1341\n",
      "Epoch 3047/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3820 - val_loss: 1.1693\n",
      "Epoch 3048/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3782 - val_loss: 1.2008\n",
      "Epoch 3049/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3890 - val_loss: 1.1238\n",
      "Epoch 3050/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4296 - val_loss: 1.1547\n",
      "Epoch 3051/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4685 - val_loss: 1.1889\n",
      "Epoch 3052/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3194 - val_loss: 1.1631\n",
      "Epoch 3053/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.2625 - val_loss: 1.1680\n",
      "Epoch 3054/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4556 - val_loss: 1.1774\n",
      "Epoch 3055/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4497 - val_loss: 1.1465\n",
      "Epoch 3056/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3865 - val_loss: 1.1690\n",
      "Epoch 3057/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4316 - val_loss: 1.1739\n",
      "Epoch 3058/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3974 - val_loss: 1.2045\n",
      "Epoch 3059/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3909 - val_loss: 1.1612\n",
      "Epoch 3060/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3298 - val_loss: 1.1659\n",
      "Epoch 3061/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3739 - val_loss: 1.2268\n",
      "Epoch 3062/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4179 - val_loss: 1.1650\n",
      "Epoch 3063/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4668 - val_loss: 1.1541\n",
      "Epoch 3064/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4622 - val_loss: 1.1976\n",
      "Epoch 3065/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4301 - val_loss: 1.1449\n",
      "Epoch 3066/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3452 - val_loss: 1.1500\n",
      "Epoch 3067/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3457 - val_loss: 1.1401\n",
      "Epoch 3068/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5492 - val_loss: 1.1593\n",
      "Epoch 3069/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5270 - val_loss: 1.1577\n",
      "Epoch 3070/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4911 - val_loss: 1.1976\n",
      "Epoch 3071/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5212 - val_loss: 1.1649\n",
      "Epoch 3072/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3491 - val_loss: 1.1539\n",
      "Epoch 3073/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3578 - val_loss: 1.1500\n",
      "Epoch 3074/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3140 - val_loss: 1.1387\n",
      "Epoch 3075/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4164 - val_loss: 1.1542\n",
      "Epoch 3076/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3854 - val_loss: 1.1890\n",
      "Epoch 3077/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3814 - val_loss: 1.1291\n",
      "Epoch 3078/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4445 - val_loss: 1.1419\n",
      "Epoch 3079/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4160 - val_loss: 1.1774\n",
      "Epoch 3080/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5567 - val_loss: 1.2012\n",
      "Epoch 3081/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3978 - val_loss: 1.1286\n",
      "Epoch 3082/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3820 - val_loss: 1.2029\n",
      "Epoch 3083/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3973 - val_loss: 1.1169\n",
      "Epoch 3084/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3969 - val_loss: 1.1540\n",
      "Epoch 3085/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3100 - val_loss: 1.2127\n",
      "Epoch 3086/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3231 - val_loss: 1.1643\n",
      "Epoch 3087/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4421 - val_loss: 1.1674\n",
      "Epoch 3088/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4266 - val_loss: 1.1720\n",
      "Epoch 3089/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4824 - val_loss: 1.2018\n",
      "Epoch 3090/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4157 - val_loss: 1.1439\n",
      "Epoch 3091/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3541 - val_loss: 1.1704\n",
      "Epoch 3092/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3482 - val_loss: 1.1631\n",
      "Epoch 3093/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4711 - val_loss: 1.1742\n",
      "Epoch 3094/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3430 - val_loss: 1.1447\n",
      "Epoch 3095/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4325 - val_loss: 1.1799\n",
      "Epoch 3096/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4299 - val_loss: 1.1890\n",
      "Epoch 3097/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3134 - val_loss: 1.1805\n",
      "Epoch 3098/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3272 - val_loss: 1.1590\n",
      "Epoch 3099/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4122 - val_loss: 1.1870\n",
      "Epoch 3100/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4918 - val_loss: 1.1579\n",
      "Epoch 3101/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4602 - val_loss: 1.1321\n",
      "Epoch 3102/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4585 - val_loss: 1.2004\n",
      "Epoch 3103/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3931 - val_loss: 1.1277\n",
      "Epoch 3104/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3013 - val_loss: 1.1678\n",
      "Epoch 3105/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3182 - val_loss: 1.1735\n",
      "Epoch 3106/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3153 - val_loss: 1.1653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3107/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3028 - val_loss: 1.2009\n",
      "Epoch 3108/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4226 - val_loss: 1.1501\n",
      "Epoch 3109/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3403 - val_loss: 1.1730\n",
      "Epoch 3110/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3318 - val_loss: 1.1863\n",
      "Epoch 3111/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3540 - val_loss: 1.1433\n",
      "Epoch 3112/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4585 - val_loss: 1.2039\n",
      "Epoch 3113/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3622 - val_loss: 1.1614\n",
      "Epoch 3114/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4895 - val_loss: 1.1610\n",
      "Epoch 3115/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3693 - val_loss: 1.1884\n",
      "Epoch 3116/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4362 - val_loss: 1.1541\n",
      "Epoch 3117/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3933 - val_loss: 1.1813\n",
      "Epoch 3118/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3343 - val_loss: 1.1656\n",
      "Epoch 3119/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5279 - val_loss: 1.2051\n",
      "Epoch 3120/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3323 - val_loss: 1.1469\n",
      "Epoch 3121/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3894 - val_loss: 1.2193\n",
      "Epoch 3122/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2924 - val_loss: 1.1574\n",
      "Epoch 3123/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4248 - val_loss: 1.1827\n",
      "Epoch 3124/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3471 - val_loss: 1.1799\n",
      "Epoch 3125/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3940 - val_loss: 1.1724\n",
      "Epoch 3126/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4225 - val_loss: 1.1325\n",
      "Epoch 3127/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4068 - val_loss: 1.1662\n",
      "Epoch 3128/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4050 - val_loss: 1.1495\n",
      "Epoch 3129/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3800 - val_loss: 1.2160\n",
      "Epoch 3130/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3828 - val_loss: 1.1626\n",
      "Epoch 3131/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4763 - val_loss: 1.1418\n",
      "Epoch 3132/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3712 - val_loss: 1.1818\n",
      "Epoch 3133/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4245 - val_loss: 1.1521\n",
      "Epoch 3134/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3855 - val_loss: 1.1390\n",
      "Epoch 3135/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3616 - val_loss: 1.1580\n",
      "Epoch 3136/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4504 - val_loss: 1.1684\n",
      "Epoch 3137/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4216 - val_loss: 1.1773\n",
      "Epoch 3138/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3437 - val_loss: 1.1654\n",
      "Epoch 3139/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4888 - val_loss: 1.1576\n",
      "Epoch 3140/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3874 - val_loss: 1.2051\n",
      "Epoch 3141/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3529 - val_loss: 1.1481\n",
      "Epoch 3142/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3675 - val_loss: 1.1905\n",
      "Epoch 3143/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4933 - val_loss: 1.1711\n",
      "Epoch 3144/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3251 - val_loss: 1.1562\n",
      "Epoch 3145/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3700 - val_loss: 1.2155\n",
      "Epoch 3146/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3884 - val_loss: 1.1461\n",
      "Epoch 3147/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3974 - val_loss: 1.2073\n",
      "Epoch 3148/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4296 - val_loss: 1.2067\n",
      "Epoch 3149/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3109 - val_loss: 1.1598\n",
      "Epoch 3150/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3217 - val_loss: 1.2101\n",
      "Epoch 3151/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2768 - val_loss: 1.1849\n",
      "Epoch 3152/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2944 - val_loss: 1.1587\n",
      "Epoch 3153/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4088 - val_loss: 1.1709\n",
      "Epoch 3154/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3817 - val_loss: 1.1891\n",
      "Epoch 3155/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2646 - val_loss: 1.1281\n",
      "Epoch 3156/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5732 - val_loss: 1.1778\n",
      "Epoch 3157/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3111 - val_loss: 1.1425\n",
      "Epoch 3158/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3449 - val_loss: 1.1621\n",
      "Epoch 3159/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.4894 - val_loss: 1.1698\n",
      "Epoch 3160/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4654 - val_loss: 1.1487\n",
      "Epoch 3161/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4153 - val_loss: 1.1705\n",
      "Epoch 3162/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3978 - val_loss: 1.1599\n",
      "Epoch 3163/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4773 - val_loss: 1.1676\n",
      "Epoch 3164/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4503 - val_loss: 1.1646\n",
      "Epoch 3165/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3501 - val_loss: 1.1510\n",
      "Epoch 3166/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3965 - val_loss: 1.1617\n",
      "Epoch 3167/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4727 - val_loss: 1.1892\n",
      "Epoch 3168/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3556 - val_loss: 1.1784\n",
      "Epoch 3169/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3945 - val_loss: 1.1718\n",
      "Epoch 3170/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4190 - val_loss: 1.1456\n",
      "Epoch 3171/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4938 - val_loss: 1.1768\n",
      "Epoch 3172/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4347 - val_loss: 1.2058\n",
      "Epoch 3173/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4294 - val_loss: 1.1564\n",
      "Epoch 3174/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3472 - val_loss: 1.1623\n",
      "Epoch 3175/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4368 - val_loss: 1.1581\n",
      "Epoch 3176/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3066 - val_loss: 1.1648\n",
      "Epoch 3177/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3488 - val_loss: 1.1560\n",
      "Epoch 3178/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4012 - val_loss: 1.1879\n",
      "Epoch 3179/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3170 - val_loss: 1.1451\n",
      "Epoch 3180/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5594 - val_loss: 1.1963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3181/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4401 - val_loss: 1.1442\n",
      "Epoch 3182/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5444 - val_loss: 1.1666\n",
      "Epoch 3183/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4133 - val_loss: 1.1652\n",
      "Epoch 3184/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4249 - val_loss: 1.1456\n",
      "Epoch 3185/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5347 - val_loss: 1.2488\n",
      "Epoch 3186/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3927 - val_loss: 1.1675\n",
      "Epoch 3187/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3442 - val_loss: 1.1798\n",
      "Epoch 3188/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3356 - val_loss: 1.1757\n",
      "Epoch 3189/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4047 - val_loss: 1.1762\n",
      "Epoch 3190/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4049 - val_loss: 1.1770\n",
      "Epoch 3191/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3236 - val_loss: 1.1682\n",
      "Epoch 3192/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3709 - val_loss: 1.1999\n",
      "Epoch 3193/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4215 - val_loss: 1.1649\n",
      "Epoch 3194/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4046 - val_loss: 1.1683\n",
      "Epoch 3195/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4731 - val_loss: 1.1699\n",
      "Epoch 3196/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3075 - val_loss: 1.1368\n",
      "Epoch 3197/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4130 - val_loss: 1.1668\n",
      "Epoch 3198/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4265 - val_loss: 1.1830\n",
      "Epoch 3199/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5068 - val_loss: 1.1663\n",
      "Epoch 3200/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5899 - val_loss: 1.2134\n",
      "Epoch 3201/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5854 - val_loss: 1.1754\n",
      "Epoch 3202/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5035 - val_loss: 1.1719\n",
      "Epoch 3203/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4476 - val_loss: 1.1892\n",
      "Epoch 3204/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4002 - val_loss: 1.1573\n",
      "Epoch 3205/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5774 - val_loss: 1.1983\n",
      "Epoch 3206/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3594 - val_loss: 1.1899\n",
      "Epoch 3207/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3889 - val_loss: 1.1622\n",
      "Epoch 3208/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4124 - val_loss: 1.1705\n",
      "Epoch 3209/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3217 - val_loss: 1.1682\n",
      "Epoch 3210/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4088 - val_loss: 1.1842\n",
      "Epoch 3211/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4372 - val_loss: 1.2144\n",
      "Epoch 3212/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4753 - val_loss: 1.1650\n",
      "Epoch 3213/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4376 - val_loss: 1.1576\n",
      "Epoch 3214/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4522 - val_loss: 1.1790\n",
      "Epoch 3215/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3708 - val_loss: 1.1969\n",
      "Epoch 3216/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3444 - val_loss: 1.1571\n",
      "Epoch 3217/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3111 - val_loss: 1.2105\n",
      "Epoch 3218/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4269 - val_loss: 1.1509\n",
      "Epoch 3219/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3395 - val_loss: 1.1899\n",
      "Epoch 3220/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3112 - val_loss: 1.1723\n",
      "Epoch 3221/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4284 - val_loss: 1.1594\n",
      "Epoch 3222/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3689 - val_loss: 1.2175\n",
      "Epoch 3223/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3428 - val_loss: 1.1518\n",
      "Epoch 3224/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4123 - val_loss: 1.1440\n",
      "Epoch 3225/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4295 - val_loss: 1.1660\n",
      "Epoch 3226/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3194 - val_loss: 1.2022\n",
      "Epoch 3227/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3547 - val_loss: 1.2010\n",
      "Epoch 3228/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3723 - val_loss: 1.1550\n",
      "Epoch 3229/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3360 - val_loss: 1.1843\n",
      "Epoch 3230/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4725 - val_loss: 1.1824\n",
      "Epoch 3231/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3517 - val_loss: 1.1764\n",
      "Epoch 3232/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3131 - val_loss: 1.1397\n",
      "Epoch 3233/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4283 - val_loss: 1.2095\n",
      "Epoch 3234/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3957 - val_loss: 1.2164\n",
      "Epoch 3235/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4104 - val_loss: 1.1403\n",
      "Epoch 3236/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3776 - val_loss: 1.1968\n",
      "Epoch 3237/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4350 - val_loss: 1.2141\n",
      "Epoch 3238/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3170 - val_loss: 1.1504\n",
      "Epoch 3239/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4717 - val_loss: 1.1267\n",
      "Epoch 3240/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3551 - val_loss: 1.1804\n",
      "Epoch 3241/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.3301 - val_loss: 1.1801\n",
      "Epoch 3242/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3720 - val_loss: 1.1685\n",
      "Epoch 3243/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4186 - val_loss: 1.1728\n",
      "Epoch 3244/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4032 - val_loss: 1.1675\n",
      "Epoch 3245/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3658 - val_loss: 1.1540\n",
      "Epoch 3246/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4164 - val_loss: 1.1421\n",
      "Epoch 3247/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2585 - val_loss: 1.2109\n",
      "Epoch 3248/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3874 - val_loss: 1.1497\n",
      "Epoch 3249/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4384 - val_loss: 1.1783\n",
      "Epoch 3250/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3123 - val_loss: 1.1517\n",
      "Epoch 3251/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4461 - val_loss: 1.1346\n",
      "Epoch 3252/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3506 - val_loss: 1.1575\n",
      "Epoch 3253/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4131 - val_loss: 1.1623\n",
      "Epoch 3254/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4458 - val_loss: 1.1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3255/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3949 - val_loss: 1.1303\n",
      "Epoch 3256/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4328 - val_loss: 1.1616\n",
      "Epoch 3257/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3205 - val_loss: 1.1681\n",
      "Epoch 3258/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3802 - val_loss: 1.1999\n",
      "Epoch 3259/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4696 - val_loss: 1.1590\n",
      "Epoch 3260/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5017 - val_loss: 1.1695\n",
      "Epoch 3261/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4941 - val_loss: 1.2157\n",
      "Epoch 3262/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5463 - val_loss: 1.2634\n",
      "Epoch 3263/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3599 - val_loss: 1.1726\n",
      "Epoch 3264/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3836 - val_loss: 1.1686\n",
      "Epoch 3265/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4459 - val_loss: 1.1395\n",
      "Epoch 3266/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.6034 - val_loss: 1.2109\n",
      "Epoch 3267/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4006 - val_loss: 1.1447\n",
      "Epoch 3268/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3801 - val_loss: 1.1889\n",
      "Epoch 3269/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4242 - val_loss: 1.1798\n",
      "Epoch 3270/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3904 - val_loss: 1.1528\n",
      "Epoch 3271/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3920 - val_loss: 1.1665\n",
      "Epoch 3272/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3850 - val_loss: 1.1689\n",
      "Epoch 3273/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3402 - val_loss: 1.1797\n",
      "Epoch 3274/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4206 - val_loss: 1.1626\n",
      "Epoch 3275/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4337 - val_loss: 1.2391\n",
      "Epoch 3276/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4215 - val_loss: 1.2094\n",
      "Epoch 3277/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4354 - val_loss: 1.1444\n",
      "Epoch 3278/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3848 - val_loss: 1.1812\n",
      "Epoch 3279/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4481 - val_loss: 1.1646\n",
      "Epoch 3280/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4616 - val_loss: 1.1496\n",
      "Epoch 3281/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3474 - val_loss: 1.1873\n",
      "Epoch 3282/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3937 - val_loss: 1.1433\n",
      "Epoch 3283/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3380 - val_loss: 1.1446\n",
      "Epoch 3284/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4593 - val_loss: 1.1607\n",
      "Epoch 3285/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3949 - val_loss: 1.1924\n",
      "Epoch 3286/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4729 - val_loss: 1.1649\n",
      "Epoch 3287/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3142 - val_loss: 1.1586\n",
      "Epoch 3288/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3888 - val_loss: 1.1377\n",
      "Epoch 3289/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2863 - val_loss: 1.1438\n",
      "Epoch 3290/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3896 - val_loss: 1.2258\n",
      "Epoch 3291/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4729 - val_loss: 1.1540\n",
      "Epoch 3292/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3989 - val_loss: 1.1922\n",
      "Epoch 3293/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3816 - val_loss: 1.1804\n",
      "Epoch 3294/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4494 - val_loss: 1.1653\n",
      "Epoch 3295/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4506 - val_loss: 1.1524\n",
      "Epoch 3296/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4268 - val_loss: 1.1743\n",
      "Epoch 3297/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3657 - val_loss: 1.1898\n",
      "Epoch 3298/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3446 - val_loss: 1.1442\n",
      "Epoch 3299/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5360 - val_loss: 1.1884\n",
      "Epoch 3300/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3328 - val_loss: 1.1356\n",
      "Epoch 3301/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5302 - val_loss: 1.1787\n",
      "Epoch 3302/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4490 - val_loss: 1.1810\n",
      "Epoch 3303/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3720 - val_loss: 1.1961\n",
      "Epoch 3304/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4153 - val_loss: 1.1634\n",
      "Epoch 3305/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3696 - val_loss: 1.1629\n",
      "Epoch 3306/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4840 - val_loss: 1.2283\n",
      "Epoch 3307/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4103 - val_loss: 1.1614\n",
      "Epoch 3308/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3929 - val_loss: 1.1600\n",
      "Epoch 3309/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4856 - val_loss: 1.1900\n",
      "Epoch 3310/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3624 - val_loss: 1.1781\n",
      "Epoch 3311/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4133 - val_loss: 1.1712\n",
      "Epoch 3312/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4308 - val_loss: 1.1593\n",
      "Epoch 3313/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3014 - val_loss: 1.1805\n",
      "Epoch 3314/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5375 - val_loss: 1.1399\n",
      "Epoch 3315/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3310 - val_loss: 1.1767\n",
      "Epoch 3316/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3969 - val_loss: 1.1644\n",
      "Epoch 3317/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3539 - val_loss: 1.2106\n",
      "Epoch 3318/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3480 - val_loss: 1.1902\n",
      "Epoch 3319/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3699 - val_loss: 1.1687\n",
      "Epoch 3320/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3766 - val_loss: 1.1703\n",
      "Epoch 3321/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4076 - val_loss: 1.1803\n",
      "Epoch 3322/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4181 - val_loss: 1.1570\n",
      "Epoch 3323/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4636 - val_loss: 1.1893\n",
      "Epoch 3324/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4403 - val_loss: 1.1527\n",
      "Epoch 3325/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4524 - val_loss: 1.1788\n",
      "Epoch 3326/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4802 - val_loss: 1.1708\n",
      "Epoch 3327/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3162 - val_loss: 1.1609\n",
      "Epoch 3328/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4010 - val_loss: 1.1821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3329/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3782 - val_loss: 1.1386\n",
      "Epoch 3330/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3718 - val_loss: 1.1739\n",
      "Epoch 3331/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4591 - val_loss: 1.1426\n",
      "Epoch 3332/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3217 - val_loss: 1.1672\n",
      "Epoch 3333/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4094 - val_loss: 1.1361\n",
      "Epoch 3334/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4090 - val_loss: 1.1581\n",
      "Epoch 3335/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3789 - val_loss: 1.1768\n",
      "Epoch 3336/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3955 - val_loss: 1.1663\n",
      "Epoch 3337/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3466 - val_loss: 1.1370\n",
      "Epoch 3338/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3481 - val_loss: 1.1646\n",
      "Epoch 3339/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3808 - val_loss: 1.1527\n",
      "Epoch 3340/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3195 - val_loss: 1.1407\n",
      "Epoch 3341/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4637 - val_loss: 1.1591\n",
      "Epoch 3342/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4160 - val_loss: 1.2353\n",
      "Epoch 3343/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4375 - val_loss: 1.1621\n",
      "Epoch 3344/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3576 - val_loss: 1.2034\n",
      "Epoch 3345/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3329 - val_loss: 1.1645\n",
      "Epoch 3346/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3869 - val_loss: 1.1848\n",
      "Epoch 3347/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3381 - val_loss: 1.1884\n",
      "Epoch 3348/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3445 - val_loss: 1.1828\n",
      "Epoch 3349/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4313 - val_loss: 1.1745\n",
      "Epoch 3350/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4149 - val_loss: 1.1756\n",
      "Epoch 3351/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3748 - val_loss: 1.1596\n",
      "Epoch 3352/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3622 - val_loss: 1.1956\n",
      "Epoch 3353/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3320 - val_loss: 1.1556\n",
      "Epoch 3354/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3763 - val_loss: 1.1672\n",
      "Epoch 3355/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3182 - val_loss: 1.1868\n",
      "Epoch 3356/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3590 - val_loss: 1.2251\n",
      "Epoch 3357/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4325 - val_loss: 1.1750\n",
      "Epoch 3358/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4363 - val_loss: 1.1745\n",
      "Epoch 3359/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4751 - val_loss: 1.2162\n",
      "Epoch 3360/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4390 - val_loss: 1.1972\n",
      "Epoch 3361/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4397 - val_loss: 1.1196\n",
      "Epoch 3362/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3427 - val_loss: 1.1954\n",
      "Epoch 3363/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5334 - val_loss: 1.1403\n",
      "Epoch 3364/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2616 - val_loss: 1.1665\n",
      "Epoch 3365/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3294 - val_loss: 1.1587\n",
      "Epoch 3366/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4195 - val_loss: 1.1820\n",
      "Epoch 3367/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4235 - val_loss: 1.1639\n",
      "Epoch 3368/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4182 - val_loss: 1.1646\n",
      "Epoch 3369/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4962 - val_loss: 1.2195\n",
      "Epoch 3370/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4029 - val_loss: 1.1486\n",
      "Epoch 3371/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4084 - val_loss: 1.1890\n",
      "Epoch 3372/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3838 - val_loss: 1.1977\n",
      "Epoch 3373/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3264 - val_loss: 1.1928\n",
      "Epoch 3374/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3995 - val_loss: 1.1853\n",
      "Epoch 3375/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4055 - val_loss: 1.1775\n",
      "Epoch 3376/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3615 - val_loss: 1.1821\n",
      "Epoch 3377/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4267 - val_loss: 1.1507\n",
      "Epoch 3378/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4112 - val_loss: 1.2421\n",
      "Epoch 3379/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4100 - val_loss: 1.2343\n",
      "Epoch 3380/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4678 - val_loss: 1.1620\n",
      "Epoch 3381/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4211 - val_loss: 1.1835\n",
      "Epoch 3382/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3729 - val_loss: 1.2079\n",
      "Epoch 3383/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3492 - val_loss: 1.2188\n",
      "Epoch 3384/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3704 - val_loss: 1.1593\n",
      "Epoch 3385/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4438 - val_loss: 1.2200\n",
      "Epoch 3386/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5754 - val_loss: 1.2037\n",
      "Epoch 3387/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5746 - val_loss: 1.2015\n",
      "Epoch 3388/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4726 - val_loss: 1.2104\n",
      "Epoch 3389/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4457 - val_loss: 1.1556\n",
      "Epoch 3390/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3577 - val_loss: 1.1751\n",
      "Epoch 3391/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4475 - val_loss: 1.1693\n",
      "Epoch 3392/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3885 - val_loss: 1.2072\n",
      "Epoch 3393/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4482 - val_loss: 1.1665\n",
      "Epoch 3394/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2886 - val_loss: 1.2036\n",
      "Epoch 3395/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4043 - val_loss: 1.1258\n",
      "Epoch 3396/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3596 - val_loss: 1.1367\n",
      "Epoch 3397/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4353 - val_loss: 1.1517\n",
      "Epoch 3398/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4001 - val_loss: 1.1707\n",
      "Epoch 3399/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4761 - val_loss: 1.1912\n",
      "Epoch 3400/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2945 - val_loss: 1.1998\n",
      "Epoch 3401/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2905 - val_loss: 1.2082\n",
      "Epoch 3402/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4924 - val_loss: 1.2287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3403/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4411 - val_loss: 1.1825\n",
      "Epoch 3404/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4928 - val_loss: 1.1641\n",
      "Epoch 3405/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2864 - val_loss: 1.1542\n",
      "Epoch 3406/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4319 - val_loss: 1.1529\n",
      "Epoch 3407/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3259 - val_loss: 1.2012\n",
      "Epoch 3408/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3637 - val_loss: 1.1554\n",
      "Epoch 3409/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3959 - val_loss: 1.1756\n",
      "Epoch 3410/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4277 - val_loss: 1.1556\n",
      "Epoch 3411/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.2750 - val_loss: 1.1445\n",
      "Epoch 3412/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3461 - val_loss: 1.1546\n",
      "Epoch 3413/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5718 - val_loss: 1.1897\n",
      "Epoch 3414/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3567 - val_loss: 1.2395\n",
      "Epoch 3415/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3973 - val_loss: 1.1859\n",
      "Epoch 3416/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3277 - val_loss: 1.1670\n",
      "Epoch 3417/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4511 - val_loss: 1.1872\n",
      "Epoch 3418/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4531 - val_loss: 1.1961\n",
      "Epoch 3419/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4950 - val_loss: 1.1815\n",
      "Epoch 3420/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5091 - val_loss: 1.1593\n",
      "Epoch 3421/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3578 - val_loss: 1.1536\n",
      "Epoch 3422/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4362 - val_loss: 1.1410\n",
      "Epoch 3423/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4238 - val_loss: 1.1745\n",
      "Epoch 3424/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3609 - val_loss: 1.1523\n",
      "Epoch 3425/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4504 - val_loss: 1.1959\n",
      "Epoch 3426/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3690 - val_loss: 1.1918\n",
      "Epoch 3427/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3447 - val_loss: 1.1862\n",
      "Epoch 3428/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4271 - val_loss: 1.1720\n",
      "Epoch 3429/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5012 - val_loss: 1.1765\n",
      "Epoch 3430/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4181 - val_loss: 1.1715\n",
      "Epoch 3431/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3489 - val_loss: 1.1755\n",
      "Epoch 3432/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3592 - val_loss: 1.1767\n",
      "Epoch 3433/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3336 - val_loss: 1.1686\n",
      "Epoch 3434/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3689 - val_loss: 1.1791\n",
      "Epoch 3435/20000\n",
      "1500/1500 [==============================] - 0s 44us/sample - loss: 1.4859 - val_loss: 1.1675\n",
      "Epoch 3436/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.2994 - val_loss: 1.1660\n",
      "Epoch 3437/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3589 - val_loss: 1.1677\n",
      "Epoch 3438/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4215 - val_loss: 1.1618\n",
      "Epoch 3439/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3338 - val_loss: 1.1855\n",
      "Epoch 3440/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3266 - val_loss: 1.1700\n",
      "Epoch 3441/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3829 - val_loss: 1.1418\n",
      "Epoch 3442/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3835 - val_loss: 1.1712\n",
      "Epoch 3443/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3285 - val_loss: 1.1290\n",
      "Epoch 3444/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3814 - val_loss: 1.1672\n",
      "Epoch 3445/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3997 - val_loss: 1.1541\n",
      "Epoch 3446/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4276 - val_loss: 1.2024\n",
      "Epoch 3447/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3238 - val_loss: 1.1560\n",
      "Epoch 3448/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3247 - val_loss: 1.1974\n",
      "Epoch 3449/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4503 - val_loss: 1.2263\n",
      "Epoch 3450/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3123 - val_loss: 1.1586\n",
      "Epoch 3451/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3938 - val_loss: 1.1368\n",
      "Epoch 3452/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2751 - val_loss: 1.1533\n",
      "Epoch 3453/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3251 - val_loss: 1.1340\n",
      "Epoch 3454/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4482 - val_loss: 1.1679\n",
      "Epoch 3455/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3945 - val_loss: 1.1515\n",
      "Epoch 3456/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4343 - val_loss: 1.1646\n",
      "Epoch 3457/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3009 - val_loss: 1.1629\n",
      "Epoch 3458/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4126 - val_loss: 1.1625\n",
      "Epoch 3459/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3646 - val_loss: 1.1814\n",
      "Epoch 3460/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4724 - val_loss: 1.1591\n",
      "Epoch 3461/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4305 - val_loss: 1.2379\n",
      "Epoch 3462/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3946 - val_loss: 1.1474\n",
      "Epoch 3463/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4739 - val_loss: 1.2161\n",
      "Epoch 3464/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3631 - val_loss: 1.1492\n",
      "Epoch 3465/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3137 - val_loss: 1.1412\n",
      "Epoch 3466/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5647 - val_loss: 1.1362\n",
      "Epoch 3467/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4147 - val_loss: 1.1607\n",
      "Epoch 3468/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3753 - val_loss: 1.1512\n",
      "Epoch 3469/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4197 - val_loss: 1.1823\n",
      "Epoch 3470/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4139 - val_loss: 1.2129\n",
      "Epoch 3471/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3960 - val_loss: 1.1692\n",
      "Epoch 3472/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3831 - val_loss: 1.1462\n",
      "Epoch 3473/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3865 - val_loss: 1.1824\n",
      "Epoch 3474/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5243 - val_loss: 1.1678\n",
      "Epoch 3475/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3578 - val_loss: 1.2021\n",
      "Epoch 3476/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3598 - val_loss: 1.1628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3477/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4220 - val_loss: 1.1601\n",
      "Epoch 3478/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3347 - val_loss: 1.1685\n",
      "Epoch 3479/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3687 - val_loss: 1.1709\n",
      "Epoch 3480/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3562 - val_loss: 1.1766\n",
      "Epoch 3481/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4668 - val_loss: 1.1972\n",
      "Epoch 3482/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4268 - val_loss: 1.2154\n",
      "Epoch 3483/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3471 - val_loss: 1.1627\n",
      "Epoch 3484/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3630 - val_loss: 1.1767\n",
      "Epoch 3485/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3886 - val_loss: 1.1671\n",
      "Epoch 3486/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4173 - val_loss: 1.1596\n",
      "Epoch 3487/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4250 - val_loss: 1.2040\n",
      "Epoch 3488/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3152 - val_loss: 1.1704\n",
      "Epoch 3489/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3827 - val_loss: 1.1559\n",
      "Epoch 3490/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3655 - val_loss: 1.1824\n",
      "Epoch 3491/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3776 - val_loss: 1.1621\n",
      "Epoch 3492/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3823 - val_loss: 1.1497\n",
      "Epoch 3493/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3152 - val_loss: 1.1902\n",
      "Epoch 3494/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3206 - val_loss: 1.1564\n",
      "Epoch 3495/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3862 - val_loss: 1.1928\n",
      "Epoch 3496/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4785 - val_loss: 1.1589\n",
      "Epoch 3497/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3163 - val_loss: 1.1491\n",
      "Epoch 3498/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3567 - val_loss: 1.1793\n",
      "Epoch 3499/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4787 - val_loss: 1.1589\n",
      "Epoch 3500/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4049 - val_loss: 1.1735\n",
      "Epoch 3501/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3547 - val_loss: 1.1801\n",
      "Epoch 3502/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3132 - val_loss: 1.1460\n",
      "Epoch 3503/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3211 - val_loss: 1.1998\n",
      "Epoch 3504/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3720 - val_loss: 1.1510\n",
      "Epoch 3505/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3259 - val_loss: 1.1827\n",
      "Epoch 3506/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4310 - val_loss: 1.1895\n",
      "Epoch 3507/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5891 - val_loss: 1.2069\n",
      "Epoch 3508/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4258 - val_loss: 1.2222\n",
      "Epoch 3509/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4486 - val_loss: 1.2167\n",
      "Epoch 3510/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3682 - val_loss: 1.1989\n",
      "Epoch 3511/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3000 - val_loss: 1.1784\n",
      "Epoch 3512/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3463 - val_loss: 1.2068\n",
      "Epoch 3513/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4521 - val_loss: 1.2538\n",
      "Epoch 3514/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4080 - val_loss: 1.2166\n",
      "Epoch 3515/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4548 - val_loss: 1.1513\n",
      "Epoch 3516/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4040 - val_loss: 1.2317\n",
      "Epoch 3517/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4011 - val_loss: 1.1735\n",
      "Epoch 3518/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2685 - val_loss: 1.1604\n",
      "Epoch 3519/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3404 - val_loss: 1.1885\n",
      "Epoch 3520/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5207 - val_loss: 1.1741\n",
      "Epoch 3521/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4261 - val_loss: 1.1662\n",
      "Epoch 3522/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3260 - val_loss: 1.1764\n",
      "Epoch 3523/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4160 - val_loss: 1.1733\n",
      "Epoch 3524/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4650 - val_loss: 1.1925\n",
      "Epoch 3525/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3574 - val_loss: 1.1389\n",
      "Epoch 3526/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4090 - val_loss: 1.1544\n",
      "Epoch 3527/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4546 - val_loss: 1.1755\n",
      "Epoch 3528/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3926 - val_loss: 1.1673\n",
      "Epoch 3529/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3990 - val_loss: 1.2357\n",
      "Epoch 3530/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3509 - val_loss: 1.1549\n",
      "Epoch 3531/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3757 - val_loss: 1.1972\n",
      "Epoch 3532/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3195 - val_loss: 1.1390\n",
      "Epoch 3533/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5335 - val_loss: 1.2320\n",
      "Epoch 3534/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4939 - val_loss: 1.5628\n",
      "Epoch 3535/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4476 - val_loss: 1.5231\n",
      "Epoch 3536/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3905 - val_loss: 1.4367\n",
      "Epoch 3537/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4054 - val_loss: 1.2956\n",
      "Epoch 3538/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4966 - val_loss: 1.2227\n",
      "Epoch 3539/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3753 - val_loss: 1.2233\n",
      "Epoch 3540/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4204 - val_loss: 1.2008\n",
      "Epoch 3541/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3677 - val_loss: 1.1360\n",
      "Epoch 3542/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4549 - val_loss: 1.2194\n",
      "Epoch 3543/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4756 - val_loss: 1.1546\n",
      "Epoch 3544/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4208 - val_loss: 1.1694\n",
      "Epoch 3545/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3560 - val_loss: 1.1798\n",
      "Epoch 3546/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5243 - val_loss: 1.1577\n",
      "Epoch 3547/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4466 - val_loss: 1.1627\n",
      "Epoch 3548/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4485 - val_loss: 1.2239\n",
      "Epoch 3549/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3920 - val_loss: 1.1520\n",
      "Epoch 3550/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3601 - val_loss: 1.1915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3551/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4226 - val_loss: 1.1612\n",
      "Epoch 3552/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4003 - val_loss: 1.1333\n",
      "Epoch 3553/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3891 - val_loss: 1.2055\n",
      "Epoch 3554/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4175 - val_loss: 1.1693\n",
      "Epoch 3555/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3879 - val_loss: 1.1415\n",
      "Epoch 3556/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4423 - val_loss: 1.1795\n",
      "Epoch 3557/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3183 - val_loss: 1.1535\n",
      "Epoch 3558/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4256 - val_loss: 1.1981\n",
      "Epoch 3559/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5051 - val_loss: 1.1454\n",
      "Epoch 3560/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.6145 - val_loss: 1.1673\n",
      "Epoch 3561/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4153 - val_loss: 1.1760\n",
      "Epoch 3562/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4458 - val_loss: 1.2006\n",
      "Epoch 3563/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4582 - val_loss: 1.2229\n",
      "Epoch 3564/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3769 - val_loss: 1.1756\n",
      "Epoch 3565/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2861 - val_loss: 1.1642\n",
      "Epoch 3566/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4523 - val_loss: 1.1941\n",
      "Epoch 3567/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3623 - val_loss: 1.2491\n",
      "Epoch 3568/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4160 - val_loss: 1.1509\n",
      "Epoch 3569/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3488 - val_loss: 1.1539\n",
      "Epoch 3570/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5079 - val_loss: 1.1775\n",
      "Epoch 3571/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3761 - val_loss: 1.1565\n",
      "Epoch 3572/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.4072 - val_loss: 1.1818\n",
      "Epoch 3573/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4541 - val_loss: 1.2010\n",
      "Epoch 3574/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4056 - val_loss: 1.1376\n",
      "Epoch 3575/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5016 - val_loss: 1.2238\n",
      "Epoch 3576/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5183 - val_loss: 1.1661\n",
      "Epoch 3577/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4667 - val_loss: 1.1510\n",
      "Epoch 3578/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4910 - val_loss: 1.1681\n",
      "Epoch 3579/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4641 - val_loss: 1.1352\n",
      "Epoch 3580/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3728 - val_loss: 1.1898\n",
      "Epoch 3581/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5411 - val_loss: 1.1670\n",
      "Epoch 3582/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3285 - val_loss: 1.1421\n",
      "Epoch 3583/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4289 - val_loss: 1.1876\n",
      "Epoch 3584/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4501 - val_loss: 1.1838\n",
      "Epoch 3585/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4179 - val_loss: 1.1730\n",
      "Epoch 3586/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3561 - val_loss: 1.1717\n",
      "Epoch 3587/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4154 - val_loss: 1.2170\n",
      "Epoch 3588/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3614 - val_loss: 1.2184\n",
      "Epoch 3589/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4101 - val_loss: 1.1906\n",
      "Epoch 3590/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3697 - val_loss: 1.2065\n",
      "Epoch 3591/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3332 - val_loss: 1.1847\n",
      "Epoch 3592/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2843 - val_loss: 1.2020\n",
      "Epoch 3593/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4535 - val_loss: 1.1986\n",
      "Epoch 3594/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5056 - val_loss: 1.2112\n",
      "Epoch 3595/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3566 - val_loss: 1.2288\n",
      "Epoch 3596/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5098 - val_loss: 1.1615\n",
      "Epoch 3597/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4462 - val_loss: 1.2054\n",
      "Epoch 3598/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4822 - val_loss: 1.2087\n",
      "Epoch 3599/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3621 - val_loss: 1.1495\n",
      "Epoch 3600/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4852 - val_loss: 1.1667\n",
      "Epoch 3601/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3453 - val_loss: 1.1736\n",
      "Epoch 3602/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3214 - val_loss: 1.1642\n",
      "Epoch 3603/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4421 - val_loss: 1.2274\n",
      "Epoch 3604/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4205 - val_loss: 1.2030\n",
      "Epoch 3605/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4058 - val_loss: 1.1752\n",
      "Epoch 3606/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3344 - val_loss: 1.1692\n",
      "Epoch 3607/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3610 - val_loss: 1.1982\n",
      "Epoch 3608/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2523 - val_loss: 1.1550\n",
      "Epoch 3609/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3999 - val_loss: 1.1656\n",
      "Epoch 3610/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3384 - val_loss: 1.1669\n",
      "Epoch 3611/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4736 - val_loss: 1.1986\n",
      "Epoch 3612/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5826 - val_loss: 1.1967\n",
      "Epoch 3613/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3534 - val_loss: 1.1803\n",
      "Epoch 3614/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5179 - val_loss: 1.1949\n",
      "Epoch 3615/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3915 - val_loss: 1.1715\n",
      "Epoch 3616/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4001 - val_loss: 1.1349\n",
      "Epoch 3617/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3832 - val_loss: 1.1907\n",
      "Epoch 3618/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3183 - val_loss: 1.1677\n",
      "Epoch 3619/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3757 - val_loss: 1.1684\n",
      "Epoch 3620/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3061 - val_loss: 1.1642\n",
      "Epoch 3621/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4179 - val_loss: 1.1732\n",
      "Epoch 3622/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4653 - val_loss: 1.1821\n",
      "Epoch 3623/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3604 - val_loss: 1.1622\n",
      "Epoch 3624/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3779 - val_loss: 1.2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3625/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4201 - val_loss: 1.1755\n",
      "Epoch 3626/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4931 - val_loss: 1.1627\n",
      "Epoch 3627/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4662 - val_loss: 1.1738\n",
      "Epoch 3628/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2893 - val_loss: 1.2205\n",
      "Epoch 3629/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4582 - val_loss: 1.1736\n",
      "Epoch 3630/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3521 - val_loss: 1.2000\n",
      "Epoch 3631/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4202 - val_loss: 1.1679\n",
      "Epoch 3632/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5043 - val_loss: 1.1739\n",
      "Epoch 3633/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3941 - val_loss: 1.1784\n",
      "Epoch 3634/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4317 - val_loss: 1.1889\n",
      "Epoch 3635/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3109 - val_loss: 1.1726\n",
      "Epoch 3636/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4690 - val_loss: 1.2005\n",
      "Epoch 3637/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3525 - val_loss: 1.1496\n",
      "Epoch 3638/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3997 - val_loss: 1.1756\n",
      "Epoch 3639/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4642 - val_loss: 1.1867\n",
      "Epoch 3640/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4464 - val_loss: 1.1320\n",
      "Epoch 3641/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4673 - val_loss: 1.2288\n",
      "Epoch 3642/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4959 - val_loss: 1.1689\n",
      "Epoch 3643/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4251 - val_loss: 1.1547\n",
      "Epoch 3644/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5594 - val_loss: 1.1576\n",
      "Epoch 3645/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4316 - val_loss: 1.1739\n",
      "Epoch 3646/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3636 - val_loss: 1.1490\n",
      "Epoch 3647/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3749 - val_loss: 1.2172\n",
      "Epoch 3648/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3926 - val_loss: 1.1522\n",
      "Epoch 3649/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3665 - val_loss: 1.1556\n",
      "Epoch 3650/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3953 - val_loss: 1.1415\n",
      "Epoch 3651/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3674 - val_loss: 1.1633\n",
      "Epoch 3652/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5281 - val_loss: 1.1863\n",
      "Epoch 3653/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2525 - val_loss: 1.1904\n",
      "Epoch 3654/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3577 - val_loss: 1.1717\n",
      "Epoch 3655/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2942 - val_loss: 1.1550\n",
      "Epoch 3656/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4487 - val_loss: 1.1714\n",
      "Epoch 3657/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5151 - val_loss: 1.2103\n",
      "Epoch 3658/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4792 - val_loss: 1.1619\n",
      "Epoch 3659/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4305 - val_loss: 1.1530\n",
      "Epoch 3660/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3103 - val_loss: 1.1514\n",
      "Epoch 3661/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4208 - val_loss: 1.2138\n",
      "Epoch 3662/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3334 - val_loss: 1.1371\n",
      "Epoch 3663/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5490 - val_loss: 1.1989\n",
      "Epoch 3664/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4299 - val_loss: 1.1705\n",
      "Epoch 3665/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4729 - val_loss: 1.1766\n",
      "Epoch 3666/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3028 - val_loss: 1.1637\n",
      "Epoch 3667/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2432 - val_loss: 1.1650\n",
      "Epoch 3668/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3988 - val_loss: 1.1917\n",
      "Epoch 3669/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4850 - val_loss: 1.1842\n",
      "Epoch 3670/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4173 - val_loss: 1.1807\n",
      "Epoch 3671/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3211 - val_loss: 1.1926\n",
      "Epoch 3672/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4014 - val_loss: 1.1647\n",
      "Epoch 3673/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4832 - val_loss: 1.2215\n",
      "Epoch 3674/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4624 - val_loss: 1.2001\n",
      "Epoch 3675/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4289 - val_loss: 1.1553\n",
      "Epoch 3676/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4087 - val_loss: 1.1875\n",
      "Epoch 3677/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5089 - val_loss: 1.1750\n",
      "Epoch 3678/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4027 - val_loss: 1.1372\n",
      "Epoch 3679/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4656 - val_loss: 1.1754\n",
      "Epoch 3680/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3741 - val_loss: 1.1794\n",
      "Epoch 3681/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3593 - val_loss: 1.1794\n",
      "Epoch 3682/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3278 - val_loss: 1.2172\n",
      "Epoch 3683/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4366 - val_loss: 1.1465\n",
      "Epoch 3684/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2779 - val_loss: 1.1811\n",
      "Epoch 3685/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4551 - val_loss: 1.1410\n",
      "Epoch 3686/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3677 - val_loss: 1.1748\n",
      "Epoch 3687/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3864 - val_loss: 1.1779\n",
      "Epoch 3688/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4744 - val_loss: 1.1983\n",
      "Epoch 3689/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4684 - val_loss: 1.1830\n",
      "Epoch 3690/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3326 - val_loss: 1.1625\n",
      "Epoch 3691/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4440 - val_loss: 1.1424\n",
      "Epoch 3692/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3420 - val_loss: 1.1890\n",
      "Epoch 3693/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3711 - val_loss: 1.1563\n",
      "Epoch 3694/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3860 - val_loss: 1.1440\n",
      "Epoch 3695/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3914 - val_loss: 1.1762\n",
      "Epoch 3696/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4302 - val_loss: 1.1813\n",
      "Epoch 3697/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4546 - val_loss: 1.1686\n",
      "Epoch 3698/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5012 - val_loss: 1.1842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3699/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3470 - val_loss: 1.1786\n",
      "Epoch 3700/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4798 - val_loss: 1.1826\n",
      "Epoch 3701/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4300 - val_loss: 1.2019\n",
      "Epoch 3702/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3586 - val_loss: 1.1897\n",
      "Epoch 3703/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4056 - val_loss: 1.1634\n",
      "Epoch 3704/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3532 - val_loss: 1.1644\n",
      "Epoch 3705/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3096 - val_loss: 1.1634\n",
      "Epoch 3706/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4404 - val_loss: 1.1648\n",
      "Epoch 3707/20000\n",
      "1500/1500 [==============================] - 0s 44us/sample - loss: 1.3924 - val_loss: 1.1845\n",
      "Epoch 3708/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5234 - val_loss: 1.1717\n",
      "Epoch 3709/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3132 - val_loss: 1.1551\n",
      "Epoch 3710/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5309 - val_loss: 1.1788\n",
      "Epoch 3711/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3795 - val_loss: 1.2016\n",
      "Epoch 3712/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3553 - val_loss: 1.1520\n",
      "Epoch 3713/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3803 - val_loss: 1.2178\n",
      "Epoch 3714/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3651 - val_loss: 1.1847\n",
      "Epoch 3715/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3839 - val_loss: 1.1960\n",
      "Epoch 3716/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4594 - val_loss: 1.1469\n",
      "Epoch 3717/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3275 - val_loss: 1.1925\n",
      "Epoch 3718/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3999 - val_loss: 1.1335\n",
      "Epoch 3719/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3443 - val_loss: 1.2001\n",
      "Epoch 3720/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4393 - val_loss: 1.1584\n",
      "Epoch 3721/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4176 - val_loss: 1.1886\n",
      "Epoch 3722/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3220 - val_loss: 1.1722\n",
      "Epoch 3723/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3647 - val_loss: 1.1727\n",
      "Epoch 3724/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3094 - val_loss: 1.1426\n",
      "Epoch 3725/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3313 - val_loss: 1.1726\n",
      "Epoch 3726/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3912 - val_loss: 1.1888\n",
      "Epoch 3727/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4900 - val_loss: 1.1777\n",
      "Epoch 3728/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2954 - val_loss: 1.1707\n",
      "Epoch 3729/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4356 - val_loss: 1.1504\n",
      "Epoch 3730/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3779 - val_loss: 1.2187\n",
      "Epoch 3731/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4943 - val_loss: 1.1956\n",
      "Epoch 3732/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3405 - val_loss: 1.2144\n",
      "Epoch 3733/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4786 - val_loss: 1.1441\n",
      "Epoch 3734/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5173 - val_loss: 1.1789\n",
      "Epoch 3735/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4863 - val_loss: 1.1852\n",
      "Epoch 3736/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3624 - val_loss: 1.1756\n",
      "Epoch 3737/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2961 - val_loss: 1.1710\n",
      "Epoch 3738/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4510 - val_loss: 1.1330\n",
      "Epoch 3739/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4490 - val_loss: 1.1716\n",
      "Epoch 3740/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4744 - val_loss: 1.1701\n",
      "Epoch 3741/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3551 - val_loss: 1.1349\n",
      "Epoch 3742/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5390 - val_loss: 1.1912\n",
      "Epoch 3743/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3121 - val_loss: 1.1675\n",
      "Epoch 3744/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5423 - val_loss: 1.1248\n",
      "Epoch 3745/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5043 - val_loss: 1.2110\n",
      "Epoch 3746/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4796 - val_loss: 1.1359\n",
      "Epoch 3747/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3526 - val_loss: 1.1541\n",
      "Epoch 3748/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3601 - val_loss: 1.1895\n",
      "Epoch 3749/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5028 - val_loss: 1.1622\n",
      "Epoch 3750/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4250 - val_loss: 1.2161\n",
      "Epoch 3751/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3311 - val_loss: 1.1871\n",
      "Epoch 3752/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3590 - val_loss: 1.1832\n",
      "Epoch 3753/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3817 - val_loss: 1.1688\n",
      "Epoch 3754/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3188 - val_loss: 1.2065\n",
      "Epoch 3755/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3209 - val_loss: 1.1682\n",
      "Epoch 3756/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3752 - val_loss: 1.1647\n",
      "Epoch 3757/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5467 - val_loss: 1.2124\n",
      "Epoch 3758/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4030 - val_loss: 1.1401\n",
      "Epoch 3759/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4441 - val_loss: 1.1696\n",
      "Epoch 3760/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4385 - val_loss: 1.1651\n",
      "Epoch 3761/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4129 - val_loss: 1.1342\n",
      "Epoch 3762/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3337 - val_loss: 1.1994\n",
      "Epoch 3763/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4921 - val_loss: 1.1564\n",
      "Epoch 3764/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.2811 - val_loss: 1.1577\n",
      "Epoch 3765/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4754 - val_loss: 1.2100\n",
      "Epoch 3766/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3542 - val_loss: 1.1816\n",
      "Epoch 3767/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5106 - val_loss: 1.2022\n",
      "Epoch 3768/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3526 - val_loss: 1.1685\n",
      "Epoch 3769/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3254 - val_loss: 1.1500\n",
      "Epoch 3770/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3756 - val_loss: 1.1533\n",
      "Epoch 3771/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3251 - val_loss: 1.1607\n",
      "Epoch 3772/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3368 - val_loss: 1.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3773/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4226 - val_loss: 1.1430\n",
      "Epoch 3774/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4764 - val_loss: 1.1489\n",
      "Epoch 3775/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3036 - val_loss: 1.1654\n",
      "Epoch 3776/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5229 - val_loss: 1.1538\n",
      "Epoch 3777/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3640 - val_loss: 1.1930\n",
      "Epoch 3778/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3605 - val_loss: 1.1916\n",
      "Epoch 3779/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.2930 - val_loss: 1.1668\n",
      "Epoch 3780/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5105 - val_loss: 1.2220\n",
      "Epoch 3781/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4181 - val_loss: 1.2070\n",
      "Epoch 3782/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3709 - val_loss: 1.1507\n",
      "Epoch 3783/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2612 - val_loss: 1.1611\n",
      "Epoch 3784/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3694 - val_loss: 1.1868\n",
      "Epoch 3785/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2992 - val_loss: 1.1260\n",
      "Epoch 3786/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4028 - val_loss: 1.1779\n",
      "Epoch 3787/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4638 - val_loss: 1.1308\n",
      "Epoch 3788/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4847 - val_loss: 1.2108\n",
      "Epoch 3789/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4682 - val_loss: 1.1478\n",
      "Epoch 3790/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5178 - val_loss: 1.1662\n",
      "Epoch 3791/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4136 - val_loss: 1.1505\n",
      "Epoch 3792/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4989 - val_loss: 1.1786\n",
      "Epoch 3793/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4326 - val_loss: 1.1422\n",
      "Epoch 3794/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3446 - val_loss: 1.1819\n",
      "Epoch 3795/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3154 - val_loss: 1.1491\n",
      "Epoch 3796/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5312 - val_loss: 1.2194\n",
      "Epoch 3797/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4972 - val_loss: 1.1470\n",
      "Epoch 3798/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3410 - val_loss: 1.1307\n",
      "Epoch 3799/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3707 - val_loss: 1.1767\n",
      "Epoch 3800/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3326 - val_loss: 1.1283\n",
      "Epoch 3801/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4433 - val_loss: 1.1717\n",
      "Epoch 3802/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3228 - val_loss: 1.1765\n",
      "Epoch 3803/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3299 - val_loss: 1.1687\n",
      "Epoch 3804/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3127 - val_loss: 1.1852\n",
      "Epoch 3805/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2976 - val_loss: 1.1625\n",
      "Epoch 3806/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4496 - val_loss: 1.1876\n",
      "Epoch 3807/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4329 - val_loss: 1.1776\n",
      "Epoch 3808/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4115 - val_loss: 1.1694\n",
      "Epoch 3809/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3714 - val_loss: 1.1549\n",
      "Epoch 3810/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3506 - val_loss: 1.1539\n",
      "Epoch 3811/20000\n",
      "1500/1500 [==============================] - 0s 47us/sample - loss: 1.4651 - val_loss: 1.1582\n",
      "Epoch 3812/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5386 - val_loss: 1.1969\n",
      "Epoch 3813/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3994 - val_loss: 1.1776\n",
      "Epoch 3814/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4523 - val_loss: 1.1848\n",
      "Epoch 3815/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3826 - val_loss: 1.1725\n",
      "Epoch 3816/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4697 - val_loss: 1.1671\n",
      "Epoch 3817/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4556 - val_loss: 1.1418\n",
      "Epoch 3818/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2838 - val_loss: 1.1953\n",
      "Epoch 3819/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3623 - val_loss: 1.1522\n",
      "Epoch 3820/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3814 - val_loss: 1.1791\n",
      "Epoch 3821/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4317 - val_loss: 1.1784\n",
      "Epoch 3822/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4245 - val_loss: 1.2186\n",
      "Epoch 3823/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4577 - val_loss: 1.1630\n",
      "Epoch 3824/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3155 - val_loss: 1.1639\n",
      "Epoch 3825/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5710 - val_loss: 1.2469\n",
      "Epoch 3826/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5208 - val_loss: 1.2014\n",
      "Epoch 3827/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4080 - val_loss: 1.2264\n",
      "Epoch 3828/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4989 - val_loss: 1.1891\n",
      "Epoch 3829/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4587 - val_loss: 1.1809\n",
      "Epoch 3830/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4705 - val_loss: 1.1972\n",
      "Epoch 3831/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4828 - val_loss: 1.1534\n",
      "Epoch 3832/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4471 - val_loss: 1.1897\n",
      "Epoch 3833/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4072 - val_loss: 1.1521\n",
      "Epoch 3834/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4500 - val_loss: 1.1834\n",
      "Epoch 3835/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3450 - val_loss: 1.1340\n",
      "Epoch 3836/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3631 - val_loss: 1.1467\n",
      "Epoch 3837/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4128 - val_loss: 1.1483\n",
      "Epoch 3838/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4038 - val_loss: 1.1684\n",
      "Epoch 3839/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4749 - val_loss: 1.2204\n",
      "Epoch 3840/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3422 - val_loss: 1.1507\n",
      "Epoch 3841/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3917 - val_loss: 1.1643\n",
      "Epoch 3842/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3911 - val_loss: 1.1363\n",
      "Epoch 3843/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2431 - val_loss: 1.2109\n",
      "Epoch 3844/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4548 - val_loss: 1.2207\n",
      "Epoch 3845/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4178 - val_loss: 1.1727\n",
      "Epoch 3846/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.2859 - val_loss: 1.1966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3847/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4170 - val_loss: 1.1608\n",
      "Epoch 3848/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4056 - val_loss: 1.1322\n",
      "Epoch 3849/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3535 - val_loss: 1.1697\n",
      "Epoch 3850/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4622 - val_loss: 1.2216\n",
      "Epoch 3851/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4292 - val_loss: 1.1497\n",
      "Epoch 3852/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3386 - val_loss: 1.2004\n",
      "Epoch 3853/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4130 - val_loss: 1.2067\n",
      "Epoch 3854/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4946 - val_loss: 1.1558\n",
      "Epoch 3855/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3842 - val_loss: 1.1636\n",
      "Epoch 3856/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4025 - val_loss: 1.1779\n",
      "Epoch 3857/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4612 - val_loss: 1.1597\n",
      "Epoch 3858/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4494 - val_loss: 1.1782\n",
      "Epoch 3859/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3459 - val_loss: 1.1735\n",
      "Epoch 3860/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3039 - val_loss: 1.1901\n",
      "Epoch 3861/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3695 - val_loss: 1.1829\n",
      "Epoch 3862/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4098 - val_loss: 1.2095\n",
      "Epoch 3863/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4814 - val_loss: 1.2075\n",
      "Epoch 3864/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5036 - val_loss: 1.1973\n",
      "Epoch 3865/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4072 - val_loss: 1.2167\n",
      "Epoch 3866/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3534 - val_loss: 1.1653\n",
      "Epoch 3867/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4890 - val_loss: 1.2135\n",
      "Epoch 3868/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3771 - val_loss: 1.2476\n",
      "Epoch 3869/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3346 - val_loss: 1.2244\n",
      "Epoch 3870/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4005 - val_loss: 1.1693\n",
      "Epoch 3871/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4111 - val_loss: 1.1864\n",
      "Epoch 3872/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3463 - val_loss: 1.2006\n",
      "Epoch 3873/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4216 - val_loss: 1.1944\n",
      "Epoch 3874/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4943 - val_loss: 1.2237\n",
      "Epoch 3875/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3285 - val_loss: 1.1752\n",
      "Epoch 3876/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5262 - val_loss: 1.2367\n",
      "Epoch 3877/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4111 - val_loss: 1.2025\n",
      "Epoch 3878/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3663 - val_loss: 1.2031\n",
      "Epoch 3879/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4254 - val_loss: 1.2121\n",
      "Epoch 3880/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4392 - val_loss: 1.2117\n",
      "Epoch 3881/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4795 - val_loss: 1.2183\n",
      "Epoch 3882/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4144 - val_loss: 1.1865\n",
      "Epoch 3883/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4357 - val_loss: 1.1801\n",
      "Epoch 3884/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5019 - val_loss: 1.2394\n",
      "Epoch 3885/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3951 - val_loss: 1.1803\n",
      "Epoch 3886/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4309 - val_loss: 1.2046\n",
      "Epoch 3887/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4037 - val_loss: 1.1725\n",
      "Epoch 3888/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4425 - val_loss: 1.1972\n",
      "Epoch 3889/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3925 - val_loss: 1.1524\n",
      "Epoch 3890/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5017 - val_loss: 1.2061\n",
      "Epoch 3891/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3590 - val_loss: 1.1785\n",
      "Epoch 3892/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2614 - val_loss: 1.2030\n",
      "Epoch 3893/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3270 - val_loss: 1.1523\n",
      "Epoch 3894/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3470 - val_loss: 1.1473\n",
      "Epoch 3895/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2875 - val_loss: 1.1670\n",
      "Epoch 3896/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4090 - val_loss: 1.1694\n",
      "Epoch 3897/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3786 - val_loss: 1.1981\n",
      "Epoch 3898/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4407 - val_loss: 1.1651\n",
      "Epoch 3899/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4060 - val_loss: 1.1469\n",
      "Epoch 3900/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4010 - val_loss: 1.1803\n",
      "Epoch 3901/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3230 - val_loss: 1.1556\n",
      "Epoch 3902/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3749 - val_loss: 1.1884\n",
      "Epoch 3903/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2664 - val_loss: 1.1822\n",
      "Epoch 3904/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4346 - val_loss: 1.1844\n",
      "Epoch 3905/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4210 - val_loss: 1.2325\n",
      "Epoch 3906/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3238 - val_loss: 1.1530\n",
      "Epoch 3907/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3473 - val_loss: 1.1969\n",
      "Epoch 3908/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3174 - val_loss: 1.1920\n",
      "Epoch 3909/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3856 - val_loss: 1.1463\n",
      "Epoch 3910/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2861 - val_loss: 1.1773\n",
      "Epoch 3911/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4330 - val_loss: 1.1714\n",
      "Epoch 3912/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3849 - val_loss: 1.1646\n",
      "Epoch 3913/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4559 - val_loss: 1.1444\n",
      "Epoch 3914/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4907 - val_loss: 1.1824\n",
      "Epoch 3915/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3949 - val_loss: 1.1642\n",
      "Epoch 3916/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4794 - val_loss: 1.1140\n",
      "Epoch 3917/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4275 - val_loss: 1.1866\n",
      "Epoch 3918/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3594 - val_loss: 1.2404\n",
      "Epoch 3919/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4389 - val_loss: 1.1956\n",
      "Epoch 3920/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3817 - val_loss: 1.1563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3921/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4132 - val_loss: 1.1950\n",
      "Epoch 3922/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3478 - val_loss: 1.1939\n",
      "Epoch 3923/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3254 - val_loss: 1.1634\n",
      "Epoch 3924/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5032 - val_loss: 1.1413\n",
      "Epoch 3925/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4298 - val_loss: 1.1953\n",
      "Epoch 3926/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3166 - val_loss: 1.1461\n",
      "Epoch 3927/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4351 - val_loss: 1.1672\n",
      "Epoch 3928/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3491 - val_loss: 1.2177\n",
      "Epoch 3929/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4272 - val_loss: 1.1893\n",
      "Epoch 3930/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3457 - val_loss: 1.1714\n",
      "Epoch 3931/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4628 - val_loss: 1.2013\n",
      "Epoch 3932/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4207 - val_loss: 1.1568\n",
      "Epoch 3933/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3604 - val_loss: 1.1588\n",
      "Epoch 3934/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3656 - val_loss: 1.2408\n",
      "Epoch 3935/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4316 - val_loss: 1.2131\n",
      "Epoch 3936/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3605 - val_loss: 1.1705\n",
      "Epoch 3937/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5094 - val_loss: 1.1891\n",
      "Epoch 3938/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3178 - val_loss: 1.1660\n",
      "Epoch 3939/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4394 - val_loss: 1.1368\n",
      "Epoch 3940/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4433 - val_loss: 1.1266\n",
      "Epoch 3941/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.2884 - val_loss: 1.1386\n",
      "Epoch 3942/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3693 - val_loss: 1.1451\n",
      "Epoch 3943/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5011 - val_loss: 1.1368\n",
      "Epoch 3944/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3978 - val_loss: 1.1872\n",
      "Epoch 3945/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3672 - val_loss: 1.1658\n",
      "Epoch 3946/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4944 - val_loss: 1.1870\n",
      "Epoch 3947/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6077 - val_loss: 1.1855\n",
      "Epoch 3948/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5083 - val_loss: 1.2199\n",
      "Epoch 3949/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3483 - val_loss: 1.1492\n",
      "Epoch 3950/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3718 - val_loss: 1.1684\n",
      "Epoch 3951/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3474 - val_loss: 1.1349\n",
      "Epoch 3952/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3323 - val_loss: 1.2044\n",
      "Epoch 3953/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4216 - val_loss: 1.1960\n",
      "Epoch 3954/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4115 - val_loss: 1.1882\n",
      "Epoch 3955/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3846 - val_loss: 1.1720\n",
      "Epoch 3956/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3709 - val_loss: 1.2366\n",
      "Epoch 3957/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4414 - val_loss: 1.2397\n",
      "Epoch 3958/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.3391 - val_loss: 1.2929\n",
      "Epoch 3959/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3679 - val_loss: 1.2320\n",
      "Epoch 3960/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4159 - val_loss: 1.2086\n",
      "Epoch 3961/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3838 - val_loss: 1.1832\n",
      "Epoch 3962/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3071 - val_loss: 1.1765\n",
      "Epoch 3963/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4255 - val_loss: 1.1972\n",
      "Epoch 3964/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3740 - val_loss: 1.2064\n",
      "Epoch 3965/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4823 - val_loss: 1.2693\n",
      "Epoch 3966/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3830 - val_loss: 1.1926\n",
      "Epoch 3967/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4483 - val_loss: 1.2039\n",
      "Epoch 3968/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4504 - val_loss: 1.2228\n",
      "Epoch 3969/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4585 - val_loss: 1.2470\n",
      "Epoch 3970/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3431 - val_loss: 1.1920\n",
      "Epoch 3971/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4210 - val_loss: 1.2538\n",
      "Epoch 3972/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4852 - val_loss: 1.1641\n",
      "Epoch 3973/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4310 - val_loss: 1.2645\n",
      "Epoch 3974/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4752 - val_loss: 1.1956\n",
      "Epoch 3975/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4061 - val_loss: 1.1858\n",
      "Epoch 3976/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4259 - val_loss: 1.1786\n",
      "Epoch 3977/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3864 - val_loss: 1.1791\n",
      "Epoch 3978/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5106 - val_loss: 1.1629\n",
      "Epoch 3979/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4367 - val_loss: 1.1934\n",
      "Epoch 3980/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4149 - val_loss: 1.1433\n",
      "Epoch 3981/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3928 - val_loss: 1.1784\n",
      "Epoch 3982/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5724 - val_loss: 1.1562\n",
      "Epoch 3983/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3970 - val_loss: 1.2092\n",
      "Epoch 3984/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4330 - val_loss: 1.1307\n",
      "Epoch 3985/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3811 - val_loss: 1.1764\n",
      "Epoch 3986/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4672 - val_loss: 1.1995\n",
      "Epoch 3987/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3862 - val_loss: 1.2264\n",
      "Epoch 3988/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3125 - val_loss: 1.1367\n",
      "Epoch 3989/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3997 - val_loss: 1.1874\n",
      "Epoch 3990/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3727 - val_loss: 1.2236\n",
      "Epoch 3991/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4934 - val_loss: 1.1335\n",
      "Epoch 3992/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4438 - val_loss: 1.1969\n",
      "Epoch 3993/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4263 - val_loss: 1.1656\n",
      "Epoch 3994/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3372 - val_loss: 1.1480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3995/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4077 - val_loss: 1.1663\n",
      "Epoch 3996/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.4890 - val_loss: 1.1659\n",
      "Epoch 3997/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4500 - val_loss: 1.1252\n",
      "Epoch 3998/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3305 - val_loss: 1.1732\n",
      "Epoch 3999/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3931 - val_loss: 1.1638\n",
      "Epoch 4000/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5415 - val_loss: 1.1884\n",
      "Epoch 4001/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4230 - val_loss: 1.1678\n",
      "Epoch 4002/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4305 - val_loss: 1.1582\n",
      "Epoch 4003/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3941 - val_loss: 1.1481\n",
      "Epoch 4004/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3458 - val_loss: 1.1341\n",
      "Epoch 4005/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3460 - val_loss: 1.1176\n",
      "Epoch 4006/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4418 - val_loss: 1.1431\n",
      "Epoch 4007/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3924 - val_loss: 1.1475\n",
      "Epoch 4008/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4582 - val_loss: 1.2122\n",
      "Epoch 4009/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4043 - val_loss: 1.2127\n",
      "Epoch 4010/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3770 - val_loss: 1.2113\n",
      "Epoch 4011/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4332 - val_loss: 1.1979\n",
      "Epoch 4012/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3491 - val_loss: 1.1910\n",
      "Epoch 4013/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3777 - val_loss: 1.2175\n",
      "Epoch 4014/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3895 - val_loss: 1.1718\n",
      "Epoch 4015/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4830 - val_loss: 1.3059\n",
      "Epoch 4016/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4118 - val_loss: 1.2269\n",
      "Epoch 4017/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4090 - val_loss: 1.2144\n",
      "Epoch 4018/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3954 - val_loss: 1.1981\n",
      "Epoch 4019/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3571 - val_loss: 1.2013\n",
      "Epoch 4020/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4819 - val_loss: 1.2206\n",
      "Epoch 4021/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5149 - val_loss: 1.1991\n",
      "Epoch 4022/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3555 - val_loss: 1.1681\n",
      "Epoch 4023/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3352 - val_loss: 1.1384\n",
      "Epoch 4024/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4812 - val_loss: 1.1393\n",
      "Epoch 4025/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4235 - val_loss: 1.1609\n",
      "Epoch 4026/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4187 - val_loss: 1.1442\n",
      "Epoch 4027/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2979 - val_loss: 1.1408\n",
      "Epoch 4028/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3118 - val_loss: 1.1769\n",
      "Epoch 4029/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3343 - val_loss: 1.1798\n",
      "Epoch 4030/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3362 - val_loss: 1.1928\n",
      "Epoch 4031/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3835 - val_loss: 1.2109\n",
      "Epoch 4032/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4335 - val_loss: 1.2665\n",
      "Epoch 4033/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3918 - val_loss: 1.1819\n",
      "Epoch 4034/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3619 - val_loss: 1.2134\n",
      "Epoch 4035/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3963 - val_loss: 1.1707\n",
      "Epoch 4036/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5147 - val_loss: 1.2070\n",
      "Epoch 4037/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3357 - val_loss: 1.1641\n",
      "Epoch 4038/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4984 - val_loss: 1.2095\n",
      "Epoch 4039/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3541 - val_loss: 1.2115\n",
      "Epoch 4040/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3780 - val_loss: 1.1618\n",
      "Epoch 4041/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3973 - val_loss: 1.2168\n",
      "Epoch 4042/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3569 - val_loss: 1.1719\n",
      "Epoch 4043/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4367 - val_loss: 1.1434\n",
      "Epoch 4044/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4039 - val_loss: 1.1815\n",
      "Epoch 4045/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3267 - val_loss: 1.1680\n",
      "Epoch 4046/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3727 - val_loss: 1.1381\n",
      "Epoch 4047/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4567 - val_loss: 1.1889\n",
      "Epoch 4048/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3177 - val_loss: 1.1341\n",
      "Epoch 4049/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4422 - val_loss: 1.1540\n",
      "Epoch 4050/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4529 - val_loss: 1.2320\n",
      "Epoch 4051/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3824 - val_loss: 1.1849\n",
      "Epoch 4052/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4655 - val_loss: 1.1357\n",
      "Epoch 4053/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3605 - val_loss: 1.2089\n",
      "Epoch 4054/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4057 - val_loss: 1.1893\n",
      "Epoch 4055/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4157 - val_loss: 1.3312\n",
      "Epoch 4056/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3924 - val_loss: 1.3019\n",
      "Epoch 4057/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4927 - val_loss: 1.2052\n",
      "Epoch 4058/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3289 - val_loss: 1.1660\n",
      "Epoch 4059/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4203 - val_loss: 1.1669\n",
      "Epoch 4060/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3906 - val_loss: 1.1540\n",
      "Epoch 4061/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3775 - val_loss: 1.1523\n",
      "Epoch 4062/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4693 - val_loss: 1.1533\n",
      "Epoch 4063/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4744 - val_loss: 1.1451\n",
      "Epoch 4064/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5134 - val_loss: 1.2261\n",
      "Epoch 4065/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5310 - val_loss: 1.2021\n",
      "Epoch 4066/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4315 - val_loss: 1.1844\n",
      "Epoch 4067/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3342 - val_loss: 1.2443\n",
      "Epoch 4068/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.3675 - val_loss: 1.2484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4069/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3914 - val_loss: 1.1930\n",
      "Epoch 4070/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3724 - val_loss: 1.1525\n",
      "Epoch 4071/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4413 - val_loss: 1.2015\n",
      "Epoch 4072/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4658 - val_loss: 1.2069\n",
      "Epoch 4073/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3161 - val_loss: 1.2020\n",
      "Epoch 4074/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4099 - val_loss: 1.2591\n",
      "Epoch 4075/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5218 - val_loss: 1.1713\n",
      "Epoch 4076/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3154 - val_loss: 1.2293\n",
      "Epoch 4077/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2773 - val_loss: 1.1684\n",
      "Epoch 4078/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3378 - val_loss: 1.2540\n",
      "Epoch 4079/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4656 - val_loss: 1.1486\n",
      "Epoch 4080/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3244 - val_loss: 1.1786\n",
      "Epoch 4081/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4549 - val_loss: 1.1647\n",
      "Epoch 4082/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3034 - val_loss: 1.1754\n",
      "Epoch 4083/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4838 - val_loss: 1.1776\n",
      "Epoch 4084/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3731 - val_loss: 1.1605\n",
      "Epoch 4085/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3893 - val_loss: 1.1747\n",
      "Epoch 4086/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5576 - val_loss: 1.1517\n",
      "Epoch 4087/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3032 - val_loss: 1.1702\n",
      "Epoch 4088/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4537 - val_loss: 1.2068\n",
      "Epoch 4089/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3986 - val_loss: 1.1968\n",
      "Epoch 4090/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4072 - val_loss: 1.2284\n",
      "Epoch 4091/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3478 - val_loss: 1.3289\n",
      "Epoch 4092/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3345 - val_loss: 1.2065\n",
      "Epoch 4093/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5475 - val_loss: 1.1412\n",
      "Epoch 4094/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3792 - val_loss: 1.2469\n",
      "Epoch 4095/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4662 - val_loss: 1.1973\n",
      "Epoch 4096/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4036 - val_loss: 1.2225\n",
      "Epoch 4097/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3806 - val_loss: 1.2116\n",
      "Epoch 4098/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3330 - val_loss: 1.1617\n",
      "Epoch 4099/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3403 - val_loss: 1.1826\n",
      "Epoch 4100/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3076 - val_loss: 1.1364\n",
      "Epoch 4101/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4482 - val_loss: 1.1512\n",
      "Epoch 4102/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3650 - val_loss: 1.1617\n",
      "Epoch 4103/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.2992 - val_loss: 1.2325\n",
      "Epoch 4104/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4799 - val_loss: 1.1843\n",
      "Epoch 4105/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3779 - val_loss: 1.2140\n",
      "Epoch 4106/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4637 - val_loss: 1.2064\n",
      "Epoch 4107/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3444 - val_loss: 1.2312\n",
      "Epoch 4108/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4714 - val_loss: 1.2335\n",
      "Epoch 4109/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4693 - val_loss: 1.1771\n",
      "Epoch 4110/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4898 - val_loss: 1.2033\n",
      "Epoch 4111/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5106 - val_loss: 1.1550\n",
      "Epoch 4112/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4858 - val_loss: 1.1399\n",
      "Epoch 4113/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4309 - val_loss: 1.1965\n",
      "Epoch 4114/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3899 - val_loss: 1.2448\n",
      "Epoch 4115/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3906 - val_loss: 1.1739\n",
      "Epoch 4116/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4010 - val_loss: 1.1735\n",
      "Epoch 4117/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4113 - val_loss: 1.1759\n",
      "Epoch 4118/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4052 - val_loss: 1.2380\n",
      "Epoch 4119/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3569 - val_loss: 1.1382\n",
      "Epoch 4120/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3992 - val_loss: 1.1566\n",
      "Epoch 4121/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4694 - val_loss: 1.2134\n",
      "Epoch 4122/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4629 - val_loss: 1.2121\n",
      "Epoch 4123/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4620 - val_loss: 1.2125\n",
      "Epoch 4124/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4514 - val_loss: 1.1999\n",
      "Epoch 4125/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3856 - val_loss: 1.1912\n",
      "Epoch 4126/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3619 - val_loss: 1.2128\n",
      "Epoch 4127/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4364 - val_loss: 1.2787\n",
      "Epoch 4128/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3888 - val_loss: 1.2342\n",
      "Epoch 4129/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3039 - val_loss: 1.2172\n",
      "Epoch 4130/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3758 - val_loss: 1.2010\n",
      "Epoch 4131/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4169 - val_loss: 1.2006\n",
      "Epoch 4132/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4024 - val_loss: 1.1990\n",
      "Epoch 4133/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4285 - val_loss: 1.1946\n",
      "Epoch 4134/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3779 - val_loss: 1.2412\n",
      "Epoch 4135/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3747 - val_loss: 1.1348\n",
      "Epoch 4136/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5080 - val_loss: 1.1911\n",
      "Epoch 4137/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4398 - val_loss: 1.1394\n",
      "Epoch 4138/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3510 - val_loss: 1.1568\n",
      "Epoch 4139/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4040 - val_loss: 1.1268\n",
      "Epoch 4140/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3464 - val_loss: 1.1479\n",
      "Epoch 4141/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4049 - val_loss: 1.1445\n",
      "Epoch 4142/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4809 - val_loss: 1.1473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4143/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3467 - val_loss: 1.1867\n",
      "Epoch 4144/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3925 - val_loss: 1.1824\n",
      "Epoch 4145/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3252 - val_loss: 1.1692\n",
      "Epoch 4146/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3405 - val_loss: 1.1550\n",
      "Epoch 4147/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3605 - val_loss: 1.1731\n",
      "Epoch 4148/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3962 - val_loss: 1.1388\n",
      "Epoch 4149/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5197 - val_loss: 1.1596\n",
      "Epoch 4150/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4172 - val_loss: 1.1776\n",
      "Epoch 4151/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4145 - val_loss: 1.1816\n",
      "Epoch 4152/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3034 - val_loss: 1.1597\n",
      "Epoch 4153/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3675 - val_loss: 1.2086\n",
      "Epoch 4154/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3863 - val_loss: 1.1654\n",
      "Epoch 4155/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3105 - val_loss: 1.1690\n",
      "Epoch 4156/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4783 - val_loss: 1.1488\n",
      "Epoch 4157/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4155 - val_loss: 1.1497\n",
      "Epoch 4158/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3517 - val_loss: 1.1748\n",
      "Epoch 4159/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.4689 - val_loss: 1.1497\n",
      "Epoch 4160/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4423 - val_loss: 1.1631\n",
      "Epoch 4161/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3679 - val_loss: 1.1509\n",
      "Epoch 4162/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4779 - val_loss: 1.1547\n",
      "Epoch 4163/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4957 - val_loss: 1.1304\n",
      "Epoch 4164/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3872 - val_loss: 1.2078\n",
      "Epoch 4165/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5360 - val_loss: 1.1636\n",
      "Epoch 4166/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3383 - val_loss: 1.1827\n",
      "Epoch 4167/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3111 - val_loss: 1.1610\n",
      "Epoch 4168/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.4476 - val_loss: 1.1543\n",
      "Epoch 4169/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4899 - val_loss: 1.2048\n",
      "Epoch 4170/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3651 - val_loss: 1.2442\n",
      "Epoch 4171/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4014 - val_loss: 1.1941\n",
      "Epoch 4172/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5236 - val_loss: 1.2112\n",
      "Epoch 4173/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4613 - val_loss: 1.2101\n",
      "Epoch 4174/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4268 - val_loss: 1.1724\n",
      "Epoch 4175/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4467 - val_loss: 1.1430\n",
      "Epoch 4176/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4293 - val_loss: 1.2889\n",
      "Epoch 4177/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3981 - val_loss: 1.3084\n",
      "Epoch 4178/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4474 - val_loss: 1.3096\n",
      "Epoch 4179/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3821 - val_loss: 1.3731\n",
      "Epoch 4180/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3437 - val_loss: 1.2365\n",
      "Epoch 4181/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3349 - val_loss: 1.3212\n",
      "Epoch 4182/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3935 - val_loss: 1.2212\n",
      "Epoch 4183/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4133 - val_loss: 1.2236\n",
      "Epoch 4184/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5019 - val_loss: 1.2033\n",
      "Epoch 4185/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4600 - val_loss: 1.2298\n",
      "Epoch 4186/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4185 - val_loss: 1.1797\n",
      "Epoch 4187/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3651 - val_loss: 1.2043\n",
      "Epoch 4188/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4718 - val_loss: 1.1478\n",
      "Epoch 4189/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4616 - val_loss: 1.1622\n",
      "Epoch 4190/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4212 - val_loss: 1.1554\n",
      "Epoch 4191/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4026 - val_loss: 1.1936\n",
      "Epoch 4192/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3938 - val_loss: 1.1605\n",
      "Epoch 4193/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2938 - val_loss: 1.1920\n",
      "Epoch 4194/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3849 - val_loss: 1.1805\n",
      "Epoch 4195/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3781 - val_loss: 1.2221\n",
      "Epoch 4196/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4434 - val_loss: 1.1336\n",
      "Epoch 4197/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4934 - val_loss: 1.1440\n",
      "Epoch 4198/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4904 - val_loss: 1.1715\n",
      "Epoch 4199/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4452 - val_loss: 1.2293\n",
      "Epoch 4200/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2888 - val_loss: 1.1443\n",
      "Epoch 4201/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3501 - val_loss: 1.1282\n",
      "Epoch 4202/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.2890 - val_loss: 1.1513\n",
      "Epoch 4203/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3097 - val_loss: 1.1331\n",
      "Epoch 4204/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4069 - val_loss: 1.1927\n",
      "Epoch 4205/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2751 - val_loss: 1.1379\n",
      "Epoch 4206/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2698 - val_loss: 1.1539\n",
      "Epoch 4207/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3089 - val_loss: 1.1900\n",
      "Epoch 4208/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5043 - val_loss: 1.2507\n",
      "Epoch 4209/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4168 - val_loss: 1.2078\n",
      "Epoch 4210/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3732 - val_loss: 1.3053\n",
      "Epoch 4211/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2710 - val_loss: 1.1927\n",
      "Epoch 4212/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5913 - val_loss: 1.2640\n",
      "Epoch 4213/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4192 - val_loss: 1.1612\n",
      "Epoch 4214/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4849 - val_loss: 1.1684\n",
      "Epoch 4215/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3314 - val_loss: 1.1513\n",
      "Epoch 4216/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5286 - val_loss: 1.1528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4217/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3906 - val_loss: 1.1752\n",
      "Epoch 4218/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4757 - val_loss: 1.1382\n",
      "Epoch 4219/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4555 - val_loss: 1.1575\n",
      "Epoch 4220/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3200 - val_loss: 1.1630\n",
      "Epoch 4221/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4906 - val_loss: 1.2013\n",
      "Epoch 4222/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4258 - val_loss: 1.2211\n",
      "Epoch 4223/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3093 - val_loss: 1.1468\n",
      "Epoch 4224/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3624 - val_loss: 1.1663\n",
      "Epoch 4225/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4224 - val_loss: 1.1582\n",
      "Epoch 4226/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3730 - val_loss: 1.1421\n",
      "Epoch 4227/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4060 - val_loss: 1.1579\n",
      "Epoch 4228/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4104 - val_loss: 1.1487\n",
      "Epoch 4229/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4398 - val_loss: 1.1463\n",
      "Epoch 4230/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3264 - val_loss: 1.1530\n",
      "Epoch 4231/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3885 - val_loss: 1.1670\n",
      "Epoch 4232/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3532 - val_loss: 1.2052\n",
      "Epoch 4233/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4609 - val_loss: 1.1628\n",
      "Epoch 4234/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4619 - val_loss: 1.1303\n",
      "Epoch 4235/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3175 - val_loss: 1.1723\n",
      "Epoch 4236/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3147 - val_loss: 1.1597\n",
      "Epoch 4237/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3076 - val_loss: 1.1583\n",
      "Epoch 4238/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3370 - val_loss: 1.1343\n",
      "Epoch 4239/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3506 - val_loss: 1.1303\n",
      "Epoch 4240/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3247 - val_loss: 1.1393\n",
      "Epoch 4241/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5534 - val_loss: 1.1647\n",
      "Epoch 4242/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3645 - val_loss: 1.1674\n",
      "Epoch 4243/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4273 - val_loss: 1.1848\n",
      "Epoch 4244/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4552 - val_loss: 1.1959\n",
      "Epoch 4245/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4064 - val_loss: 1.1754\n",
      "Epoch 4246/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3899 - val_loss: 1.2055\n",
      "Epoch 4247/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4950 - val_loss: 1.2188\n",
      "Epoch 4248/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5205 - val_loss: 1.2128\n",
      "Epoch 4249/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4007 - val_loss: 1.2578\n",
      "Epoch 4250/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4066 - val_loss: 1.2372\n",
      "Epoch 4251/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3866 - val_loss: 1.2109\n",
      "Epoch 4252/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3869 - val_loss: 1.2172\n",
      "Epoch 4253/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3665 - val_loss: 1.2877\n",
      "Epoch 4254/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4066 - val_loss: 1.2048\n",
      "Epoch 4255/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3131 - val_loss: 1.2517\n",
      "Epoch 4256/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4197 - val_loss: 1.1995\n",
      "Epoch 4257/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4539 - val_loss: 1.2179\n",
      "Epoch 4258/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4980 - val_loss: 1.2043\n",
      "Epoch 4259/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3450 - val_loss: 1.1538\n",
      "Epoch 4260/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3846 - val_loss: 1.1437\n",
      "Epoch 4261/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3687 - val_loss: 1.1527\n",
      "Epoch 4262/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4325 - val_loss: 1.1210\n",
      "Epoch 4263/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4041 - val_loss: 1.2024\n",
      "Epoch 4264/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3233 - val_loss: 1.1552\n",
      "Epoch 4265/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4818 - val_loss: 1.1542\n",
      "Epoch 4266/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3589 - val_loss: 1.1762\n",
      "Epoch 4267/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4772 - val_loss: 1.1883\n",
      "Epoch 4268/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3266 - val_loss: 1.2181\n",
      "Epoch 4269/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3266 - val_loss: 1.1700\n",
      "Epoch 4270/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3953 - val_loss: 1.2978\n",
      "Epoch 4271/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4082 - val_loss: 1.1679\n",
      "Epoch 4272/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5298 - val_loss: 1.1631\n",
      "Epoch 4273/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4718 - val_loss: 1.1770\n",
      "Epoch 4274/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3216 - val_loss: 1.1554\n",
      "Epoch 4275/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4549 - val_loss: 1.1959\n",
      "Epoch 4276/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4055 - val_loss: 1.2424\n",
      "Epoch 4277/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4296 - val_loss: 1.1816\n",
      "Epoch 4278/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4108 - val_loss: 1.1978\n",
      "Epoch 4279/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4129 - val_loss: 1.2430\n",
      "Epoch 4280/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3272 - val_loss: 1.1496\n",
      "Epoch 4281/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3604 - val_loss: 1.1286\n",
      "Epoch 4282/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3948 - val_loss: 1.1873\n",
      "Epoch 4283/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5019 - val_loss: 1.2098\n",
      "Epoch 4284/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3024 - val_loss: 1.1526\n",
      "Epoch 4285/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4275 - val_loss: 1.1631\n",
      "Epoch 4286/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4021 - val_loss: 1.1853\n",
      "Epoch 4287/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3856 - val_loss: 1.2088\n",
      "Epoch 4288/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4201 - val_loss: 1.2487\n",
      "Epoch 4289/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3441 - val_loss: 1.1436\n",
      "Epoch 4290/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4569 - val_loss: 1.1405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4291/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5112 - val_loss: 1.2173\n",
      "Epoch 4292/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4373 - val_loss: 1.2017\n",
      "Epoch 4293/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4282 - val_loss: 1.1713\n",
      "Epoch 4294/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3043 - val_loss: 1.1658\n",
      "Epoch 4295/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4061 - val_loss: 1.1738\n",
      "Epoch 4296/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3985 - val_loss: 1.1685\n",
      "Epoch 4297/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4999 - val_loss: 1.1397\n",
      "Epoch 4298/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4331 - val_loss: 1.1788\n",
      "Epoch 4299/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3901 - val_loss: 1.1757\n",
      "Epoch 4300/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3956 - val_loss: 1.1684\n",
      "Epoch 4301/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4277 - val_loss: 1.1655\n",
      "Epoch 4302/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4541 - val_loss: 1.1329\n",
      "Epoch 4303/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4355 - val_loss: 1.1514\n",
      "Epoch 4304/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4861 - val_loss: 1.1402\n",
      "Epoch 4305/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3751 - val_loss: 1.1556\n",
      "Epoch 4306/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3725 - val_loss: 1.1466\n",
      "Epoch 4307/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4430 - val_loss: 1.1650\n",
      "Epoch 4308/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4400 - val_loss: 1.1539\n",
      "Epoch 4309/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3820 - val_loss: 1.1479\n",
      "Epoch 4310/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3364 - val_loss: 1.1413\n",
      "Epoch 4311/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3723 - val_loss: 1.2023\n",
      "Epoch 4312/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5262 - val_loss: 1.1723\n",
      "Epoch 4313/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3861 - val_loss: 1.1269\n",
      "Epoch 4314/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3860 - val_loss: 1.1387\n",
      "Epoch 4315/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5231 - val_loss: 1.1979\n",
      "Epoch 4316/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4189 - val_loss: 1.1474\n",
      "Epoch 4317/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5053 - val_loss: 1.1539\n",
      "Epoch 4318/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2960 - val_loss: 1.1325\n",
      "Epoch 4319/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3968 - val_loss: 1.1511\n",
      "Epoch 4320/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4279 - val_loss: 1.1963\n",
      "Epoch 4321/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3450 - val_loss: 1.1549\n",
      "Epoch 4322/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3415 - val_loss: 1.1504\n",
      "Epoch 4323/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3923 - val_loss: 1.1508\n",
      "Epoch 4324/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4048 - val_loss: 1.1361\n",
      "Epoch 4325/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3156 - val_loss: 1.1765\n",
      "Epoch 4326/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4673 - val_loss: 1.1304\n",
      "Epoch 4327/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4526 - val_loss: 1.1556\n",
      "Epoch 4328/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3411 - val_loss: 1.1371\n",
      "Epoch 4329/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4101 - val_loss: 1.2067\n",
      "Epoch 4330/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3628 - val_loss: 1.2145\n",
      "Epoch 4331/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3773 - val_loss: 1.2016\n",
      "Epoch 4332/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3764 - val_loss: 1.1971\n",
      "Epoch 4333/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4052 - val_loss: 1.1570\n",
      "Epoch 4334/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4346 - val_loss: 1.2312\n",
      "Epoch 4335/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3792 - val_loss: 1.1414\n",
      "Epoch 4336/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4506 - val_loss: 1.1690\n",
      "Epoch 4337/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3461 - val_loss: 1.1759\n",
      "Epoch 4338/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4420 - val_loss: 1.2091\n",
      "Epoch 4339/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3500 - val_loss: 1.1780\n",
      "Epoch 4340/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4860 - val_loss: 1.1774\n",
      "Epoch 4341/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4107 - val_loss: 1.1750\n",
      "Epoch 4342/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4171 - val_loss: 1.1377\n",
      "Epoch 4343/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4315 - val_loss: 1.1199\n",
      "Epoch 4344/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2850 - val_loss: 1.1827\n",
      "Epoch 4345/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3928 - val_loss: 1.1850\n",
      "Epoch 4346/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4380 - val_loss: 1.1906\n",
      "Epoch 4347/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4071 - val_loss: 1.2423\n",
      "Epoch 4348/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4500 - val_loss: 1.1832\n",
      "Epoch 4349/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3758 - val_loss: 1.1845\n",
      "Epoch 4350/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4826 - val_loss: 1.1786\n",
      "Epoch 4351/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3544 - val_loss: 1.1561\n",
      "Epoch 4352/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3437 - val_loss: 1.1910\n",
      "Epoch 4353/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3973 - val_loss: 1.1404\n",
      "Epoch 4354/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3398 - val_loss: 1.1846\n",
      "Epoch 4355/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4344 - val_loss: 1.1597\n",
      "Epoch 4356/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4830 - val_loss: 1.1335\n",
      "Epoch 4357/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2967 - val_loss: 1.1385\n",
      "Epoch 4358/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3807 - val_loss: 1.1807\n",
      "Epoch 4359/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3600 - val_loss: 1.1375\n",
      "Epoch 4360/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3482 - val_loss: 1.1725\n",
      "Epoch 4361/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3887 - val_loss: 1.1559\n",
      "Epoch 4362/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3194 - val_loss: 1.1959\n",
      "Epoch 4363/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4529 - val_loss: 1.1537\n",
      "Epoch 4364/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4240 - val_loss: 1.1304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4365/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3483 - val_loss: 1.1363\n",
      "Epoch 4366/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4244 - val_loss: 1.1308\n",
      "Epoch 4367/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4064 - val_loss: 1.1977\n",
      "Epoch 4368/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5110 - val_loss: 1.1689\n",
      "Epoch 4369/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2717 - val_loss: 1.1766\n",
      "Epoch 4370/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4108 - val_loss: 1.2720\n",
      "Epoch 4371/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3664 - val_loss: 1.1840\n",
      "Epoch 4372/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4527 - val_loss: 1.2237\n",
      "Epoch 4373/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4714 - val_loss: 1.1981\n",
      "Epoch 4374/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4598 - val_loss: 1.1645\n",
      "Epoch 4375/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3567 - val_loss: 1.1716\n",
      "Epoch 4376/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3989 - val_loss: 1.1851\n",
      "Epoch 4377/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4785 - val_loss: 1.2022\n",
      "Epoch 4378/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4701 - val_loss: 1.2112\n",
      "Epoch 4379/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3272 - val_loss: 1.2162\n",
      "Epoch 4380/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2475 - val_loss: 1.1790\n",
      "Epoch 4381/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6544 - val_loss: 1.1921\n",
      "Epoch 4382/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3698 - val_loss: 1.2009\n",
      "Epoch 4383/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4127 - val_loss: 1.1692\n",
      "Epoch 4384/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3898 - val_loss: 1.1552\n",
      "Epoch 4385/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4019 - val_loss: 1.2106\n",
      "Epoch 4386/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4608 - val_loss: 1.1280\n",
      "Epoch 4387/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4896 - val_loss: 1.1829\n",
      "Epoch 4388/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3012 - val_loss: 1.1387\n",
      "Epoch 4389/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3492 - val_loss: 1.1426\n",
      "Epoch 4390/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4013 - val_loss: 1.1462\n",
      "Epoch 4391/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4894 - val_loss: 1.1985\n",
      "Epoch 4392/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4661 - val_loss: 1.2489\n",
      "Epoch 4393/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3959 - val_loss: 1.1754\n",
      "Epoch 4394/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2920 - val_loss: 1.1440\n",
      "Epoch 4395/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5593 - val_loss: 1.1899\n",
      "Epoch 4396/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4573 - val_loss: 1.1475\n",
      "Epoch 4397/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5013 - val_loss: 1.1636\n",
      "Epoch 4398/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3237 - val_loss: 1.1551\n",
      "Epoch 4399/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3852 - val_loss: 1.1827\n",
      "Epoch 4400/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3765 - val_loss: 1.2259\n",
      "Epoch 4401/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3377 - val_loss: 1.1862\n",
      "Epoch 4402/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.4087 - val_loss: 1.1771\n",
      "Epoch 4403/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5831 - val_loss: 1.2311\n",
      "Epoch 4404/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4220 - val_loss: 1.1383\n",
      "Epoch 4405/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4879 - val_loss: 1.1828\n",
      "Epoch 4406/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4414 - val_loss: 1.1591\n",
      "Epoch 4407/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4221 - val_loss: 1.1801\n",
      "Epoch 4408/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3821 - val_loss: 1.1442\n",
      "Epoch 4409/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.3493 - val_loss: 1.1406\n",
      "Epoch 4410/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3608 - val_loss: 1.1436\n",
      "Epoch 4411/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3561 - val_loss: 1.1593\n",
      "Epoch 4412/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3440 - val_loss: 1.1430\n",
      "Epoch 4413/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4370 - val_loss: 1.1381\n",
      "Epoch 4414/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5501 - val_loss: 1.1647\n",
      "Epoch 4415/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4579 - val_loss: 1.2506\n",
      "Epoch 4416/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4048 - val_loss: 1.1779\n",
      "Epoch 4417/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4816 - val_loss: 1.1338\n",
      "Epoch 4418/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3986 - val_loss: 1.1846\n",
      "Epoch 4419/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3722 - val_loss: 1.1542\n",
      "Epoch 4420/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4349 - val_loss: 1.1853\n",
      "Epoch 4421/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4046 - val_loss: 1.1554\n",
      "Epoch 4422/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4417 - val_loss: 1.1879\n",
      "Epoch 4423/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4256 - val_loss: 1.1873\n",
      "Epoch 4424/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4549 - val_loss: 1.2523\n",
      "Epoch 4425/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4276 - val_loss: 1.1733\n",
      "Epoch 4426/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4882 - val_loss: 1.1400\n",
      "Epoch 4427/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4596 - val_loss: 1.1985\n",
      "Epoch 4428/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3872 - val_loss: 1.2031\n",
      "Epoch 4429/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3576 - val_loss: 1.1727\n",
      "Epoch 4430/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4491 - val_loss: 1.2696\n",
      "Epoch 4431/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3429 - val_loss: 1.1883\n",
      "Epoch 4432/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4011 - val_loss: 1.2258\n",
      "Epoch 4433/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4891 - val_loss: 1.1894\n",
      "Epoch 4434/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4263 - val_loss: 1.1732\n",
      "Epoch 4435/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4047 - val_loss: 1.2124\n",
      "Epoch 4436/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4793 - val_loss: 1.1774\n",
      "Epoch 4437/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4372 - val_loss: 1.1457\n",
      "Epoch 4438/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3145 - val_loss: 1.1723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4439/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4542 - val_loss: 1.1746\n",
      "Epoch 4440/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4762 - val_loss: 1.2218\n",
      "Epoch 4441/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3756 - val_loss: 1.1505\n",
      "Epoch 4442/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5577 - val_loss: 1.1519\n",
      "Epoch 4443/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4295 - val_loss: 1.1445\n",
      "Epoch 4444/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3709 - val_loss: 1.2027\n",
      "Epoch 4445/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.2990 - val_loss: 1.1443\n",
      "Epoch 4446/20000\n",
      "1500/1500 [==============================] - 0s 41us/sample - loss: 1.3988 - val_loss: 1.1867\n",
      "Epoch 4447/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2932 - val_loss: 1.1363\n",
      "Epoch 4448/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3371 - val_loss: 1.1652\n",
      "Epoch 4449/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4435 - val_loss: 1.1738\n",
      "Epoch 4450/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4467 - val_loss: 1.1664\n",
      "Epoch 4451/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4562 - val_loss: 1.1979\n",
      "Epoch 4452/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5286 - val_loss: 1.1971\n",
      "Epoch 4453/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4484 - val_loss: 1.2297\n",
      "Epoch 4454/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4422 - val_loss: 1.2358\n",
      "Epoch 4455/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4309 - val_loss: 1.2513\n",
      "Epoch 4456/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3040 - val_loss: 1.2183\n",
      "Epoch 4457/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2712 - val_loss: 1.2296\n",
      "Epoch 4458/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3907 - val_loss: 1.2035\n",
      "Epoch 4459/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4967 - val_loss: 1.1365\n",
      "Epoch 4460/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4008 - val_loss: 1.1911\n",
      "Epoch 4461/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4013 - val_loss: 1.1491\n",
      "Epoch 4462/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4926 - val_loss: 1.1864\n",
      "Epoch 4463/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3071 - val_loss: 1.1502\n",
      "Epoch 4464/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3953 - val_loss: 1.1564\n",
      "Epoch 4465/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4336 - val_loss: 1.1627\n",
      "Epoch 4466/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3763 - val_loss: 1.1228\n",
      "Epoch 4467/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4790 - val_loss: 1.1465\n",
      "Epoch 4468/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5065 - val_loss: 1.1416\n",
      "Epoch 4469/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3966 - val_loss: 1.1473\n",
      "Epoch 4470/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3229 - val_loss: 1.1812\n",
      "Epoch 4471/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3759 - val_loss: 1.2022\n",
      "Epoch 4472/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3765 - val_loss: 1.2088\n",
      "Epoch 4473/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3648 - val_loss: 1.2027\n",
      "Epoch 4474/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3706 - val_loss: 1.2338\n",
      "Epoch 4475/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4734 - val_loss: 1.2590\n",
      "Epoch 4476/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5032 - val_loss: 1.2099\n",
      "Epoch 4477/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3179 - val_loss: 1.1945\n",
      "Epoch 4478/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3233 - val_loss: 1.1980\n",
      "Epoch 4479/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4603 - val_loss: 1.1960\n",
      "Epoch 4480/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3168 - val_loss: 1.1858\n",
      "Epoch 4481/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.5300 - val_loss: 1.2266\n",
      "Epoch 4482/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4657 - val_loss: 1.1908\n",
      "Epoch 4483/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3495 - val_loss: 1.1618\n",
      "Epoch 4484/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3870 - val_loss: 1.1622\n",
      "Epoch 4485/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4857 - val_loss: 1.1714\n",
      "Epoch 4486/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3654 - val_loss: 1.1440\n",
      "Epoch 4487/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3859 - val_loss: 1.1653\n",
      "Epoch 4488/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4772 - val_loss: 1.1341\n",
      "Epoch 4489/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3944 - val_loss: 1.1562\n",
      "Epoch 4490/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3960 - val_loss: 1.1441\n",
      "Epoch 4491/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3367 - val_loss: 1.1577\n",
      "Epoch 4492/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3599 - val_loss: 1.1914\n",
      "Epoch 4493/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4886 - val_loss: 1.1620\n",
      "Epoch 4494/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3711 - val_loss: 1.2182\n",
      "Epoch 4495/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3619 - val_loss: 1.1582\n",
      "Epoch 4496/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3449 - val_loss: 1.2322\n",
      "Epoch 4497/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3864 - val_loss: 1.2073\n",
      "Epoch 4498/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3408 - val_loss: 1.2165\n",
      "Epoch 4499/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3463 - val_loss: 1.1789\n",
      "Epoch 4500/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3657 - val_loss: 1.2250\n",
      "Epoch 4501/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3327 - val_loss: 1.1999\n",
      "Epoch 4502/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3933 - val_loss: 1.1580\n",
      "Epoch 4503/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3797 - val_loss: 1.2211\n",
      "Epoch 4504/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4519 - val_loss: 1.1852\n",
      "Epoch 4505/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3286 - val_loss: 1.1338\n",
      "Epoch 4506/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3270 - val_loss: 1.2070\n",
      "Epoch 4507/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4013 - val_loss: 1.1735\n",
      "Epoch 4508/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3105 - val_loss: 1.1729\n",
      "Epoch 4509/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4176 - val_loss: 1.2088\n",
      "Epoch 4510/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4461 - val_loss: 1.1504\n",
      "Epoch 4511/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3522 - val_loss: 1.2062\n",
      "Epoch 4512/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5231 - val_loss: 1.1915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4513/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4735 - val_loss: 1.1772\n",
      "Epoch 4514/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3352 - val_loss: 1.2700\n",
      "Epoch 4515/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4251 - val_loss: 1.2143\n",
      "Epoch 4516/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4541 - val_loss: 1.2000\n",
      "Epoch 4517/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4341 - val_loss: 1.2501\n",
      "Epoch 4518/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4001 - val_loss: 1.2278\n",
      "Epoch 4519/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3669 - val_loss: 1.2168\n",
      "Epoch 4520/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4078 - val_loss: 1.2161\n",
      "Epoch 4521/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4858 - val_loss: 1.1487\n",
      "Epoch 4522/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4610 - val_loss: 1.1799\n",
      "Epoch 4523/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3145 - val_loss: 1.1833\n",
      "Epoch 4524/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5188 - val_loss: 1.2755\n",
      "Epoch 4525/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3923 - val_loss: 1.2819\n",
      "Epoch 4526/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3522 - val_loss: 1.2571\n",
      "Epoch 4527/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2841 - val_loss: 1.1955\n",
      "Epoch 4528/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3690 - val_loss: 1.1657\n",
      "Epoch 4529/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3850 - val_loss: 1.1968\n",
      "Epoch 4530/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2668 - val_loss: 1.1792\n",
      "Epoch 4531/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3690 - val_loss: 1.1707\n",
      "Epoch 4532/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3708 - val_loss: 1.2002\n",
      "Epoch 4533/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4712 - val_loss: 1.1704\n",
      "Epoch 4534/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4100 - val_loss: 1.2257\n",
      "Epoch 4535/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5114 - val_loss: 1.2317\n",
      "Epoch 4536/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4037 - val_loss: 1.2501\n",
      "Epoch 4537/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4310 - val_loss: 1.1735\n",
      "Epoch 4538/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6126 - val_loss: 1.1606\n",
      "Epoch 4539/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4319 - val_loss: 1.2507\n",
      "Epoch 4540/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4500 - val_loss: 1.2211\n",
      "Epoch 4541/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3913 - val_loss: 1.1941\n",
      "Epoch 4542/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4758 - val_loss: 1.1912\n",
      "Epoch 4543/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3755 - val_loss: 1.1975\n",
      "Epoch 4544/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3571 - val_loss: 1.1789\n",
      "Epoch 4545/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4866 - val_loss: 1.1640\n",
      "Epoch 4546/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3978 - val_loss: 1.1977\n",
      "Epoch 4547/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3195 - val_loss: 1.2047\n",
      "Epoch 4548/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3245 - val_loss: 1.1937\n",
      "Epoch 4549/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3696 - val_loss: 1.1968\n",
      "Epoch 4550/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2758 - val_loss: 1.1589\n",
      "Epoch 4551/20000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 1.150 - 0s 33us/sample - loss: 1.3382 - val_loss: 1.1710\n",
      "Epoch 4552/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3095 - val_loss: 1.2413\n",
      "Epoch 4553/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3549 - val_loss: 1.2190\n",
      "Epoch 4554/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4200 - val_loss: 1.1454\n",
      "Epoch 4555/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.2936 - val_loss: 1.1674\n",
      "Epoch 4556/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3122 - val_loss: 1.1724\n",
      "Epoch 4557/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3740 - val_loss: 1.1506\n",
      "Epoch 4558/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4232 - val_loss: 1.1833\n",
      "Epoch 4559/20000\n",
      "1500/1500 [==============================] - 0s 42us/sample - loss: 1.3478 - val_loss: 1.1476\n",
      "Epoch 4560/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3833 - val_loss: 1.1549\n",
      "Epoch 4561/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4258 - val_loss: 1.1860\n",
      "Epoch 4562/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4758 - val_loss: 1.1845\n",
      "Epoch 4563/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3236 - val_loss: 1.1325\n",
      "Epoch 4564/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3921 - val_loss: 1.1664\n",
      "Epoch 4565/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4426 - val_loss: 1.1640\n",
      "Epoch 4566/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3262 - val_loss: 1.1753\n",
      "Epoch 4567/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4098 - val_loss: 1.1987\n",
      "Epoch 4568/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3907 - val_loss: 1.2307\n",
      "Epoch 4569/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3658 - val_loss: 1.1637\n",
      "Epoch 4570/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3803 - val_loss: 1.2235\n",
      "Epoch 4571/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3272 - val_loss: 1.2078\n",
      "Epoch 4572/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3876 - val_loss: 1.2000\n",
      "Epoch 4573/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.6168 - val_loss: 1.1929\n",
      "Epoch 4574/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4288 - val_loss: 1.2284\n",
      "Epoch 4575/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3682 - val_loss: 1.2204\n",
      "Epoch 4576/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3421 - val_loss: 1.1740\n",
      "Epoch 4577/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4423 - val_loss: 1.2313\n",
      "Epoch 4578/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3681 - val_loss: 1.1710\n",
      "Epoch 4579/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3570 - val_loss: 1.2269\n",
      "Epoch 4580/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4612 - val_loss: 1.1778\n",
      "Epoch 4581/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3189 - val_loss: 1.2824\n",
      "Epoch 4582/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4227 - val_loss: 1.2943\n",
      "Epoch 4583/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4176 - val_loss: 1.3043\n",
      "Epoch 4584/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4024 - val_loss: 1.2457\n",
      "Epoch 4585/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4568 - val_loss: 1.2195\n",
      "Epoch 4586/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3521 - val_loss: 1.1750\n",
      "Epoch 4587/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3804 - val_loss: 1.1572\n",
      "Epoch 4588/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3670 - val_loss: 1.2106\n",
      "Epoch 4589/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4657 - val_loss: 1.2266\n",
      "Epoch 4590/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4488 - val_loss: 1.1762\n",
      "Epoch 4591/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3726 - val_loss: 1.1875\n",
      "Epoch 4592/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3830 - val_loss: 1.2113\n",
      "Epoch 4593/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4406 - val_loss: 1.2064\n",
      "Epoch 4594/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2853 - val_loss: 1.1720\n",
      "Epoch 4595/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4144 - val_loss: 1.2074\n",
      "Epoch 4596/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3158 - val_loss: 1.1977\n",
      "Epoch 4597/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3730 - val_loss: 1.1786\n",
      "Epoch 4598/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3248 - val_loss: 1.1758\n",
      "Epoch 4599/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4818 - val_loss: 1.2721\n",
      "Epoch 4600/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2953 - val_loss: 1.1949\n",
      "Epoch 4601/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3869 - val_loss: 1.2050\n",
      "Epoch 4602/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5022 - val_loss: 1.1860\n",
      "Epoch 4603/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3882 - val_loss: 1.1835\n",
      "Epoch 4604/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4318 - val_loss: 1.1439\n",
      "Epoch 4605/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2622 - val_loss: 1.1831\n",
      "Epoch 4606/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4708 - val_loss: 1.2009\n",
      "Epoch 4607/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3057 - val_loss: 1.1724\n",
      "Epoch 4608/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5625 - val_loss: 1.5215\n",
      "Epoch 4609/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3548 - val_loss: 1.5252\n",
      "Epoch 4610/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4457 - val_loss: 1.4569\n",
      "Epoch 4611/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3522 - val_loss: 1.3431\n",
      "Epoch 4612/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3961 - val_loss: 1.3843\n",
      "Epoch 4613/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4102 - val_loss: 1.2467\n",
      "Epoch 4614/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3292 - val_loss: 1.2423\n",
      "Epoch 4615/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5417 - val_loss: 1.2463\n",
      "Epoch 4616/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4083 - val_loss: 1.1642\n",
      "Epoch 4617/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5617 - val_loss: 1.2582\n",
      "Epoch 4618/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3725 - val_loss: 1.1910\n",
      "Epoch 4619/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3628 - val_loss: 1.1997\n",
      "Epoch 4620/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4088 - val_loss: 1.1986\n",
      "Epoch 4621/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4735 - val_loss: 1.1720\n",
      "Epoch 4622/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3812 - val_loss: 1.2116\n",
      "Epoch 4623/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5276 - val_loss: 1.1730\n",
      "Epoch 4624/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3405 - val_loss: 1.1497\n",
      "Epoch 4625/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3877 - val_loss: 1.1790\n",
      "Epoch 4626/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4143 - val_loss: 1.1619\n",
      "Epoch 4627/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4169 - val_loss: 1.1834\n",
      "Epoch 4628/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4443 - val_loss: 1.1723\n",
      "Epoch 4629/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4771 - val_loss: 1.1922\n",
      "Epoch 4630/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3981 - val_loss: 1.1408\n",
      "Epoch 4631/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3637 - val_loss: 1.1869\n",
      "Epoch 4632/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3916 - val_loss: 1.1791\n",
      "Epoch 4633/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3188 - val_loss: 1.1975\n",
      "Epoch 4634/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3682 - val_loss: 1.1374\n",
      "Epoch 4635/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3407 - val_loss: 1.1824\n",
      "Epoch 4636/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4838 - val_loss: 1.1582\n",
      "Epoch 4637/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3393 - val_loss: 1.1837\n",
      "Epoch 4638/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4433 - val_loss: 1.2244\n",
      "Epoch 4639/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4315 - val_loss: 1.1667\n",
      "Epoch 4640/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3236 - val_loss: 1.1453\n",
      "Epoch 4641/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4204 - val_loss: 1.1825\n",
      "Epoch 4642/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3952 - val_loss: 1.1450\n",
      "Epoch 4643/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3173 - val_loss: 1.1600\n",
      "Epoch 4644/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4600 - val_loss: 1.2012\n",
      "Epoch 4645/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3651 - val_loss: 1.1400\n",
      "Epoch 4646/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3974 - val_loss: 1.1960\n",
      "Epoch 4647/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4127 - val_loss: 1.1566\n",
      "Epoch 4648/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4405 - val_loss: 1.1659\n",
      "Epoch 4649/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4361 - val_loss: 1.1884\n",
      "Epoch 4650/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5512 - val_loss: 1.1541\n",
      "Epoch 4651/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3709 - val_loss: 1.1629\n",
      "Epoch 4652/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4745 - val_loss: 1.1636\n",
      "Epoch 4653/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4618 - val_loss: 1.1639\n",
      "Epoch 4654/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4818 - val_loss: 1.1744\n",
      "Epoch 4655/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3224 - val_loss: 1.1729\n",
      "Epoch 4656/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3703 - val_loss: 1.1317\n",
      "Epoch 4657/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4647 - val_loss: 1.1381\n",
      "Epoch 4658/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3242 - val_loss: 1.1701\n",
      "Epoch 4659/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4297 - val_loss: 1.2088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4660/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3300 - val_loss: 1.1470\n",
      "Epoch 4661/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3655 - val_loss: 1.1827\n",
      "Epoch 4662/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3742 - val_loss: 1.1620\n",
      "Epoch 4663/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4315 - val_loss: 1.1794\n",
      "Epoch 4664/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4214 - val_loss: 1.1575\n",
      "Epoch 4665/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3258 - val_loss: 1.1750\n",
      "Epoch 4666/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4021 - val_loss: 1.1486\n",
      "Epoch 4667/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3311 - val_loss: 1.1418\n",
      "Epoch 4668/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4789 - val_loss: 1.1647\n",
      "Epoch 4669/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3114 - val_loss: 1.1169\n",
      "Epoch 4670/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3179 - val_loss: 1.1504\n",
      "Epoch 4671/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3705 - val_loss: 1.1537\n",
      "Epoch 4672/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4041 - val_loss: 1.1493\n",
      "Epoch 4673/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4670 - val_loss: 1.1722\n",
      "Epoch 4674/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4111 - val_loss: 1.1607\n",
      "Epoch 4675/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4398 - val_loss: 1.1759\n",
      "Epoch 4676/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3433 - val_loss: 1.1587\n",
      "Epoch 4677/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3987 - val_loss: 1.1590\n",
      "Epoch 4678/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5165 - val_loss: 1.1789\n",
      "Epoch 4679/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4402 - val_loss: 1.1449\n",
      "Epoch 4680/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3605 - val_loss: 1.1917\n",
      "Epoch 4681/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3792 - val_loss: 1.1570\n",
      "Epoch 4682/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3954 - val_loss: 1.1624\n",
      "Epoch 4683/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4480 - val_loss: 1.1895\n",
      "Epoch 4684/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2869 - val_loss: 1.1665\n",
      "Epoch 4685/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3450 - val_loss: 1.1503\n",
      "Epoch 4686/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4283 - val_loss: 1.1447\n",
      "Epoch 4687/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3566 - val_loss: 1.2187\n",
      "Epoch 4688/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3893 - val_loss: 1.1642\n",
      "Epoch 4689/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3470 - val_loss: 1.1969\n",
      "Epoch 4690/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3762 - val_loss: 1.1820\n",
      "Epoch 4691/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4292 - val_loss: 1.1569\n",
      "Epoch 4692/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4991 - val_loss: 1.1707\n",
      "Epoch 4693/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3983 - val_loss: 1.1837\n",
      "Epoch 4694/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3470 - val_loss: 1.1969\n",
      "Epoch 4695/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3531 - val_loss: 1.2039\n",
      "Epoch 4696/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4678 - val_loss: 1.1622\n",
      "Epoch 4697/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4182 - val_loss: 1.1738\n",
      "Epoch 4698/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4414 - val_loss: 1.1610\n",
      "Epoch 4699/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5006 - val_loss: 1.1511\n",
      "Epoch 4700/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3577 - val_loss: 1.2114\n",
      "Epoch 4701/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4198 - val_loss: 1.1513\n",
      "Epoch 4702/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3300 - val_loss: 1.1577\n",
      "Epoch 4703/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3164 - val_loss: 1.1556\n",
      "Epoch 4704/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3362 - val_loss: 1.1689\n",
      "Epoch 4705/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3635 - val_loss: 1.1625\n",
      "Epoch 4706/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4848 - val_loss: 1.2479\n",
      "Epoch 4707/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3546 - val_loss: 1.1778\n",
      "Epoch 4708/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3032 - val_loss: 1.1559\n",
      "Epoch 4709/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4259 - val_loss: 1.1502\n",
      "Epoch 4710/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.2908 - val_loss: 1.1341\n",
      "Epoch 4711/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4446 - val_loss: 1.1722\n",
      "Epoch 4712/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3566 - val_loss: 1.1881\n",
      "Epoch 4713/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4029 - val_loss: 1.1728\n",
      "Epoch 4714/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3606 - val_loss: 1.1570\n",
      "Epoch 4715/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3846 - val_loss: 1.1585\n",
      "Epoch 4716/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3667 - val_loss: 1.1575\n",
      "Epoch 4717/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4396 - val_loss: 1.1490\n",
      "Epoch 4718/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3437 - val_loss: 1.1981\n",
      "Epoch 4719/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.3649 - val_loss: 1.1657\n",
      "Epoch 4720/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3643 - val_loss: 1.1615\n",
      "Epoch 4721/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4452 - val_loss: 1.2381\n",
      "Epoch 4722/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3833 - val_loss: 1.1224\n",
      "Epoch 4723/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4385 - val_loss: 1.1871\n",
      "Epoch 4724/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3061 - val_loss: 1.1582\n",
      "Epoch 4725/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3613 - val_loss: 1.1794\n",
      "Epoch 4726/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3612 - val_loss: 1.1340\n",
      "Epoch 4727/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.5222 - val_loss: 1.1572\n",
      "Epoch 4728/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3286 - val_loss: 1.1689\n",
      "Epoch 4729/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4662 - val_loss: 1.1750\n",
      "Epoch 4730/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3765 - val_loss: 1.1537\n",
      "Epoch 4731/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4332 - val_loss: 1.1760\n",
      "Epoch 4732/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5960 - val_loss: 1.1872\n",
      "Epoch 4733/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3129 - val_loss: 1.1637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4734/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3717 - val_loss: 1.1924\n",
      "Epoch 4735/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3907 - val_loss: 1.1690\n",
      "Epoch 4736/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3425 - val_loss: 1.1512\n",
      "Epoch 4737/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4349 - val_loss: 1.1815\n",
      "Epoch 4738/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4224 - val_loss: 1.1870\n",
      "Epoch 4739/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4555 - val_loss: 1.1383\n",
      "Epoch 4740/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3440 - val_loss: 1.2019\n",
      "Epoch 4741/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4145 - val_loss: 1.1657\n",
      "Epoch 4742/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3968 - val_loss: 1.1475\n",
      "Epoch 4743/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4739 - val_loss: 1.1652\n",
      "Epoch 4744/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3681 - val_loss: 1.1729\n",
      "Epoch 4745/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2817 - val_loss: 1.1338\n",
      "Epoch 4746/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3780 - val_loss: 1.1983\n",
      "Epoch 4747/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3017 - val_loss: 1.1422\n",
      "Epoch 4748/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2511 - val_loss: 1.1648\n",
      "Epoch 4749/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5613 - val_loss: 1.1575\n",
      "Epoch 4750/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4423 - val_loss: 1.1898\n",
      "Epoch 4751/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4497 - val_loss: 1.1394\n",
      "Epoch 4752/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5261 - val_loss: 1.1943\n",
      "Epoch 4753/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5495 - val_loss: 1.1643\n",
      "Epoch 4754/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3379 - val_loss: 1.2188\n",
      "Epoch 4755/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4571 - val_loss: 1.1638\n",
      "Epoch 4756/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3638 - val_loss: 1.1729\n",
      "Epoch 4757/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4890 - val_loss: 1.1637\n",
      "Epoch 4758/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5162 - val_loss: 1.1699\n",
      "Epoch 4759/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3875 - val_loss: 1.1708\n",
      "Epoch 4760/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4143 - val_loss: 1.1929\n",
      "Epoch 4761/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3905 - val_loss: 1.1635\n",
      "Epoch 4762/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4851 - val_loss: 1.2316\n",
      "Epoch 4763/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4482 - val_loss: 1.1341\n",
      "Epoch 4764/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4323 - val_loss: 1.1510\n",
      "Epoch 4765/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3813 - val_loss: 1.1636\n",
      "Epoch 4766/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3275 - val_loss: 1.1859\n",
      "Epoch 4767/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3353 - val_loss: 1.1209\n",
      "Epoch 4768/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4186 - val_loss: 1.1903\n",
      "Epoch 4769/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3769 - val_loss: 1.1868\n",
      "Epoch 4770/20000\n",
      "1500/1500 [==============================] - 0s 47us/sample - loss: 1.4198 - val_loss: 1.1369\n",
      "Epoch 4771/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.3698 - val_loss: 1.1798\n",
      "Epoch 4772/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.4220 - val_loss: 1.1831\n",
      "Epoch 4773/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3881 - val_loss: 1.1487\n",
      "Epoch 4774/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3102 - val_loss: 1.1679\n",
      "Epoch 4775/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4335 - val_loss: 1.1688\n",
      "Epoch 4776/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4332 - val_loss: 1.1899\n",
      "Epoch 4777/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2672 - val_loss: 1.1516\n",
      "Epoch 4778/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3934 - val_loss: 1.1673\n",
      "Epoch 4779/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4200 - val_loss: 1.1904\n",
      "Epoch 4780/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4235 - val_loss: 1.1426\n",
      "Epoch 4781/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5404 - val_loss: 1.1725\n",
      "Epoch 4782/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3325 - val_loss: 1.1679\n",
      "Epoch 4783/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3312 - val_loss: 1.1953\n",
      "Epoch 4784/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3311 - val_loss: 1.1816\n",
      "Epoch 4785/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4641 - val_loss: 1.1854\n",
      "Epoch 4786/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4644 - val_loss: 1.1929\n",
      "Epoch 4787/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3579 - val_loss: 1.1529\n",
      "Epoch 4788/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4167 - val_loss: 1.1526\n",
      "Epoch 4789/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3929 - val_loss: 1.1899\n",
      "Epoch 4790/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.5083 - val_loss: 1.1932\n",
      "Epoch 4791/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3394 - val_loss: 1.1846\n",
      "Epoch 4792/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4154 - val_loss: 1.1837\n",
      "Epoch 4793/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4111 - val_loss: 1.1772\n",
      "Epoch 4794/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3908 - val_loss: 1.1850\n",
      "Epoch 4795/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4446 - val_loss: 1.2239\n",
      "Epoch 4796/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3652 - val_loss: 1.1560\n",
      "Epoch 4797/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3966 - val_loss: 1.1622\n",
      "Epoch 4798/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4589 - val_loss: 1.1744\n",
      "Epoch 4799/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3770 - val_loss: 1.1577\n",
      "Epoch 4800/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3553 - val_loss: 1.1823\n",
      "Epoch 4801/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5062 - val_loss: 1.1810\n",
      "Epoch 4802/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3981 - val_loss: 1.1760\n",
      "Epoch 4803/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5440 - val_loss: 1.2009\n",
      "Epoch 4804/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3983 - val_loss: 1.1754\n",
      "Epoch 4805/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3550 - val_loss: 1.1796\n",
      "Epoch 4806/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4136 - val_loss: 1.1720\n",
      "Epoch 4807/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4723 - val_loss: 1.1935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4808/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3701 - val_loss: 1.1522\n",
      "Epoch 4809/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2776 - val_loss: 1.1881\n",
      "Epoch 4810/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4054 - val_loss: 1.1860\n",
      "Epoch 4811/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4709 - val_loss: 1.2108\n",
      "Epoch 4812/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4128 - val_loss: 1.1752\n",
      "Epoch 4813/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3594 - val_loss: 1.1544\n",
      "Epoch 4814/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3685 - val_loss: 1.1907\n",
      "Epoch 4815/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3664 - val_loss: 1.1725\n",
      "Epoch 4816/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5490 - val_loss: 1.1749\n",
      "Epoch 4817/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3540 - val_loss: 1.1558\n",
      "Epoch 4818/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4572 - val_loss: 1.1840\n",
      "Epoch 4819/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3525 - val_loss: 1.1710\n",
      "Epoch 4820/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4611 - val_loss: 1.1906\n",
      "Epoch 4821/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.4252 - val_loss: 1.1603\n",
      "Epoch 4822/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3574 - val_loss: 1.1700\n",
      "Epoch 4823/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3607 - val_loss: 1.1569\n",
      "Epoch 4824/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4442 - val_loss: 1.1885\n",
      "Epoch 4825/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4451 - val_loss: 1.1778\n",
      "Epoch 4826/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4072 - val_loss: 1.1555\n",
      "Epoch 4827/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3501 - val_loss: 1.1666\n",
      "Epoch 4828/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4069 - val_loss: 1.1499\n",
      "Epoch 4829/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4106 - val_loss: 1.1912\n",
      "Epoch 4830/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4159 - val_loss: 1.1639\n",
      "Epoch 4831/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4099 - val_loss: 1.1692\n",
      "Epoch 4832/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3890 - val_loss: 1.1780\n",
      "Epoch 4833/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4053 - val_loss: 1.1805\n",
      "Epoch 4834/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3556 - val_loss: 1.1497\n",
      "Epoch 4835/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4316 - val_loss: 1.1780\n",
      "Epoch 4836/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3042 - val_loss: 1.1527\n",
      "Epoch 4837/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4336 - val_loss: 1.1541\n",
      "Epoch 4838/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4986 - val_loss: 1.1725\n",
      "Epoch 4839/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4050 - val_loss: 1.1621\n",
      "Epoch 4840/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.5972 - val_loss: 1.1443\n",
      "Epoch 4841/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3387 - val_loss: 1.1496\n",
      "Epoch 4842/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4479 - val_loss: 1.1752\n",
      "Epoch 4843/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3447 - val_loss: 1.1792\n",
      "Epoch 4844/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3218 - val_loss: 1.1700\n",
      "Epoch 4845/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4009 - val_loss: 1.1585\n",
      "Epoch 4846/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4355 - val_loss: 1.1705\n",
      "Epoch 4847/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4125 - val_loss: 1.1817\n",
      "Epoch 4848/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4874 - val_loss: 1.1668\n",
      "Epoch 4849/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3932 - val_loss: 1.1675\n",
      "Epoch 4850/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4256 - val_loss: 1.1798\n",
      "Epoch 4851/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4800 - val_loss: 1.1670\n",
      "Epoch 4852/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4833 - val_loss: 1.1783\n",
      "Epoch 4853/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3397 - val_loss: 1.2036\n",
      "Epoch 4854/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4074 - val_loss: 1.1601\n",
      "Epoch 4855/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5394 - val_loss: 1.1926\n",
      "Epoch 4856/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4807 - val_loss: 1.2142\n",
      "Epoch 4857/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4240 - val_loss: 1.1484\n",
      "Epoch 4858/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3826 - val_loss: 1.1847\n",
      "Epoch 4859/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3270 - val_loss: 1.1663\n",
      "Epoch 4860/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4312 - val_loss: 1.1704\n",
      "Epoch 4861/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3469 - val_loss: 1.1717\n",
      "Epoch 4862/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4690 - val_loss: 1.1451\n",
      "Epoch 4863/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3938 - val_loss: 1.1975\n",
      "Epoch 4864/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4710 - val_loss: 1.1460\n",
      "Epoch 4865/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4207 - val_loss: 1.1789\n",
      "Epoch 4866/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5454 - val_loss: 1.1635\n",
      "Epoch 4867/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3734 - val_loss: 1.1735\n",
      "Epoch 4868/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3622 - val_loss: 1.1898\n",
      "Epoch 4869/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3611 - val_loss: 1.1641\n",
      "Epoch 4870/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3794 - val_loss: 1.1581\n",
      "Epoch 4871/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3940 - val_loss: 1.1459\n",
      "Epoch 4872/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2837 - val_loss: 1.2134\n",
      "Epoch 4873/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4959 - val_loss: 1.1978\n",
      "Epoch 4874/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4280 - val_loss: 1.1746\n",
      "Epoch 4875/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3813 - val_loss: 1.2025\n",
      "Epoch 4876/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3680 - val_loss: 1.1522\n",
      "Epoch 4877/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3670 - val_loss: 1.1704\n",
      "Epoch 4878/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4286 - val_loss: 1.1777\n",
      "Epoch 4879/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2821 - val_loss: 1.1761\n",
      "Epoch 4880/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2993 - val_loss: 1.1797\n",
      "Epoch 4881/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3676 - val_loss: 1.2113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4882/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3447 - val_loss: 1.1617\n",
      "Epoch 4883/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4774 - val_loss: 1.2025\n",
      "Epoch 4884/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4843 - val_loss: 1.2044\n",
      "Epoch 4885/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4499 - val_loss: 1.1593\n",
      "Epoch 4886/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4567 - val_loss: 1.2085\n",
      "Epoch 4887/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3617 - val_loss: 1.1356\n",
      "Epoch 4888/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4241 - val_loss: 1.1755\n",
      "Epoch 4889/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3502 - val_loss: 1.2077\n",
      "Epoch 4890/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3736 - val_loss: 1.1536\n",
      "Epoch 4891/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3736 - val_loss: 1.2014\n",
      "Epoch 4892/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3807 - val_loss: 1.1942\n",
      "Epoch 4893/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4486 - val_loss: 1.1593\n",
      "Epoch 4894/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4579 - val_loss: 1.1684\n",
      "Epoch 4895/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3990 - val_loss: 1.1585\n",
      "Epoch 4896/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3331 - val_loss: 1.1998\n",
      "Epoch 4897/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4379 - val_loss: 1.1237\n",
      "Epoch 4898/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5024 - val_loss: 1.1890\n",
      "Epoch 4899/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4589 - val_loss: 1.1757\n",
      "Epoch 4900/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4352 - val_loss: 1.1414\n",
      "Epoch 4901/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4863 - val_loss: 1.1516\n",
      "Epoch 4902/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3675 - val_loss: 1.1810\n",
      "Epoch 4903/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4263 - val_loss: 1.1726\n",
      "Epoch 4904/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4124 - val_loss: 1.1761\n",
      "Epoch 4905/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3256 - val_loss: 1.2072\n",
      "Epoch 4906/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3057 - val_loss: 1.1518\n",
      "Epoch 4907/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4047 - val_loss: 1.1808\n",
      "Epoch 4908/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4128 - val_loss: 1.1406\n",
      "Epoch 4909/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3596 - val_loss: 1.1833\n",
      "Epoch 4910/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3581 - val_loss: 1.1752\n",
      "Epoch 4911/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4636 - val_loss: 1.1552\n",
      "Epoch 4912/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4295 - val_loss: 1.1632\n",
      "Epoch 4913/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3486 - val_loss: 1.1807\n",
      "Epoch 4914/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3557 - val_loss: 1.1645\n",
      "Epoch 4915/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4083 - val_loss: 1.1705\n",
      "Epoch 4916/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3954 - val_loss: 1.1743\n",
      "Epoch 4917/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3240 - val_loss: 1.1785\n",
      "Epoch 4918/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4960 - val_loss: 1.1677\n",
      "Epoch 4919/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3114 - val_loss: 1.1888\n",
      "Epoch 4920/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3691 - val_loss: 1.1824\n",
      "Epoch 4921/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4884 - val_loss: 1.1747\n",
      "Epoch 4922/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5014 - val_loss: 1.1843\n",
      "Epoch 4923/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3377 - val_loss: 1.1808\n",
      "Epoch 4924/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4234 - val_loss: 1.1886\n",
      "Epoch 4925/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3337 - val_loss: 1.2112\n",
      "Epoch 4926/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4006 - val_loss: 1.1961\n",
      "Epoch 4927/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4402 - val_loss: 1.1631\n",
      "Epoch 4928/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4015 - val_loss: 1.1494\n",
      "Epoch 4929/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3214 - val_loss: 1.1828\n",
      "Epoch 4930/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5650 - val_loss: 1.1432\n",
      "Epoch 4931/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4442 - val_loss: 1.1341\n",
      "Epoch 4932/20000\n",
      "1500/1500 [==============================] - 0s 43us/sample - loss: 1.4022 - val_loss: 1.2120\n",
      "Epoch 4933/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4500 - val_loss: 1.1540\n",
      "Epoch 4934/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.5160 - val_loss: 1.1942\n",
      "Epoch 4935/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4608 - val_loss: 1.2248\n",
      "Epoch 4936/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3660 - val_loss: 1.1481\n",
      "Epoch 4937/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3371 - val_loss: 1.1510\n",
      "Epoch 4938/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4214 - val_loss: 1.2303\n",
      "Epoch 4939/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3883 - val_loss: 1.1667\n",
      "Epoch 4940/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4385 - val_loss: 1.1831\n",
      "Epoch 4941/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4442 - val_loss: 1.1834\n",
      "Epoch 4942/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3666 - val_loss: 1.1956\n",
      "Epoch 4943/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.6045 - val_loss: 1.1556\n",
      "Epoch 4944/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2788 - val_loss: 1.1793\n",
      "Epoch 4945/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3379 - val_loss: 1.1465\n",
      "Epoch 4946/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3667 - val_loss: 1.1513\n",
      "Epoch 4947/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4439 - val_loss: 1.1559\n",
      "Epoch 4948/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3938 - val_loss: 1.1705\n",
      "Epoch 4949/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3617 - val_loss: 1.1465\n",
      "Epoch 4950/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3913 - val_loss: 1.1354\n",
      "Epoch 4951/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4272 - val_loss: 1.1518\n",
      "Epoch 4952/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3164 - val_loss: 1.1761\n",
      "Epoch 4953/20000\n",
      "1500/1500 [==============================] - 0s 38us/sample - loss: 1.3962 - val_loss: 1.1931\n",
      "Epoch 4954/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3805 - val_loss: 1.1717\n",
      "Epoch 4955/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3528 - val_loss: 1.1526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4956/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3377 - val_loss: 1.2034\n",
      "Epoch 4957/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4158 - val_loss: 1.1701\n",
      "Epoch 4958/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.5285 - val_loss: 1.1943\n",
      "Epoch 4959/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3301 - val_loss: 1.1512\n",
      "Epoch 4960/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4304 - val_loss: 1.1785\n",
      "Epoch 4961/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4476 - val_loss: 1.1526\n",
      "Epoch 4962/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3393 - val_loss: 1.1383\n",
      "Epoch 4963/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4363 - val_loss: 1.1772\n",
      "Epoch 4964/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3678 - val_loss: 1.1822\n",
      "Epoch 4965/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3905 - val_loss: 1.1757\n",
      "Epoch 4966/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4467 - val_loss: 1.2003\n",
      "Epoch 4967/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4056 - val_loss: 1.2085\n",
      "Epoch 4968/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3072 - val_loss: 1.1715\n",
      "Epoch 4969/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4108 - val_loss: 1.1816\n",
      "Epoch 4970/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3688 - val_loss: 1.1406\n",
      "Epoch 4971/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3464 - val_loss: 1.1585\n",
      "Epoch 4972/20000\n",
      "1500/1500 [==============================] - 0s 40us/sample - loss: 1.3831 - val_loss: 1.1822\n",
      "Epoch 4973/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4857 - val_loss: 1.1739\n",
      "Epoch 4974/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3298 - val_loss: 1.1606\n",
      "Epoch 4975/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4148 - val_loss: 1.2007\n",
      "Epoch 4976/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3990 - val_loss: 1.1309\n",
      "Epoch 4977/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3665 - val_loss: 1.1629\n",
      "Epoch 4978/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3705 - val_loss: 1.1791\n",
      "Epoch 4979/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4475 - val_loss: 1.1709\n",
      "Epoch 4980/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4652 - val_loss: 1.1777\n",
      "Epoch 4981/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.5315 - val_loss: 1.1648\n",
      "Epoch 4982/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3491 - val_loss: 1.1636\n",
      "Epoch 4983/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3605 - val_loss: 1.1696\n",
      "Epoch 4984/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4377 - val_loss: 1.1677\n",
      "Epoch 4985/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3895 - val_loss: 1.2047\n",
      "Epoch 4986/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4744 - val_loss: 1.1927\n",
      "Epoch 4987/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2921 - val_loss: 1.1646\n",
      "Epoch 4988/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3248 - val_loss: 1.1494\n",
      "Epoch 4989/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4040 - val_loss: 1.1845\n",
      "Epoch 4990/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4352 - val_loss: 1.1642\n",
      "Epoch 4991/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.3627 - val_loss: 1.1333\n",
      "Epoch 4992/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3971 - val_loss: 1.1814\n",
      "Epoch 4993/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4813 - val_loss: 1.1390\n",
      "Epoch 4994/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4320 - val_loss: 1.1673\n",
      "Epoch 4995/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4022 - val_loss: 1.1677\n",
      "Epoch 4996/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4282 - val_loss: 1.1810\n",
      "Epoch 4997/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4518 - val_loss: 1.1659\n",
      "Epoch 4998/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3322 - val_loss: 1.2007\n",
      "Epoch 4999/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4016 - val_loss: 1.1607\n",
      "Epoch 5000/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3487 - val_loss: 1.1947\n",
      "Epoch 5001/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3905 - val_loss: 1.1550\n",
      "Epoch 5002/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3588 - val_loss: 1.1717\n",
      "Epoch 5003/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3805 - val_loss: 1.1788\n",
      "Epoch 5004/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3872 - val_loss: 1.1796\n",
      "Epoch 5005/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3633 - val_loss: 1.1867\n",
      "Epoch 5006/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4390 - val_loss: 1.2132\n",
      "Epoch 5007/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4845 - val_loss: 1.1903\n",
      "Epoch 5008/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4339 - val_loss: 1.1737\n",
      "Epoch 5009/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.2881 - val_loss: 1.1407\n",
      "Epoch 5010/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.4773 - val_loss: 1.2021\n",
      "Epoch 5011/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3593 - val_loss: 1.1654\n",
      "Epoch 5012/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.2689 - val_loss: 1.1616\n",
      "Epoch 5013/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4862 - val_loss: 1.1607\n",
      "Epoch 5014/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4861 - val_loss: 1.1432\n",
      "Epoch 5015/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3480 - val_loss: 1.1412\n",
      "Epoch 5016/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4474 - val_loss: 1.1945\n",
      "Epoch 5017/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4357 - val_loss: 1.1321\n",
      "Epoch 5018/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3833 - val_loss: 1.1855\n",
      "Epoch 5019/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3867 - val_loss: 1.1493\n",
      "Epoch 5020/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3337 - val_loss: 1.1683\n",
      "Epoch 5021/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3673 - val_loss: 1.1689\n",
      "Epoch 5022/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.2983 - val_loss: 1.1735\n",
      "Epoch 5023/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.3513 - val_loss: 1.2007\n",
      "Epoch 5024/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.3891 - val_loss: 1.1906\n",
      "Epoch 5025/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.4153 - val_loss: 1.1590\n",
      "Epoch 5026/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3947 - val_loss: 1.2059\n",
      "Epoch 5027/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.4636 - val_loss: 1.1653\n",
      "Epoch 5028/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.4000 - val_loss: 1.1522\n",
      "Epoch 5029/20000\n",
      "1500/1500 [==============================] - 0s 39us/sample - loss: 1.3932 - val_loss: 1.1908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5030/20000\n",
      "1500/1500 [==============================] - 0s 37us/sample - loss: 1.4433 - val_loss: 1.1743\n",
      "Epoch 5031/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.3254 - val_loss: 1.1551\n",
      "Epoch 5032/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.3890 - val_loss: 1.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [04:31<04:31, 271.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_layer': 'selu', 'batc_normalization': False, 'batch_size': 64, 'dropout': 0, 'epochs': 20000, 'first_neuron': 160, 'hidden_layers': 1, 'hidden_neuron': 25, 'kernel_initializer': 'ones', 'last_activation': 'linear', 'optimizer': 'adam'}\n",
      "adding layer 1\n",
      "Train on 1500 samples, validate on 375 samples\n",
      "Epoch 1/20000\n",
      "1500/1500 [==============================] - 0s 295us/sample - loss: 18618.5929 - val_loss: 16647.0386\n",
      "Epoch 2/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 17310.5737 - val_loss: 15447.8443\n",
      "Epoch 3/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 16081.5570 - val_loss: 14354.0465\n",
      "Epoch 4/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 14954.9446 - val_loss: 13327.7511\n",
      "Epoch 5/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 13890.0289 - val_loss: 12385.4482\n",
      "Epoch 6/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 12916.0137 - val_loss: 11495.0760\n",
      "Epoch 7/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 11997.1588 - val_loss: 10677.4692\n",
      "Epoch 8/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 11154.9325 - val_loss: 9910.5735\n",
      "Epoch 9/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 10377.5211 - val_loss: 9197.3744\n",
      "Epoch 10/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 9640.4717 - val_loss: 8554.5750\n",
      "Epoch 11/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 8969.4149 - val_loss: 7945.9041\n",
      "Epoch 12/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 8340.8375 - val_loss: 7375.8597\n",
      "Epoch 13/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 7756.9048 - val_loss: 6855.0007\n",
      "Epoch 14/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 7215.8638 - val_loss: 6380.6943\n",
      "Epoch 15/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 6717.2289 - val_loss: 5925.8485\n",
      "Epoch 16/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 6248.6341 - val_loss: 5511.6740\n",
      "Epoch 17/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 5820.0492 - val_loss: 5127.6087\n",
      "Epoch 18/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 5419.4435 - val_loss: 4765.3876\n",
      "Epoch 19/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 5045.4098 - val_loss: 4433.7125\n",
      "Epoch 20/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 4702.0397 - val_loss: 4129.1290\n",
      "Epoch 21/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 4381.3454 - val_loss: 3846.4230\n",
      "Epoch 22/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 4084.4727 - val_loss: 3586.9158\n",
      "Epoch 23/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 3814.3816 - val_loss: 3336.0150\n",
      "Epoch 24/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 3551.6643 - val_loss: 3110.6325\n",
      "Epoch 25/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 3316.2389 - val_loss: 2899.0982\n",
      "Epoch 26/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 3093.9818 - val_loss: 2703.2007\n",
      "Epoch 27/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 2887.7732 - val_loss: 2523.9192\n",
      "Epoch 28/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 2697.4192 - val_loss: 2355.3549\n",
      "Epoch 29/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 2520.3201 - val_loss: 2195.2419\n",
      "Epoch 30/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 2354.5712 - val_loss: 2049.0061\n",
      "Epoch 31/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 2199.5662 - val_loss: 1914.6890\n",
      "Epoch 32/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 2057.2431 - val_loss: 1787.7907\n",
      "Epoch 33/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1923.6018 - val_loss: 1668.3644\n",
      "Epoch 34/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1797.7192 - val_loss: 1560.1830\n",
      "Epoch 35/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1681.9002 - val_loss: 1459.6918\n",
      "Epoch 36/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1575.1610 - val_loss: 1365.1380\n",
      "Epoch 37/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1474.7674 - val_loss: 1277.2772\n",
      "Epoch 38/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1381.3270 - val_loss: 1195.4986\n",
      "Epoch 39/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1293.7933 - val_loss: 1119.4835\n",
      "Epoch 40/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1212.9273 - val_loss: 1046.6515\n",
      "Epoch 41/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1136.4163 - val_loss: 982.2049\n",
      "Epoch 42/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1067.2184 - val_loss: 920.7010\n",
      "Epoch 43/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1001.1878 - val_loss: 864.3924\n",
      "Epoch 44/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 940.4552 - val_loss: 810.8990\n",
      "Epoch 45/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 882.8059 - val_loss: 762.3105\n",
      "Epoch 46/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 830.2764 - val_loss: 714.9795\n",
      "Epoch 47/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 779.5482 - val_loss: 672.4868\n",
      "Epoch 48/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 733.4659 - val_loss: 631.6935\n",
      "Epoch 49/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 689.2794 - val_loss: 594.1908\n",
      "Epoch 50/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 648.7864 - val_loss: 558.4030\n",
      "Epoch 51/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 610.6534 - val_loss: 525.4144\n",
      "Epoch 52/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 574.8597 - val_loss: 494.7666\n",
      "Epoch 53/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 541.3112 - val_loss: 466.2005\n",
      "Epoch 54/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 510.5524 - val_loss: 439.4558\n",
      "Epoch 55/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 481.7896 - val_loss: 414.2975\n",
      "Epoch 56/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 454.4863 - val_loss: 391.3627\n",
      "Epoch 57/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 429.4496 - val_loss: 369.5680\n",
      "Epoch 58/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 406.0389 - val_loss: 348.8964\n",
      "Epoch 59/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 383.7013 - val_loss: 329.9409\n",
      "Epoch 60/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 363.0530 - val_loss: 312.0374\n",
      "Epoch 61/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 343.5830 - val_loss: 295.6954\n",
      "Epoch 62/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 325.6391 - val_loss: 280.1708\n",
      "Epoch 63/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 308.9628 - val_loss: 265.4575\n",
      "Epoch 64/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 293.1168 - val_loss: 252.1504\n",
      "Epoch 65/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 278.5482 - val_loss: 239.7838\n",
      "Epoch 66/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 264.7355 - val_loss: 228.3039\n",
      "Epoch 67/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 251.8690 - val_loss: 217.3793\n",
      "Epoch 68/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 239.7835 - val_loss: 207.4111\n",
      "Epoch 69/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 228.5204 - val_loss: 198.1058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 218.0904 - val_loss: 189.2594\n",
      "Epoch 71/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 208.0505 - val_loss: 181.2932\n",
      "Epoch 72/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 198.7903 - val_loss: 173.5092\n",
      "Epoch 73/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 190.0601 - val_loss: 166.2975\n",
      "Epoch 74/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 181.9008 - val_loss: 159.8794\n",
      "Epoch 75/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 174.3934 - val_loss: 153.7187\n",
      "Epoch 76/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 167.2324 - val_loss: 147.8164\n",
      "Epoch 77/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 160.5053 - val_loss: 142.4208\n",
      "Epoch 78/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 154.3002 - val_loss: 137.2274\n",
      "Epoch 79/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 148.4043 - val_loss: 132.4526\n",
      "Epoch 80/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 142.9802 - val_loss: 128.1273\n",
      "Epoch 81/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 137.9101 - val_loss: 124.0830\n",
      "Epoch 82/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 133.1503 - val_loss: 120.3764\n",
      "Epoch 83/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 128.8613 - val_loss: 116.8038\n",
      "Epoch 84/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 124.7666 - val_loss: 113.6880\n",
      "Epoch 85/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 121.0819 - val_loss: 110.8642\n",
      "Epoch 86/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 117.6755 - val_loss: 108.3825\n",
      "Epoch 87/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 114.5472 - val_loss: 106.0376\n",
      "Epoch 88/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 111.5703 - val_loss: 103.8816\n",
      "Epoch 89/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 108.8226 - val_loss: 101.9041\n",
      "Epoch 90/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 106.2972 - val_loss: 100.0547\n",
      "Epoch 91/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 103.9924 - val_loss: 98.3933\n",
      "Epoch 92/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 101.8637 - val_loss: 96.9179\n",
      "Epoch 93/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 99.9917 - val_loss: 95.6597\n",
      "Epoch 94/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 98.3463 - val_loss: 94.5399\n",
      "Epoch 95/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 96.8436 - val_loss: 93.5534\n",
      "Epoch 96/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 95.4322 - val_loss: 92.6911\n",
      "Epoch 97/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 94.1547 - val_loss: 91.9139\n",
      "Epoch 98/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 92.9774 - val_loss: 91.2421\n",
      "Epoch 99/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 91.9834 - val_loss: 90.5902\n",
      "Epoch 100/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 91.0246 - val_loss: 89.9824\n",
      "Epoch 101/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 90.1283 - val_loss: 89.4557\n",
      "Epoch 102/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 89.3662 - val_loss: 88.9566\n",
      "Epoch 103/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 88.6548 - val_loss: 88.5108\n",
      "Epoch 104/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 88.0270 - val_loss: 88.1039\n",
      "Epoch 105/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 87.4541 - val_loss: 87.7437\n",
      "Epoch 106/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 86.9384 - val_loss: 87.4464\n",
      "Epoch 107/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 86.5047 - val_loss: 87.1679\n",
      "Epoch 108/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 86.1111 - val_loss: 86.9116\n",
      "Epoch 109/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 85.7319 - val_loss: 86.6938\n",
      "Epoch 110/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 85.3942 - val_loss: 86.5160\n",
      "Epoch 111/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 85.0683 - val_loss: 86.3767\n",
      "Epoch 112/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 84.7748 - val_loss: 86.2474\n",
      "Epoch 113/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 84.5104 - val_loss: 86.1200\n",
      "Epoch 114/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 84.2352 - val_loss: 86.0032\n",
      "Epoch 115/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 83.9946 - val_loss: 85.8923\n",
      "Epoch 116/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 83.7737 - val_loss: 85.7984\n",
      "Epoch 117/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 83.5613 - val_loss: 85.7207\n",
      "Epoch 118/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 83.3751 - val_loss: 85.6522\n",
      "Epoch 119/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 83.2066 - val_loss: 85.5875\n",
      "Epoch 120/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 83.0399 - val_loss: 85.5340\n",
      "Epoch 121/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 82.8853 - val_loss: 85.4811\n",
      "Epoch 122/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 82.7359 - val_loss: 85.4249\n",
      "Epoch 123/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 82.5962 - val_loss: 85.3706\n",
      "Epoch 124/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 82.4605 - val_loss: 85.3110\n",
      "Epoch 125/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 82.3298 - val_loss: 85.2661\n",
      "Epoch 126/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 82.2108 - val_loss: 85.2205\n",
      "Epoch 127/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 82.0964 - val_loss: 85.1713\n",
      "Epoch 128/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 81.9906 - val_loss: 85.1321\n",
      "Epoch 129/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 81.8878 - val_loss: 85.0791\n",
      "Epoch 130/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 81.7915 - val_loss: 85.0189\n",
      "Epoch 131/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 81.7016 - val_loss: 84.9708\n",
      "Epoch 132/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 81.6066 - val_loss: 84.9128\n",
      "Epoch 133/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 81.5173 - val_loss: 84.8609\n",
      "Epoch 134/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 81.4257 - val_loss: 84.7886\n",
      "Epoch 135/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 81.3409 - val_loss: 84.7391\n",
      "Epoch 136/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 81.2510 - val_loss: 84.6644\n",
      "Epoch 137/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 81.1663 - val_loss: 84.6099\n",
      "Epoch 138/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 81.0738 - val_loss: 84.5312\n",
      "Epoch 139/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 80.9884 - val_loss: 84.4635\n",
      "Epoch 140/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 80.9005 - val_loss: 84.3971\n",
      "Epoch 141/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 80.8152 - val_loss: 84.3309\n",
      "Epoch 142/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 80.7304 - val_loss: 84.2626\n",
      "Epoch 143/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 25us/sample - loss: 80.6480 - val_loss: 84.1825\n",
      "Epoch 144/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 80.5605 - val_loss: 84.1165\n",
      "Epoch 145/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 80.4745 - val_loss: 84.0507\n",
      "Epoch 146/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 80.3921 - val_loss: 83.9874\n",
      "Epoch 147/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 80.3050 - val_loss: 83.9059\n",
      "Epoch 148/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 80.2211 - val_loss: 83.8394\n",
      "Epoch 149/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 80.1357 - val_loss: 83.7611\n",
      "Epoch 150/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 80.0539 - val_loss: 83.6731\n",
      "Epoch 151/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 79.9692 - val_loss: 83.6023\n",
      "Epoch 152/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 79.8870 - val_loss: 83.5320\n",
      "Epoch 153/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 79.8016 - val_loss: 83.4454\n",
      "Epoch 154/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 79.7176 - val_loss: 83.3697\n",
      "Epoch 155/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 79.6321 - val_loss: 83.2889\n",
      "Epoch 156/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 79.5475 - val_loss: 83.2092\n",
      "Epoch 157/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 79.4609 - val_loss: 83.1352\n",
      "Epoch 158/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 79.3770 - val_loss: 83.0527\n",
      "Epoch 159/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 79.2886 - val_loss: 82.9761\n",
      "Epoch 160/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 79.2041 - val_loss: 82.9002\n",
      "Epoch 161/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 79.1126 - val_loss: 82.8118\n",
      "Epoch 162/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 79.0241 - val_loss: 82.7254\n",
      "Epoch 163/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 78.9338 - val_loss: 82.6201\n",
      "Epoch 164/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 78.8440 - val_loss: 82.5380\n",
      "Epoch 165/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 78.7534 - val_loss: 82.4301\n",
      "Epoch 166/20000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 82.33 - 0s 25us/sample - loss: 78.6651 - val_loss: 82.3263\n",
      "Epoch 167/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 78.5665 - val_loss: 82.2419\n",
      "Epoch 168/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 78.4730 - val_loss: 82.1474\n",
      "Epoch 169/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 78.3773 - val_loss: 82.0375\n",
      "Epoch 170/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 78.2833 - val_loss: 81.9530\n",
      "Epoch 171/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 78.1891 - val_loss: 81.8755\n",
      "Epoch 172/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 78.0909 - val_loss: 81.7675\n",
      "Epoch 173/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 77.9926 - val_loss: 81.6690\n",
      "Epoch 174/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 77.8940 - val_loss: 81.5823\n",
      "Epoch 175/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 77.7984 - val_loss: 81.4738\n",
      "Epoch 176/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 77.6916 - val_loss: 81.3764\n",
      "Epoch 177/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 77.5893 - val_loss: 81.2751\n",
      "Epoch 178/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 77.4857 - val_loss: 81.1769\n",
      "Epoch 179/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 77.3829 - val_loss: 81.0678\n",
      "Epoch 180/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 77.2812 - val_loss: 80.9692\n",
      "Epoch 181/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 77.1735 - val_loss: 80.8707\n",
      "Epoch 182/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 77.0667 - val_loss: 80.7633\n",
      "Epoch 183/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 76.9578 - val_loss: 80.6611\n",
      "Epoch 184/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 76.8515 - val_loss: 80.5335\n",
      "Epoch 185/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 76.7391 - val_loss: 80.4352\n",
      "Epoch 186/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 76.6297 - val_loss: 80.3092\n",
      "Epoch 187/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 76.5136 - val_loss: 80.2060\n",
      "Epoch 188/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 76.3968 - val_loss: 80.0572\n",
      "Epoch 189/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 76.2805 - val_loss: 79.9518\n",
      "Epoch 190/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 76.1690 - val_loss: 79.8110\n",
      "Epoch 191/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 76.0473 - val_loss: 79.7214\n",
      "Epoch 192/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 75.9349 - val_loss: 79.6032\n",
      "Epoch 193/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 75.8175 - val_loss: 79.5210\n",
      "Epoch 194/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 75.7015 - val_loss: 79.4303\n",
      "Epoch 195/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 75.5925 - val_loss: 79.2772\n",
      "Epoch 196/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 75.4671 - val_loss: 79.1477\n",
      "Epoch 197/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 75.3443 - val_loss: 79.0402\n",
      "Epoch 198/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 75.2301 - val_loss: 78.9193\n",
      "Epoch 199/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 75.1114 - val_loss: 78.8205\n",
      "Epoch 200/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 74.9937 - val_loss: 78.7031\n",
      "Epoch 201/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 74.8719 - val_loss: 78.5952\n",
      "Epoch 202/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 74.7514 - val_loss: 78.4689\n",
      "Epoch 203/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 74.6319 - val_loss: 78.3736\n",
      "Epoch 204/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 74.5103 - val_loss: 78.2552\n",
      "Epoch 205/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 74.3863 - val_loss: 78.1264\n",
      "Epoch 206/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 74.2616 - val_loss: 78.0312\n",
      "Epoch 207/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 74.1366 - val_loss: 77.8823\n",
      "Epoch 208/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 74.0184 - val_loss: 77.7797\n",
      "Epoch 209/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 73.9009 - val_loss: 77.6188\n",
      "Epoch 210/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 73.7751 - val_loss: 77.5049\n",
      "Epoch 211/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 73.6570 - val_loss: 77.3444\n",
      "Epoch 212/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 73.5271 - val_loss: 77.2138\n",
      "Epoch 213/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 73.4049 - val_loss: 77.0937\n",
      "Epoch 214/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 73.2782 - val_loss: 76.9627\n",
      "Epoch 215/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 73.1501 - val_loss: 76.8168\n",
      "Epoch 216/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 33us/sample - loss: 73.0257 - val_loss: 76.6798\n",
      "Epoch 217/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 72.9021 - val_loss: 76.5388\n",
      "Epoch 218/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 72.7763 - val_loss: 76.3267\n",
      "Epoch 219/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 72.6288 - val_loss: 76.2034\n",
      "Epoch 220/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 72.5043 - val_loss: 76.0916\n",
      "Epoch 221/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 72.3573 - val_loss: 75.8911\n",
      "Epoch 222/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 72.2252 - val_loss: 75.6790\n",
      "Epoch 223/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 72.0818 - val_loss: 75.5649\n",
      "Epoch 224/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 71.9425 - val_loss: 75.3515\n",
      "Epoch 225/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 71.7992 - val_loss: 75.2056\n",
      "Epoch 226/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 71.6623 - val_loss: 75.0075\n",
      "Epoch 227/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 71.5065 - val_loss: 74.8082\n",
      "Epoch 228/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 71.3567 - val_loss: 74.6640\n",
      "Epoch 229/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 71.1980 - val_loss: 74.4276\n",
      "Epoch 230/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 71.0300 - val_loss: 74.2907\n",
      "Epoch 231/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 70.8698 - val_loss: 74.1028\n",
      "Epoch 232/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 70.7191 - val_loss: 73.8598\n",
      "Epoch 233/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 70.5489 - val_loss: 73.7432\n",
      "Epoch 234/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 70.3447 - val_loss: 73.4406\n",
      "Epoch 235/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 70.1162 - val_loss: 73.1533\n",
      "Epoch 236/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 69.8728 - val_loss: 72.8674\n",
      "Epoch 237/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 69.6328 - val_loss: 72.5717\n",
      "Epoch 238/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 69.3943 - val_loss: 72.3073\n",
      "Epoch 239/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 69.1570 - val_loss: 72.0639\n",
      "Epoch 240/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 68.9184 - val_loss: 71.7416\n",
      "Epoch 241/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 68.6761 - val_loss: 71.4841\n",
      "Epoch 242/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 68.4211 - val_loss: 71.2250\n",
      "Epoch 243/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 68.1757 - val_loss: 70.9034\n",
      "Epoch 244/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 67.9125 - val_loss: 70.5951\n",
      "Epoch 245/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 67.6395 - val_loss: 70.3153\n",
      "Epoch 246/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 67.3646 - val_loss: 69.8957\n",
      "Epoch 247/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 67.0755 - val_loss: 69.5884\n",
      "Epoch 248/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 66.7848 - val_loss: 69.2593\n",
      "Epoch 249/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 66.5022 - val_loss: 68.9259\n",
      "Epoch 250/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 66.1927 - val_loss: 68.5294\n",
      "Epoch 251/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 65.8979 - val_loss: 68.1803\n",
      "Epoch 252/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 65.5923 - val_loss: 67.7896\n",
      "Epoch 253/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 65.2764 - val_loss: 67.4109\n",
      "Epoch 254/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 64.9500 - val_loss: 67.0268\n",
      "Epoch 255/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 64.6394 - val_loss: 66.7095\n",
      "Epoch 256/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 64.2574 - val_loss: 66.1411\n",
      "Epoch 257/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 63.9270 - val_loss: 65.7763\n",
      "Epoch 258/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 63.5374 - val_loss: 65.2900\n",
      "Epoch 259/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 63.1486 - val_loss: 64.7584\n",
      "Epoch 260/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 62.7622 - val_loss: 64.2717\n",
      "Epoch 261/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 62.3510 - val_loss: 63.8360\n",
      "Epoch 262/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 61.9429 - val_loss: 63.2584\n",
      "Epoch 263/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 61.4795 - val_loss: 62.7545\n",
      "Epoch 264/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 61.0025 - val_loss: 62.1684\n",
      "Epoch 265/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 60.4752 - val_loss: 61.4406\n",
      "Epoch 266/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 59.9424 - val_loss: 60.8655\n",
      "Epoch 267/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 59.3458 - val_loss: 60.0897\n",
      "Epoch 268/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 58.7160 - val_loss: 59.3247\n",
      "Epoch 269/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 58.0479 - val_loss: 58.5517\n",
      "Epoch 270/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 57.3289 - val_loss: 57.7818\n",
      "Epoch 271/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 56.5963 - val_loss: 56.8790\n",
      "Epoch 272/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 55.7680 - val_loss: 55.7974\n",
      "Epoch 273/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 54.8391 - val_loss: 54.5729\n",
      "Epoch 274/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 53.7845 - val_loss: 53.3077\n",
      "Epoch 275/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 52.5356 - val_loss: 51.6966\n",
      "Epoch 276/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 51.0717 - val_loss: 49.7547\n",
      "Epoch 277/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 49.2152 - val_loss: 47.5539\n",
      "Epoch 278/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 46.9560 - val_loss: 44.7616\n",
      "Epoch 279/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 44.1637 - val_loss: 41.4644\n",
      "Epoch 280/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 40.5750 - val_loss: 36.9322\n",
      "Epoch 281/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 35.8027 - val_loss: 31.4034\n",
      "Epoch 282/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 30.2622 - val_loss: 25.5245\n",
      "Epoch 283/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 24.6815 - val_loss: 20.3469\n",
      "Epoch 284/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 20.1323 - val_loss: 17.2400\n",
      "Epoch 285/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 17.1921 - val_loss: 15.1737\n",
      "Epoch 286/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 15.0268 - val_loss: 13.3158\n",
      "Epoch 287/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 13.1170 - val_loss: 11.7368\n",
      "Epoch 288/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 11.3796 - val_loss: 10.1912\n",
      "Epoch 289/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 9.7448 - val_loss: 8.8207\n",
      "Epoch 290/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 8.3107 - val_loss: 7.5400\n",
      "Epoch 291/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 7.0048 - val_loss: 6.6319\n",
      "Epoch 292/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 5.8615 - val_loss: 5.6480\n",
      "Epoch 293/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 4.8729 - val_loss: 4.6611\n",
      "Epoch 294/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 3.9923 - val_loss: 4.0672\n",
      "Epoch 295/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 3.2579 - val_loss: 3.5733\n",
      "Epoch 296/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 2.7181 - val_loss: 3.4023\n",
      "Epoch 297/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 2.3407 - val_loss: 3.1405\n",
      "Epoch 298/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 2.0841 - val_loss: 3.0242\n",
      "Epoch 299/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.9784 - val_loss: 2.8830\n",
      "Epoch 300/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.9276 - val_loss: 2.7720\n",
      "Epoch 301/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.8636 - val_loss: 2.9116\n",
      "Epoch 302/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.8016 - val_loss: 2.8756\n",
      "Epoch 303/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.7924 - val_loss: 2.8205\n",
      "Epoch 304/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.7510 - val_loss: 2.7858\n",
      "Epoch 305/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.7757 - val_loss: 2.7785\n",
      "Epoch 306/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.7972 - val_loss: 2.9527\n",
      "Epoch 307/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.7551 - val_loss: 2.6868\n",
      "Epoch 308/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.7535 - val_loss: 2.7515\n",
      "Epoch 309/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.7319 - val_loss: 2.7565\n",
      "Epoch 310/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.7392 - val_loss: 2.6745\n",
      "Epoch 311/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.7158 - val_loss: 2.7765\n",
      "Epoch 312/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.7052 - val_loss: 2.6251\n",
      "Epoch 313/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.7113 - val_loss: 2.6553\n",
      "Epoch 314/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.7432 - val_loss: 2.6522\n",
      "Epoch 315/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.7206 - val_loss: 2.6833\n",
      "Epoch 316/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.7374 - val_loss: 2.5638\n",
      "Epoch 317/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.6954 - val_loss: 2.6969\n",
      "Epoch 318/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.7366 - val_loss: 2.5895\n",
      "Epoch 319/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.7323 - val_loss: 2.5719\n",
      "Epoch 320/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6880 - val_loss: 2.7537\n",
      "Epoch 321/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6817 - val_loss: 2.5002\n",
      "Epoch 322/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.6835 - val_loss: 2.6122\n",
      "Epoch 323/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6937 - val_loss: 2.5013\n",
      "Epoch 324/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6555 - val_loss: 2.6598\n",
      "Epoch 325/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6937 - val_loss: 2.6852\n",
      "Epoch 326/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.7111 - val_loss: 2.7683\n",
      "Epoch 327/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6811 - val_loss: 2.4679\n",
      "Epoch 328/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6665 - val_loss: 2.4242\n",
      "Epoch 329/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6588 - val_loss: 2.4747\n",
      "Epoch 330/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6440 - val_loss: 2.5237\n",
      "Epoch 331/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6432 - val_loss: 2.5263\n",
      "Epoch 332/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6463 - val_loss: 2.5151\n",
      "Epoch 333/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6769 - val_loss: 2.5966\n",
      "Epoch 334/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.6314 - val_loss: 2.4362\n",
      "Epoch 335/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.6419 - val_loss: 2.6493\n",
      "Epoch 336/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6304 - val_loss: 2.5634\n",
      "Epoch 337/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6339 - val_loss: 2.6099\n",
      "Epoch 338/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.6256 - val_loss: 2.4981\n",
      "Epoch 339/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.6224 - val_loss: 2.4373\n",
      "Epoch 340/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6168 - val_loss: 2.4203\n",
      "Epoch 341/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6084 - val_loss: 2.3985\n",
      "Epoch 342/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.6041 - val_loss: 2.4204\n",
      "Epoch 343/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6191 - val_loss: 2.3361\n",
      "Epoch 344/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5929 - val_loss: 2.2879\n",
      "Epoch 345/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.6124 - val_loss: 2.4177\n",
      "Epoch 346/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5991 - val_loss: 2.3672\n",
      "Epoch 347/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5996 - val_loss: 2.3171\n",
      "Epoch 348/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.6964 - val_loss: 2.4298\n",
      "Epoch 349/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6611 - val_loss: 2.3536\n",
      "Epoch 350/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.7407 - val_loss: 2.3567\n",
      "Epoch 351/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5900 - val_loss: 2.5304\n",
      "Epoch 352/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6241 - val_loss: 2.3994\n",
      "Epoch 353/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.6640 - val_loss: 2.2753\n",
      "Epoch 354/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6050 - val_loss: 2.5032\n",
      "Epoch 355/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5753 - val_loss: 2.2825\n",
      "Epoch 356/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6014 - val_loss: 2.2835\n",
      "Epoch 357/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5630 - val_loss: 2.3651\n",
      "Epoch 358/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5516 - val_loss: 2.3204\n",
      "Epoch 359/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5669 - val_loss: 2.3035\n",
      "Epoch 360/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.5500 - val_loss: 2.3702\n",
      "Epoch 361/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.5905 - val_loss: 2.3674\n",
      "Epoch 362/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.6003 - val_loss: 2.5135\n",
      "Epoch 363/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5924 - val_loss: 2.2927\n",
      "Epoch 364/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.6189 - val_loss: 2.2658\n",
      "Epoch 365/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.5876 - val_loss: 2.2552\n",
      "Epoch 366/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5685 - val_loss: 2.1965\n",
      "Epoch 367/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.5385 - val_loss: 2.4306\n",
      "Epoch 368/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.5401 - val_loss: 2.3592\n",
      "Epoch 369/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5555 - val_loss: 2.0999\n",
      "Epoch 370/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.5505 - val_loss: 2.3644\n",
      "Epoch 371/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.5506 - val_loss: 2.4227\n",
      "Epoch 372/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5230 - val_loss: 2.2144\n",
      "Epoch 373/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5416 - val_loss: 2.2049\n",
      "Epoch 374/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.5215 - val_loss: 2.1878\n",
      "Epoch 375/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.5281 - val_loss: 2.2350\n",
      "Epoch 376/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5167 - val_loss: 2.2403\n",
      "Epoch 377/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5383 - val_loss: 2.0950\n",
      "Epoch 378/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5083 - val_loss: 2.2019\n",
      "Epoch 379/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5362 - val_loss: 2.4625\n",
      "Epoch 380/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.5173 - val_loss: 2.1760\n",
      "Epoch 381/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5067 - val_loss: 2.1019\n",
      "Epoch 382/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5123 - val_loss: 2.1772\n",
      "Epoch 383/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5314 - val_loss: 2.1304\n",
      "Epoch 384/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4769 - val_loss: 2.1900\n",
      "Epoch 385/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.5247 - val_loss: 2.3044\n",
      "Epoch 386/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.6288 - val_loss: 2.3216\n",
      "Epoch 387/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5314 - val_loss: 2.1192\n",
      "Epoch 388/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4854 - val_loss: 2.1155\n",
      "Epoch 389/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5228 - val_loss: 2.0294\n",
      "Epoch 390/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5041 - val_loss: 2.0663\n",
      "Epoch 391/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4877 - val_loss: 2.0573\n",
      "Epoch 392/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4803 - val_loss: 2.1792\n",
      "Epoch 393/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.4846 - val_loss: 2.1434\n",
      "Epoch 394/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.5418 - val_loss: 2.1178\n",
      "Epoch 395/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4719 - val_loss: 2.0792\n",
      "Epoch 396/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4496 - val_loss: 2.1805\n",
      "Epoch 397/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4744 - val_loss: 2.1529\n",
      "Epoch 398/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.4631 - val_loss: 2.3694\n",
      "Epoch 399/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.4918 - val_loss: 1.9115\n",
      "Epoch 400/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4689 - val_loss: 1.9835\n",
      "Epoch 401/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.4455 - val_loss: 2.1208\n",
      "Epoch 402/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4491 - val_loss: 2.1295\n",
      "Epoch 403/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4964 - val_loss: 2.0096\n",
      "Epoch 404/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4224 - val_loss: 2.0833\n",
      "Epoch 405/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4358 - val_loss: 2.0534\n",
      "Epoch 406/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4417 - val_loss: 2.1776\n",
      "Epoch 407/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4798 - val_loss: 2.0985\n",
      "Epoch 408/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4155 - val_loss: 2.0944\n",
      "Epoch 409/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.4577 - val_loss: 1.8575\n",
      "Epoch 410/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4075 - val_loss: 2.1858\n",
      "Epoch 411/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.4732 - val_loss: 2.0543\n",
      "Epoch 412/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.4152 - val_loss: 1.9705\n",
      "Epoch 413/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.4461 - val_loss: 2.0646\n",
      "Epoch 414/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4789 - val_loss: 2.3315\n",
      "Epoch 415/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4332 - val_loss: 2.0520\n",
      "Epoch 416/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4117 - val_loss: 2.0581\n",
      "Epoch 417/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4711 - val_loss: 1.9767\n",
      "Epoch 418/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.4112 - val_loss: 2.0065\n",
      "Epoch 419/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.4512 - val_loss: 2.1032\n",
      "Epoch 420/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3981 - val_loss: 1.8670\n",
      "Epoch 421/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.5218 - val_loss: 1.9678\n",
      "Epoch 422/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4282 - val_loss: 1.9626\n",
      "Epoch 423/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4108 - val_loss: 2.0142\n",
      "Epoch 424/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3883 - val_loss: 2.0679\n",
      "Epoch 425/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3983 - val_loss: 1.8374\n",
      "Epoch 426/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4084 - val_loss: 1.9853\n",
      "Epoch 427/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.4344 - val_loss: 1.8791\n",
      "Epoch 428/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4064 - val_loss: 2.1072\n",
      "Epoch 429/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.5321 - val_loss: 1.9307\n",
      "Epoch 430/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4080 - val_loss: 1.9335\n",
      "Epoch 431/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4293 - val_loss: 2.0490\n",
      "Epoch 432/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3780 - val_loss: 2.0095\n",
      "Epoch 433/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.4254 - val_loss: 2.1105\n",
      "Epoch 434/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3884 - val_loss: 2.0336\n",
      "Epoch 435/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4153 - val_loss: 1.8788\n",
      "Epoch 436/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.3573 - val_loss: 2.0804\n",
      "Epoch 437/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.4358 - val_loss: 2.0300\n",
      "Epoch 438/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3749 - val_loss: 1.8699\n",
      "Epoch 439/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3882 - val_loss: 1.7761\n",
      "Epoch 440/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4845 - val_loss: 2.0150\n",
      "Epoch 441/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.4106 - val_loss: 1.8391\n",
      "Epoch 442/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.3740 - val_loss: 1.9070\n",
      "Epoch 443/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3917 - val_loss: 1.7809\n",
      "Epoch 444/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3729 - val_loss: 1.7877\n",
      "Epoch 445/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3734 - val_loss: 1.8341\n",
      "Epoch 446/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3708 - val_loss: 1.8245\n",
      "Epoch 447/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3708 - val_loss: 2.0048\n",
      "Epoch 448/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3682 - val_loss: 1.9806\n",
      "Epoch 449/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.4046 - val_loss: 1.8286\n",
      "Epoch 450/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.4309 - val_loss: 2.0217\n",
      "Epoch 451/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3874 - val_loss: 1.8525\n",
      "Epoch 452/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3977 - val_loss: 1.9238\n",
      "Epoch 453/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3777 - val_loss: 1.7487\n",
      "Epoch 454/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3621 - val_loss: 1.8663\n",
      "Epoch 455/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3849 - val_loss: 1.8991\n",
      "Epoch 456/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.3895 - val_loss: 1.8338\n",
      "Epoch 457/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3382 - val_loss: 1.7806\n",
      "Epoch 458/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3262 - val_loss: 1.7159\n",
      "Epoch 459/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3648 - val_loss: 1.7908\n",
      "Epoch 460/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3389 - val_loss: 1.8997\n",
      "Epoch 461/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.4024 - val_loss: 1.9765\n",
      "Epoch 462/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.3740 - val_loss: 1.7049\n",
      "Epoch 463/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3392 - val_loss: 1.8645\n",
      "Epoch 464/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3594 - val_loss: 1.7713\n",
      "Epoch 465/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3453 - val_loss: 1.7359\n",
      "Epoch 466/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3242 - val_loss: 1.8503\n",
      "Epoch 467/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3438 - val_loss: 1.8396\n",
      "Epoch 468/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3325 - val_loss: 1.8092\n",
      "Epoch 469/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3174 - val_loss: 1.7169\n",
      "Epoch 470/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.3197 - val_loss: 1.7352\n",
      "Epoch 471/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3260 - val_loss: 1.7809\n",
      "Epoch 472/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3303 - val_loss: 1.7296\n",
      "Epoch 473/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3097 - val_loss: 1.7001\n",
      "Epoch 474/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3206 - val_loss: 1.8383\n",
      "Epoch 475/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3975 - val_loss: 1.6633\n",
      "Epoch 476/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3205 - val_loss: 1.6704\n",
      "Epoch 477/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3065 - val_loss: 1.7413\n",
      "Epoch 478/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3020 - val_loss: 1.7019\n",
      "Epoch 479/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3110 - val_loss: 1.6654\n",
      "Epoch 480/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2913 - val_loss: 1.6889\n",
      "Epoch 481/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3986 - val_loss: 2.0746\n",
      "Epoch 482/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3772 - val_loss: 1.7124\n",
      "Epoch 483/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3641 - val_loss: 1.6479\n",
      "Epoch 484/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.3128 - val_loss: 1.6671\n",
      "Epoch 485/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.3097 - val_loss: 1.7891\n",
      "Epoch 486/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2953 - val_loss: 1.7236\n",
      "Epoch 487/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.3008 - val_loss: 1.6933\n",
      "Epoch 488/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3192 - val_loss: 1.7958\n",
      "Epoch 489/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3058 - val_loss: 1.6692\n",
      "Epoch 490/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2875 - val_loss: 1.7145\n",
      "Epoch 491/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2871 - val_loss: 1.8008\n",
      "Epoch 492/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3254 - val_loss: 1.6540\n",
      "Epoch 493/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3217 - val_loss: 1.6364\n",
      "Epoch 494/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.3834 - val_loss: 1.7933\n",
      "Epoch 495/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.3384 - val_loss: 1.6297\n",
      "Epoch 496/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3935 - val_loss: 1.8086\n",
      "Epoch 497/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2659 - val_loss: 1.6148\n",
      "Epoch 498/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2986 - val_loss: 1.6408\n",
      "Epoch 499/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3333 - val_loss: 1.6135\n",
      "Epoch 500/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2947 - val_loss: 1.7248\n",
      "Epoch 501/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2949 - val_loss: 1.7553\n",
      "Epoch 502/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2774 - val_loss: 1.7023\n",
      "Epoch 503/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2745 - val_loss: 1.6510\n",
      "Epoch 504/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3160 - val_loss: 1.8002\n",
      "Epoch 505/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2982 - val_loss: 1.6251\n",
      "Epoch 506/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2763 - val_loss: 1.5436\n",
      "Epoch 507/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3141 - val_loss: 1.6332\n",
      "Epoch 508/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2846 - val_loss: 1.8696\n",
      "Epoch 509/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.3093 - val_loss: 1.6156\n",
      "Epoch 510/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3031 - val_loss: 1.6934\n",
      "Epoch 511/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2816 - val_loss: 1.7512\n",
      "Epoch 512/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2590 - val_loss: 1.8772\n",
      "Epoch 513/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2818 - val_loss: 1.5525\n",
      "Epoch 514/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2889 - val_loss: 1.5494\n",
      "Epoch 515/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2646 - val_loss: 1.5643\n",
      "Epoch 516/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2964 - val_loss: 1.6393\n",
      "Epoch 517/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2704 - val_loss: 1.6104\n",
      "Epoch 518/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3254 - val_loss: 1.9309\n",
      "Epoch 519/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3020 - val_loss: 1.7443\n",
      "Epoch 520/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2833 - val_loss: 1.5004\n",
      "Epoch 521/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2861 - val_loss: 1.5496\n",
      "Epoch 522/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2493 - val_loss: 1.6543\n",
      "Epoch 523/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2746 - val_loss: 1.5485\n",
      "Epoch 524/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2628 - val_loss: 1.5677\n",
      "Epoch 525/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2348 - val_loss: 1.6938\n",
      "Epoch 526/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2398 - val_loss: 1.6557\n",
      "Epoch 527/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2518 - val_loss: 1.5998\n",
      "Epoch 528/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3126 - val_loss: 1.6678\n",
      "Epoch 529/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2791 - val_loss: 1.5298\n",
      "Epoch 530/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2808 - val_loss: 1.4816\n",
      "Epoch 531/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3073 - val_loss: 1.5039\n",
      "Epoch 532/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2593 - val_loss: 1.6025\n",
      "Epoch 533/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2419 - val_loss: 1.4972\n",
      "Epoch 534/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2476 - val_loss: 1.4958\n",
      "Epoch 535/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2800 - val_loss: 1.5556\n",
      "Epoch 536/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2495 - val_loss: 1.6414\n",
      "Epoch 537/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2482 - val_loss: 1.6365\n",
      "Epoch 538/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2331 - val_loss: 1.6210\n",
      "Epoch 539/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2406 - val_loss: 1.4905\n",
      "Epoch 540/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2271 - val_loss: 1.6521\n",
      "Epoch 541/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2387 - val_loss: 1.6022\n",
      "Epoch 542/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2749 - val_loss: 1.5897\n",
      "Epoch 543/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2573 - val_loss: 1.5351\n",
      "Epoch 544/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2386 - val_loss: 1.5530\n",
      "Epoch 545/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2577 - val_loss: 1.9232\n",
      "Epoch 546/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.3531 - val_loss: 1.5721\n",
      "Epoch 547/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2794 - val_loss: 1.6100\n",
      "Epoch 548/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2386 - val_loss: 1.6092\n",
      "Epoch 549/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2618 - val_loss: 1.6511\n",
      "Epoch 550/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2328 - val_loss: 1.4557\n",
      "Epoch 551/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2575 - val_loss: 1.5364\n",
      "Epoch 552/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2315 - val_loss: 1.5589\n",
      "Epoch 553/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2304 - val_loss: 1.6234\n",
      "Epoch 554/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2409 - val_loss: 1.5523\n",
      "Epoch 555/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2494 - val_loss: 1.5075\n",
      "Epoch 556/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2598 - val_loss: 1.6928\n",
      "Epoch 557/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2744 - val_loss: 1.4959\n",
      "Epoch 558/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2583 - val_loss: 1.6167\n",
      "Epoch 559/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2643 - val_loss: 1.5670\n",
      "Epoch 560/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2270 - val_loss: 1.4580\n",
      "Epoch 561/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2208 - val_loss: 1.5037\n",
      "Epoch 562/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3240 - val_loss: 1.7851\n",
      "Epoch 563/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.3044 - val_loss: 1.5635\n",
      "Epoch 564/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2312 - val_loss: 1.4490\n",
      "Epoch 565/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2126 - val_loss: 1.5125\n",
      "Epoch 566/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2307 - val_loss: 1.6381\n",
      "Epoch 567/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2638 - val_loss: 1.7077\n",
      "Epoch 568/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2522 - val_loss: 1.4324\n",
      "Epoch 569/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2889 - val_loss: 1.6965\n",
      "Epoch 570/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2856 - val_loss: 1.4566\n",
      "Epoch 571/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2646 - val_loss: 1.5296\n",
      "Epoch 572/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1974 - val_loss: 1.5454\n",
      "Epoch 573/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2077 - val_loss: 1.7575\n",
      "Epoch 574/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2531 - val_loss: 1.5111\n",
      "Epoch 575/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2173 - val_loss: 1.6761\n",
      "Epoch 576/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2380 - val_loss: 1.4547\n",
      "Epoch 577/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1967 - val_loss: 1.4342\n",
      "Epoch 578/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1995 - val_loss: 1.4990\n",
      "Epoch 579/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2529 - val_loss: 1.4245\n",
      "Epoch 580/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2051 - val_loss: 1.4391\n",
      "Epoch 581/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2128 - val_loss: 1.5858\n",
      "Epoch 582/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2136 - val_loss: 1.4687\n",
      "Epoch 583/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2394 - val_loss: 1.4408\n",
      "Epoch 584/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2295 - val_loss: 1.4408\n",
      "Epoch 585/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2130 - val_loss: 1.4123\n",
      "Epoch 586/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2280 - val_loss: 1.4072\n",
      "Epoch 587/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2467 - val_loss: 1.3971\n",
      "Epoch 588/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2578 - val_loss: 1.6409\n",
      "Epoch 589/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2105 - val_loss: 1.5276\n",
      "Epoch 590/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2139 - val_loss: 1.4688\n",
      "Epoch 591/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2879 - val_loss: 1.3525\n",
      "Epoch 592/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2464 - val_loss: 1.5578\n",
      "Epoch 593/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2463 - val_loss: 1.5477\n",
      "Epoch 594/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2290 - val_loss: 1.3955\n",
      "Epoch 595/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2027 - val_loss: 1.4965\n",
      "Epoch 596/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2127 - val_loss: 1.4577\n",
      "Epoch 597/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2277 - val_loss: 1.5105\n",
      "Epoch 598/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1796 - val_loss: 1.5183\n",
      "Epoch 599/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1925 - val_loss: 1.5142\n",
      "Epoch 600/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1991 - val_loss: 1.4061\n",
      "Epoch 601/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2904 - val_loss: 1.6150\n",
      "Epoch 602/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2397 - val_loss: 1.4515\n",
      "Epoch 603/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1998 - val_loss: 1.5101\n",
      "Epoch 604/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1758 - val_loss: 1.3281\n",
      "Epoch 605/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1968 - val_loss: 1.4401\n",
      "Epoch 606/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1970 - val_loss: 1.4015\n",
      "Epoch 607/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2185 - val_loss: 1.4022\n",
      "Epoch 608/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1884 - val_loss: 1.4399\n",
      "Epoch 609/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2051 - val_loss: 1.5223\n",
      "Epoch 610/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2468 - val_loss: 1.3421\n",
      "Epoch 611/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2513 - val_loss: 1.4209\n",
      "Epoch 612/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1836 - val_loss: 1.4281\n",
      "Epoch 613/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2359 - val_loss: 1.4186\n",
      "Epoch 614/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2156 - val_loss: 1.5995\n",
      "Epoch 615/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2340 - val_loss: 1.3999\n",
      "Epoch 616/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1910 - val_loss: 1.4330\n",
      "Epoch 617/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2266 - val_loss: 1.4373\n",
      "Epoch 618/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1979 - val_loss: 1.3726\n",
      "Epoch 619/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2216 - val_loss: 1.4771\n",
      "Epoch 620/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2044 - val_loss: 1.4957\n",
      "Epoch 621/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2076 - val_loss: 1.4973\n",
      "Epoch 622/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1754 - val_loss: 1.4137\n",
      "Epoch 623/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1803 - val_loss: 1.4937\n",
      "Epoch 624/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2145 - val_loss: 1.4519\n",
      "Epoch 625/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1809 - val_loss: 1.3924\n",
      "Epoch 626/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1800 - val_loss: 1.4455\n",
      "Epoch 627/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1916 - val_loss: 1.4314\n",
      "Epoch 628/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1801 - val_loss: 1.3832\n",
      "Epoch 629/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2022 - val_loss: 1.3261\n",
      "Epoch 630/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2188 - val_loss: 1.4569\n",
      "Epoch 631/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2590 - val_loss: 1.5515\n",
      "Epoch 632/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2963 - val_loss: 1.3517\n",
      "Epoch 633/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1996 - val_loss: 1.3230\n",
      "Epoch 634/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1731 - val_loss: 1.4912\n",
      "Epoch 635/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1972 - val_loss: 1.4427\n",
      "Epoch 636/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1870 - val_loss: 1.3164\n",
      "Epoch 637/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2343 - val_loss: 1.3242\n",
      "Epoch 638/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2558 - val_loss: 1.5846\n",
      "Epoch 639/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2077 - val_loss: 1.3674\n",
      "Epoch 640/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1895 - val_loss: 1.5375\n",
      "Epoch 641/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.1853 - val_loss: 1.3416\n",
      "Epoch 642/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1876 - val_loss: 1.3433\n",
      "Epoch 643/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1768 - val_loss: 1.3388\n",
      "Epoch 644/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2134 - val_loss: 1.3727\n",
      "Epoch 645/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1893 - val_loss: 1.4526\n",
      "Epoch 646/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1862 - val_loss: 1.3186\n",
      "Epoch 647/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1847 - val_loss: 1.3500\n",
      "Epoch 648/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2190 - val_loss: 1.3574\n",
      "Epoch 649/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2861 - val_loss: 1.7445\n",
      "Epoch 650/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1911 - val_loss: 1.3157\n",
      "Epoch 651/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2079 - val_loss: 1.3111\n",
      "Epoch 652/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1463 - val_loss: 1.3911\n",
      "Epoch 653/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2054 - val_loss: 1.3539\n",
      "Epoch 654/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1852 - val_loss: 1.3639\n",
      "Epoch 655/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3177 - val_loss: 1.5980\n",
      "Epoch 656/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2027 - val_loss: 1.3341\n",
      "Epoch 657/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1806 - val_loss: 1.5349\n",
      "Epoch 658/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2311 - val_loss: 1.3450\n",
      "Epoch 659/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1672 - val_loss: 1.3262\n",
      "Epoch 660/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2772 - val_loss: 1.5197\n",
      "Epoch 661/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1809 - val_loss: 1.4111\n",
      "Epoch 662/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2231 - val_loss: 1.3481\n",
      "Epoch 663/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2231 - val_loss: 1.3824\n",
      "Epoch 664/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1837 - val_loss: 1.2944\n",
      "Epoch 665/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1902 - val_loss: 1.3923\n",
      "Epoch 666/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2115 - val_loss: 1.3743\n",
      "Epoch 667/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1604 - val_loss: 1.3071\n",
      "Epoch 668/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2451 - val_loss: 1.5053\n",
      "Epoch 669/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2019 - val_loss: 1.4122\n",
      "Epoch 670/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1811 - val_loss: 1.3419\n",
      "Epoch 671/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1848 - val_loss: 1.3567\n",
      "Epoch 672/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2005 - val_loss: 1.2509\n",
      "Epoch 673/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1487 - val_loss: 1.3725\n",
      "Epoch 674/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1626 - val_loss: 1.3186\n",
      "Epoch 675/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2226 - val_loss: 1.4830\n",
      "Epoch 676/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1675 - val_loss: 1.4380\n",
      "Epoch 677/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1846 - val_loss: 1.3312\n",
      "Epoch 678/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1613 - val_loss: 1.3620\n",
      "Epoch 679/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1737 - val_loss: 1.3500\n",
      "Epoch 680/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2979 - val_loss: 1.4736\n",
      "Epoch 681/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1856 - val_loss: 1.3117\n",
      "Epoch 682/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1604 - val_loss: 1.3637\n",
      "Epoch 683/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1645 - val_loss: 1.4098\n",
      "Epoch 684/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1738 - val_loss: 1.2745\n",
      "Epoch 685/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2638 - val_loss: 1.4579\n",
      "Epoch 686/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2216 - val_loss: 1.2482\n",
      "Epoch 687/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1935 - val_loss: 1.4994\n",
      "Epoch 688/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2549 - val_loss: 1.4147\n",
      "Epoch 689/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1807 - val_loss: 1.3222\n",
      "Epoch 690/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2104 - val_loss: 1.3171\n",
      "Epoch 691/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1947 - val_loss: 1.4429\n",
      "Epoch 692/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2361 - val_loss: 1.4911\n",
      "Epoch 693/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.3285 - val_loss: 1.3385\n",
      "Epoch 694/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1730 - val_loss: 1.5901\n",
      "Epoch 695/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2217 - val_loss: 1.4637\n",
      "Epoch 696/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1864 - val_loss: 1.3498\n",
      "Epoch 697/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2407 - val_loss: 1.4478\n",
      "Epoch 698/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1843 - val_loss: 1.3401\n",
      "Epoch 699/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1675 - val_loss: 1.2996\n",
      "Epoch 700/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1918 - val_loss: 1.3366\n",
      "Epoch 701/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2056 - val_loss: 1.4423\n",
      "Epoch 702/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2198 - val_loss: 1.2499\n",
      "Epoch 703/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2400 - val_loss: 1.3550\n",
      "Epoch 704/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1827 - val_loss: 1.3054\n",
      "Epoch 705/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1834 - val_loss: 1.4477\n",
      "Epoch 706/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2080 - val_loss: 1.4094\n",
      "Epoch 707/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2173 - val_loss: 1.3311\n",
      "Epoch 708/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1613 - val_loss: 1.3618\n",
      "Epoch 709/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1925 - val_loss: 1.2343\n",
      "Epoch 710/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1836 - val_loss: 1.2491\n",
      "Epoch 711/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1803 - val_loss: 1.2890\n",
      "Epoch 712/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1489 - val_loss: 1.2616\n",
      "Epoch 713/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1715 - val_loss: 1.3604\n",
      "Epoch 714/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1506 - val_loss: 1.2310\n",
      "Epoch 715/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1503 - val_loss: 1.2623\n",
      "Epoch 716/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1530 - val_loss: 1.2978\n",
      "Epoch 717/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1514 - val_loss: 1.2422\n",
      "Epoch 718/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1983 - val_loss: 1.5468\n",
      "Epoch 719/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1738 - val_loss: 1.3466\n",
      "Epoch 720/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1812 - val_loss: 1.2833\n",
      "Epoch 721/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1629 - val_loss: 1.2696\n",
      "Epoch 722/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1999 - val_loss: 1.4174\n",
      "Epoch 723/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1575 - val_loss: 1.2491\n",
      "Epoch 724/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1760 - val_loss: 1.4994\n",
      "Epoch 725/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1614 - val_loss: 1.2591\n",
      "Epoch 726/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1731 - val_loss: 1.3346\n",
      "Epoch 727/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1522 - val_loss: 1.3175\n",
      "Epoch 728/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1545 - val_loss: 1.2599\n",
      "Epoch 729/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1637 - val_loss: 1.2634\n",
      "Epoch 730/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1756 - val_loss: 1.3015\n",
      "Epoch 731/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2009 - val_loss: 1.2692\n",
      "Epoch 732/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2147 - val_loss: 1.3933\n",
      "Epoch 733/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1369 - val_loss: 1.2558\n",
      "Epoch 734/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1974 - val_loss: 1.2162\n",
      "Epoch 735/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2067 - val_loss: 1.3556\n",
      "Epoch 736/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1460 - val_loss: 1.3127\n",
      "Epoch 737/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1769 - val_loss: 1.2996\n",
      "Epoch 738/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2123 - val_loss: 1.3956\n",
      "Epoch 739/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1334 - val_loss: 1.2670\n",
      "Epoch 740/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1608 - val_loss: 1.4918\n",
      "Epoch 741/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1484 - val_loss: 1.2296\n",
      "Epoch 742/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1330 - val_loss: 1.2830\n",
      "Epoch 743/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1931 - val_loss: 1.3859\n",
      "Epoch 744/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1702 - val_loss: 1.2637\n",
      "Epoch 745/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1594 - val_loss: 1.3693\n",
      "Epoch 746/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1657 - val_loss: 1.2641\n",
      "Epoch 747/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1748 - val_loss: 1.3210\n",
      "Epoch 748/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1635 - val_loss: 1.2659\n",
      "Epoch 749/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1542 - val_loss: 1.3454\n",
      "Epoch 750/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1530 - val_loss: 1.2291\n",
      "Epoch 751/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1650 - val_loss: 1.2585\n",
      "Epoch 752/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2379 - val_loss: 1.2886\n",
      "Epoch 753/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2377 - val_loss: 1.4125\n",
      "Epoch 754/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1887 - val_loss: 1.3312\n",
      "Epoch 755/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2028 - val_loss: 1.4473\n",
      "Epoch 756/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2000 - val_loss: 1.2393\n",
      "Epoch 757/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2059 - val_loss: 1.2876\n",
      "Epoch 758/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1426 - val_loss: 1.2238\n",
      "Epoch 759/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1425 - val_loss: 1.3610\n",
      "Epoch 760/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1669 - val_loss: 1.2715\n",
      "Epoch 761/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1321 - val_loss: 1.2695\n",
      "Epoch 762/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1850 - val_loss: 1.3271\n",
      "Epoch 763/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1867 - val_loss: 1.2885\n",
      "Epoch 764/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2035 - val_loss: 1.5015\n",
      "Epoch 765/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1595 - val_loss: 1.3039\n",
      "Epoch 766/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1855 - val_loss: 1.2857\n",
      "Epoch 767/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1452 - val_loss: 1.2644\n",
      "Epoch 768/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1790 - val_loss: 1.2198\n",
      "Epoch 769/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1851 - val_loss: 1.3031\n",
      "Epoch 770/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1596 - val_loss: 1.2403\n",
      "Epoch 771/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1726 - val_loss: 1.3253\n",
      "Epoch 772/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1725 - val_loss: 1.3702\n",
      "Epoch 773/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1640 - val_loss: 1.2822\n",
      "Epoch 774/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1950 - val_loss: 1.3385\n",
      "Epoch 775/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1572 - val_loss: 1.2530\n",
      "Epoch 776/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2354 - val_loss: 1.3477\n",
      "Epoch 777/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1669 - val_loss: 1.3343\n",
      "Epoch 778/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2220 - val_loss: 1.2019\n",
      "Epoch 779/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1761 - val_loss: 1.3393\n",
      "Epoch 780/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1679 - val_loss: 1.3390\n",
      "Epoch 781/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1926 - val_loss: 1.3232\n",
      "Epoch 782/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1830 - val_loss: 1.2544\n",
      "Epoch 783/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1718 - val_loss: 1.2534\n",
      "Epoch 784/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1422 - val_loss: 1.3238\n",
      "Epoch 785/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1754 - val_loss: 1.3702\n",
      "Epoch 786/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1744 - val_loss: 1.2382\n",
      "Epoch 787/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1500 - val_loss: 1.3714\n",
      "Epoch 788/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1545 - val_loss: 1.2901\n",
      "Epoch 789/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1673 - val_loss: 1.2670\n",
      "Epoch 790/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1507 - val_loss: 1.2354\n",
      "Epoch 791/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1712 - val_loss: 1.3352\n",
      "Epoch 792/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1945 - val_loss: 1.3815\n",
      "Epoch 793/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1547 - val_loss: 1.2848\n",
      "Epoch 794/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1561 - val_loss: 1.2647\n",
      "Epoch 795/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1471 - val_loss: 1.2677\n",
      "Epoch 796/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1803 - val_loss: 1.3418\n",
      "Epoch 797/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1999 - val_loss: 1.2439\n",
      "Epoch 798/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1600 - val_loss: 1.3260\n",
      "Epoch 799/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1442 - val_loss: 1.2621\n",
      "Epoch 800/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1585 - val_loss: 1.2521\n",
      "Epoch 801/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.1506 - val_loss: 1.2750\n",
      "Epoch 802/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.1455 - val_loss: 1.3211\n",
      "Epoch 803/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.1823 - val_loss: 1.2253\n",
      "Epoch 804/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1875 - val_loss: 1.5922\n",
      "Epoch 805/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.1605 - val_loss: 1.3255\n",
      "Epoch 806/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1891 - val_loss: 1.2998\n",
      "Epoch 807/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1987 - val_loss: 1.2509\n",
      "Epoch 808/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1612 - val_loss: 1.1937\n",
      "Epoch 809/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1768 - val_loss: 1.2128\n",
      "Epoch 810/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1326 - val_loss: 1.2864\n",
      "Epoch 811/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1583 - val_loss: 1.2308\n",
      "Epoch 812/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.1340 - val_loss: 1.2644\n",
      "Epoch 813/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1522 - val_loss: 1.3041\n",
      "Epoch 814/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1699 - val_loss: 1.3197\n",
      "Epoch 815/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1655 - val_loss: 1.1955\n",
      "Epoch 816/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1501 - val_loss: 1.2575\n",
      "Epoch 817/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1528 - val_loss: 1.2671\n",
      "Epoch 818/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1417 - val_loss: 1.2082\n",
      "Epoch 819/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1641 - val_loss: 1.2880\n",
      "Epoch 820/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1538 - val_loss: 1.2495\n",
      "Epoch 821/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1390 - val_loss: 1.2638\n",
      "Epoch 822/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1485 - val_loss: 1.2499\n",
      "Epoch 823/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1474 - val_loss: 1.3153\n",
      "Epoch 824/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1496 - val_loss: 1.2607\n",
      "Epoch 825/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1486 - val_loss: 1.3211\n",
      "Epoch 826/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1350 - val_loss: 1.2401\n",
      "Epoch 827/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1458 - val_loss: 1.3144\n",
      "Epoch 828/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1410 - val_loss: 1.4347\n",
      "Epoch 829/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1933 - val_loss: 1.3812\n",
      "Epoch 830/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1325 - val_loss: 1.2514\n",
      "Epoch 831/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1522 - val_loss: 1.1939\n",
      "Epoch 832/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1746 - val_loss: 1.2733\n",
      "Epoch 833/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2208 - val_loss: 1.3671\n",
      "Epoch 834/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2129 - val_loss: 1.5355\n",
      "Epoch 835/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2388 - val_loss: 1.3168\n",
      "Epoch 836/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2287 - val_loss: 1.3315\n",
      "Epoch 837/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1483 - val_loss: 1.2162\n",
      "Epoch 838/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1762 - val_loss: 1.2487\n",
      "Epoch 839/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1642 - val_loss: 1.2266\n",
      "Epoch 840/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.1694 - val_loss: 1.1947\n",
      "Epoch 841/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.2179 - val_loss: 1.3121\n",
      "Epoch 842/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1656 - val_loss: 1.3545\n",
      "Epoch 843/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1598 - val_loss: 1.3065\n",
      "Epoch 844/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1949 - val_loss: 1.5280\n",
      "Epoch 845/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1952 - val_loss: 1.2118\n",
      "Epoch 846/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1582 - val_loss: 1.2974\n",
      "Epoch 847/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1755 - val_loss: 1.3301\n",
      "Epoch 848/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1650 - val_loss: 1.3107\n",
      "Epoch 849/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1582 - val_loss: 1.3836\n",
      "Epoch 850/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1609 - val_loss: 1.2427\n",
      "Epoch 851/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1913 - val_loss: 1.2620\n",
      "Epoch 852/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2134 - val_loss: 1.2381\n",
      "Epoch 853/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1617 - val_loss: 1.3496\n",
      "Epoch 854/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1431 - val_loss: 1.1653\n",
      "Epoch 855/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1616 - val_loss: 1.2337\n",
      "Epoch 856/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1752 - val_loss: 1.2261\n",
      "Epoch 857/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1929 - val_loss: 1.1700\n",
      "Epoch 858/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2093 - val_loss: 1.4169\n",
      "Epoch 859/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1731 - val_loss: 1.2703\n",
      "Epoch 860/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1808 - val_loss: 1.2424\n",
      "Epoch 861/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1550 - val_loss: 1.2545\n",
      "Epoch 862/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1563 - val_loss: 1.3222\n",
      "Epoch 863/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1599 - val_loss: 1.1864\n",
      "Epoch 864/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1340 - val_loss: 1.2317\n",
      "Epoch 865/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1518 - val_loss: 1.2125\n",
      "Epoch 866/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1506 - val_loss: 1.3340\n",
      "Epoch 867/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1455 - val_loss: 1.3379\n",
      "Epoch 868/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1411 - val_loss: 1.3178\n",
      "Epoch 869/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1586 - val_loss: 1.2801\n",
      "Epoch 870/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1704 - val_loss: 1.2213\n",
      "Epoch 871/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1965 - val_loss: 1.2807\n",
      "Epoch 872/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1282 - val_loss: 1.2021\n",
      "Epoch 873/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1210 - val_loss: 1.2535\n",
      "Epoch 874/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1948 - val_loss: 1.2945\n",
      "Epoch 875/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1620 - val_loss: 1.2200\n",
      "Epoch 876/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1799 - val_loss: 1.3125\n",
      "Epoch 877/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1289 - val_loss: 1.3501\n",
      "Epoch 878/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1426 - val_loss: 1.2544\n",
      "Epoch 879/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1475 - val_loss: 1.3010\n",
      "Epoch 880/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1858 - val_loss: 1.4443\n",
      "Epoch 881/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1642 - val_loss: 1.1998\n",
      "Epoch 882/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1326 - val_loss: 1.2097\n",
      "Epoch 883/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1555 - val_loss: 1.2517\n",
      "Epoch 884/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1456 - val_loss: 1.1747\n",
      "Epoch 885/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1438 - val_loss: 1.2248\n",
      "Epoch 886/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1872 - val_loss: 1.2847\n",
      "Epoch 887/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1668 - val_loss: 1.2082\n",
      "Epoch 888/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1324 - val_loss: 1.2605\n",
      "Epoch 889/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1366 - val_loss: 1.2150\n",
      "Epoch 890/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1850 - val_loss: 1.2197\n",
      "Epoch 891/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1395 - val_loss: 1.3402\n",
      "Epoch 892/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1595 - val_loss: 1.2755\n",
      "Epoch 893/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1630 - val_loss: 1.3334\n",
      "Epoch 894/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1447 - val_loss: 1.3121\n",
      "Epoch 895/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1550 - val_loss: 1.1937\n",
      "Epoch 896/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1550 - val_loss: 1.2597\n",
      "Epoch 897/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1555 - val_loss: 1.3540\n",
      "Epoch 898/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1826 - val_loss: 1.4983\n",
      "Epoch 899/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1949 - val_loss: 1.2602\n",
      "Epoch 900/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1571 - val_loss: 1.1773\n",
      "Epoch 901/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1346 - val_loss: 1.2020\n",
      "Epoch 902/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1287 - val_loss: 1.3284\n",
      "Epoch 903/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1482 - val_loss: 1.1995\n",
      "Epoch 904/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1656 - val_loss: 1.2065\n",
      "Epoch 905/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1816 - val_loss: 1.5454\n",
      "Epoch 906/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.2069 - val_loss: 1.1605\n",
      "Epoch 907/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1511 - val_loss: 1.2455\n",
      "Epoch 908/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1802 - val_loss: 1.4696\n",
      "Epoch 909/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.1823 - val_loss: 1.2235\n",
      "Epoch 910/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1715 - val_loss: 1.2825\n",
      "Epoch 911/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1651 - val_loss: 1.2275\n",
      "Epoch 912/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1548 - val_loss: 1.1752\n",
      "Epoch 913/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1525 - val_loss: 1.2307\n",
      "Epoch 914/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1502 - val_loss: 1.1870\n",
      "Epoch 915/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2044 - val_loss: 1.3184\n",
      "Epoch 916/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1468 - val_loss: 1.1895\n",
      "Epoch 917/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1709 - val_loss: 1.1724\n",
      "Epoch 918/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1491 - val_loss: 1.3468\n",
      "Epoch 919/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1326 - val_loss: 1.3069\n",
      "Epoch 920/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1812 - val_loss: 1.1341\n",
      "Epoch 921/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1500 - val_loss: 1.4351\n",
      "Epoch 922/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1589 - val_loss: 1.2260\n",
      "Epoch 923/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1811 - val_loss: 1.2145\n",
      "Epoch 924/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1360 - val_loss: 1.2658\n",
      "Epoch 925/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1887 - val_loss: 1.7137\n",
      "Epoch 926/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2120 - val_loss: 1.2453\n",
      "Epoch 927/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1705 - val_loss: 1.2118\n",
      "Epoch 928/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1874 - val_loss: 1.3389\n",
      "Epoch 929/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2093 - val_loss: 1.2989\n",
      "Epoch 930/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1563 - val_loss: 1.2338\n",
      "Epoch 931/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1605 - val_loss: 1.3385\n",
      "Epoch 932/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1479 - val_loss: 1.4463\n",
      "Epoch 933/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2058 - val_loss: 1.2221\n",
      "Epoch 934/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1709 - val_loss: 1.1802\n",
      "Epoch 935/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1527 - val_loss: 1.2294\n",
      "Epoch 936/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1652 - val_loss: 1.4572\n",
      "Epoch 937/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2572 - val_loss: 1.2144\n",
      "Epoch 938/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1370 - val_loss: 1.2657\n",
      "Epoch 939/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2071 - val_loss: 1.2925\n",
      "Epoch 940/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1894 - val_loss: 1.4606\n",
      "Epoch 941/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1523 - val_loss: 1.2055\n",
      "Epoch 942/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1697 - val_loss: 1.3860\n",
      "Epoch 943/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1410 - val_loss: 1.2014\n",
      "Epoch 944/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1501 - val_loss: 1.2636\n",
      "Epoch 945/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1798 - val_loss: 1.2587\n",
      "Epoch 946/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1515 - val_loss: 1.1723\n",
      "Epoch 947/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1512 - val_loss: 1.1781\n",
      "Epoch 948/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1405 - val_loss: 1.1726\n",
      "Epoch 949/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1338 - val_loss: 1.2865\n",
      "Epoch 950/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1819 - val_loss: 1.1769\n",
      "Epoch 951/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1475 - val_loss: 1.2881\n",
      "Epoch 952/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1759 - val_loss: 1.3146\n",
      "Epoch 953/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1654 - val_loss: 1.2755\n",
      "Epoch 954/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1994 - val_loss: 1.4641\n",
      "Epoch 955/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2599 - val_loss: 1.2138\n",
      "Epoch 956/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1604 - val_loss: 1.1431\n",
      "Epoch 957/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1816 - val_loss: 1.3254\n",
      "Epoch 958/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1504 - val_loss: 1.4426\n",
      "Epoch 959/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1866 - val_loss: 1.3340\n",
      "Epoch 960/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1551 - val_loss: 1.3496\n",
      "Epoch 961/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1592 - val_loss: 1.2190\n",
      "Epoch 962/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1383 - val_loss: 1.2334\n",
      "Epoch 963/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1507 - val_loss: 1.2233\n",
      "Epoch 964/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1943 - val_loss: 1.2677\n",
      "Epoch 965/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1850 - val_loss: 1.1748\n",
      "Epoch 966/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1717 - val_loss: 1.2576\n",
      "Epoch 967/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1349 - val_loss: 1.3563\n",
      "Epoch 968/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1367 - val_loss: 1.2398\n",
      "Epoch 969/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1372 - val_loss: 1.3428\n",
      "Epoch 970/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1734 - val_loss: 1.2443\n",
      "Epoch 971/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1594 - val_loss: 1.1985\n",
      "Epoch 972/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1616 - val_loss: 1.2511\n",
      "Epoch 973/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1756 - val_loss: 1.2453\n",
      "Epoch 974/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2068 - val_loss: 1.3661\n",
      "Epoch 975/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1992 - val_loss: 1.2218\n",
      "Epoch 976/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1354 - val_loss: 1.1839\n",
      "Epoch 977/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1478 - val_loss: 1.4458\n",
      "Epoch 978/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1293 - val_loss: 1.2405\n",
      "Epoch 979/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.1273 - val_loss: 1.2206\n",
      "Epoch 980/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1218 - val_loss: 1.1885\n",
      "Epoch 981/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1407 - val_loss: 1.3845\n",
      "Epoch 982/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1446 - val_loss: 1.2237\n",
      "Epoch 983/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1551 - val_loss: 1.1965\n",
      "Epoch 984/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1371 - val_loss: 1.2168\n",
      "Epoch 985/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1438 - val_loss: 1.3031\n",
      "Epoch 986/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2016 - val_loss: 1.2644\n",
      "Epoch 987/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1756 - val_loss: 1.4483\n",
      "Epoch 988/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2089 - val_loss: 1.1657\n",
      "Epoch 989/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.3039 - val_loss: 1.2919\n",
      "Epoch 990/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1577 - val_loss: 1.1669\n",
      "Epoch 991/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1567 - val_loss: 1.3178\n",
      "Epoch 992/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1825 - val_loss: 1.2863\n",
      "Epoch 993/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1966 - val_loss: 1.2038\n",
      "Epoch 994/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1765 - val_loss: 1.2820\n",
      "Epoch 995/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1966 - val_loss: 1.2266\n",
      "Epoch 996/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2112 - val_loss: 1.2359\n",
      "Epoch 997/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1574 - val_loss: 1.1989\n",
      "Epoch 998/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1520 - val_loss: 1.3000\n",
      "Epoch 999/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1880 - val_loss: 1.1926\n",
      "Epoch 1000/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2408 - val_loss: 1.3703\n",
      "Epoch 1001/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2351 - val_loss: 1.2378\n",
      "Epoch 1002/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1635 - val_loss: 1.2534\n",
      "Epoch 1003/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1349 - val_loss: 1.1698\n",
      "Epoch 1004/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1772 - val_loss: 1.2682\n",
      "Epoch 1005/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1431 - val_loss: 1.2238\n",
      "Epoch 1006/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1441 - val_loss: 1.4072\n",
      "Epoch 1007/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1525 - val_loss: 1.2060\n",
      "Epoch 1008/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1626 - val_loss: 1.4472\n",
      "Epoch 1009/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2503 - val_loss: 1.2535\n",
      "Epoch 1010/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1445 - val_loss: 1.2173\n",
      "Epoch 1011/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1360 - val_loss: 1.1938\n",
      "Epoch 1012/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1212 - val_loss: 1.1664\n",
      "Epoch 1013/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1407 - val_loss: 1.2645\n",
      "Epoch 1014/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1682 - val_loss: 1.3184\n",
      "Epoch 1015/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1479 - val_loss: 1.2052\n",
      "Epoch 1016/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1862 - val_loss: 1.1805\n",
      "Epoch 1017/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1672 - val_loss: 1.1651\n",
      "Epoch 1018/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1978 - val_loss: 1.4056\n",
      "Epoch 1019/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1674 - val_loss: 1.2177\n",
      "Epoch 1020/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1153 - val_loss: 1.1671\n",
      "Epoch 1021/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1286 - val_loss: 1.3361\n",
      "Epoch 1022/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1364 - val_loss: 1.2542\n",
      "Epoch 1023/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1346 - val_loss: 1.1680\n",
      "Epoch 1024/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1652 - val_loss: 1.2925\n",
      "Epoch 1025/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1532 - val_loss: 1.1899\n",
      "Epoch 1026/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1518 - val_loss: 1.3266\n",
      "Epoch 1027/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1512 - val_loss: 1.2296\n",
      "Epoch 1028/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1721 - val_loss: 1.2684\n",
      "Epoch 1029/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1640 - val_loss: 1.1649\n",
      "Epoch 1030/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1783 - val_loss: 1.2168\n",
      "Epoch 1031/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1304 - val_loss: 1.2991\n",
      "Epoch 1032/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1519 - val_loss: 1.1607\n",
      "Epoch 1033/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1350 - val_loss: 1.2024\n",
      "Epoch 1034/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1595 - val_loss: 1.2367\n",
      "Epoch 1035/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1594 - val_loss: 1.3154\n",
      "Epoch 1036/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1840 - val_loss: 1.1691\n",
      "Epoch 1037/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1465 - val_loss: 1.1750\n",
      "Epoch 1038/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1499 - val_loss: 1.3348\n",
      "Epoch 1039/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1819 - val_loss: 1.1932\n",
      "Epoch 1040/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1556 - val_loss: 1.3600\n",
      "Epoch 1041/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1719 - val_loss: 1.1626\n",
      "Epoch 1042/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1270 - val_loss: 1.1848\n",
      "Epoch 1043/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1527 - val_loss: 1.2142\n",
      "Epoch 1044/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1342 - val_loss: 1.4018\n",
      "Epoch 1045/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1412 - val_loss: 1.2201\n",
      "Epoch 1046/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1641 - val_loss: 1.2043\n",
      "Epoch 1047/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1303 - val_loss: 1.1885\n",
      "Epoch 1048/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.1317 - val_loss: 1.1629\n",
      "Epoch 1049/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.1931 - val_loss: 1.2660\n",
      "Epoch 1050/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1513 - val_loss: 1.2061\n",
      "Epoch 1051/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2316 - val_loss: 1.6644\n",
      "Epoch 1052/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1896 - val_loss: 1.2479\n",
      "Epoch 1053/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1569 - val_loss: 1.3740\n",
      "Epoch 1054/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2225 - val_loss: 1.1970\n",
      "Epoch 1055/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1450 - val_loss: 1.3423\n",
      "Epoch 1056/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1547 - val_loss: 1.1991\n",
      "Epoch 1057/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1414 - val_loss: 1.2147\n",
      "Epoch 1058/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2324 - val_loss: 1.1465\n",
      "Epoch 1059/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1879 - val_loss: 1.3598\n",
      "Epoch 1060/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1791 - val_loss: 1.2370\n",
      "Epoch 1061/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1804 - val_loss: 1.3717\n",
      "Epoch 1062/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2307 - val_loss: 1.2490\n",
      "Epoch 1063/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1833 - val_loss: 1.5763\n",
      "Epoch 1064/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1565 - val_loss: 1.2204\n",
      "Epoch 1065/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1675 - val_loss: 1.2115\n",
      "Epoch 1066/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1382 - val_loss: 1.2951\n",
      "Epoch 1067/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1338 - val_loss: 1.2408\n",
      "Epoch 1068/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1493 - val_loss: 1.1848\n",
      "Epoch 1069/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1392 - val_loss: 1.2154\n",
      "Epoch 1070/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1730 - val_loss: 1.3839\n",
      "Epoch 1071/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1311 - val_loss: 1.2480\n",
      "Epoch 1072/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1804 - val_loss: 1.5891\n",
      "Epoch 1073/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.2152 - val_loss: 1.1666\n",
      "Epoch 1074/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1864 - val_loss: 1.1844\n",
      "Epoch 1075/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1535 - val_loss: 1.1679\n",
      "Epoch 1076/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1321 - val_loss: 1.2576\n",
      "Epoch 1077/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1663 - val_loss: 1.2615\n",
      "Epoch 1078/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1543 - val_loss: 1.2649\n",
      "Epoch 1079/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1441 - val_loss: 1.2894\n",
      "Epoch 1080/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1558 - val_loss: 1.2388\n",
      "Epoch 1081/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1572 - val_loss: 1.1959\n",
      "Epoch 1082/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1333 - val_loss: 1.1998\n",
      "Epoch 1083/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1326 - val_loss: 1.1389\n",
      "Epoch 1084/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1431 - val_loss: 1.2674\n",
      "Epoch 1085/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1499 - val_loss: 1.1674\n",
      "Epoch 1086/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1552 - val_loss: 1.1732\n",
      "Epoch 1087/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1137 - val_loss: 1.2205\n",
      "Epoch 1088/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1478 - val_loss: 1.3141\n",
      "Epoch 1089/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1511 - val_loss: 1.2139\n",
      "Epoch 1090/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1555 - val_loss: 1.2300\n",
      "Epoch 1091/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1401 - val_loss: 1.3233\n",
      "Epoch 1092/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1675 - val_loss: 1.2502\n",
      "Epoch 1093/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1700 - val_loss: 1.2026\n",
      "Epoch 1094/20000\n",
      "1500/1500 [==============================] - 0s 36us/sample - loss: 1.1882 - val_loss: 1.1796\n",
      "Epoch 1095/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1960 - val_loss: 1.1739\n",
      "Epoch 1096/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1392 - val_loss: 1.2079\n",
      "Epoch 1097/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1903 - val_loss: 1.4630\n",
      "Epoch 1098/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1235 - val_loss: 1.2951\n",
      "Epoch 1099/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1433 - val_loss: 1.2127\n",
      "Epoch 1100/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1402 - val_loss: 1.1989\n",
      "Epoch 1101/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1843 - val_loss: 1.3936\n",
      "Epoch 1102/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1489 - val_loss: 1.2087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1103/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1315 - val_loss: 1.1465\n",
      "Epoch 1104/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1120 - val_loss: 1.2526\n",
      "Epoch 1105/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1404 - val_loss: 1.2717\n",
      "Epoch 1106/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1866 - val_loss: 1.2289\n",
      "Epoch 1107/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1547 - val_loss: 1.1714\n",
      "Epoch 1108/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1450 - val_loss: 1.1831\n",
      "Epoch 1109/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1553 - val_loss: 1.2506\n",
      "Epoch 1110/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1420 - val_loss: 1.2777\n",
      "Epoch 1111/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1248 - val_loss: 1.1549\n",
      "Epoch 1112/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1220 - val_loss: 1.1840\n",
      "Epoch 1113/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1614 - val_loss: 1.1993\n",
      "Epoch 1114/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1295 - val_loss: 1.1625\n",
      "Epoch 1115/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1630 - val_loss: 1.2913\n",
      "Epoch 1116/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1769 - val_loss: 1.2408\n",
      "Epoch 1117/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.1325 - val_loss: 1.2188\n",
      "Epoch 1118/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1603 - val_loss: 1.2298\n",
      "Epoch 1119/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1375 - val_loss: 1.2071\n",
      "Epoch 1120/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1696 - val_loss: 1.1578\n",
      "Epoch 1121/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1311 - val_loss: 1.1448\n",
      "Epoch 1122/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1555 - val_loss: 1.2245\n",
      "Epoch 1123/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1719 - val_loss: 1.2515\n",
      "Epoch 1124/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1354 - val_loss: 1.1939\n",
      "Epoch 1125/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1580 - val_loss: 1.2140\n",
      "Epoch 1126/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1333 - val_loss: 1.3037\n",
      "Epoch 1127/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1598 - val_loss: 1.2879\n",
      "Epoch 1128/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1363 - val_loss: 1.2826\n",
      "Epoch 1129/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1467 - val_loss: 1.1498\n",
      "Epoch 1130/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1871 - val_loss: 1.3815\n",
      "Epoch 1131/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1834 - val_loss: 1.5690\n",
      "Epoch 1132/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2243 - val_loss: 1.1992\n",
      "Epoch 1133/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1829 - val_loss: 1.3285\n",
      "Epoch 1134/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2092 - val_loss: 1.1699\n",
      "Epoch 1135/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1699 - val_loss: 1.4796\n",
      "Epoch 1136/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1966 - val_loss: 1.2154\n",
      "Epoch 1137/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1400 - val_loss: 1.1933\n",
      "Epoch 1138/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1339 - val_loss: 1.1569\n",
      "Epoch 1139/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1638 - val_loss: 1.1889\n",
      "Epoch 1140/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1419 - val_loss: 1.3382\n",
      "Epoch 1141/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.1480 - val_loss: 1.1679\n",
      "Epoch 1142/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1608 - val_loss: 1.2003\n",
      "Epoch 1143/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1516 - val_loss: 1.2049\n",
      "Epoch 1144/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1997 - val_loss: 1.3031\n",
      "Epoch 1145/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1454 - val_loss: 1.2449\n",
      "Epoch 1146/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1580 - val_loss: 1.1854\n",
      "Epoch 1147/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1460 - val_loss: 1.1724\n",
      "Epoch 1148/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1314 - val_loss: 1.1851\n",
      "Epoch 1149/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1379 - val_loss: 1.1725\n",
      "Epoch 1150/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1724 - val_loss: 1.1697\n",
      "Epoch 1151/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1968 - val_loss: 1.2412\n",
      "Epoch 1152/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1718 - val_loss: 1.3232\n",
      "Epoch 1153/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1425 - val_loss: 1.2456\n",
      "Epoch 1154/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1437 - val_loss: 1.4791\n",
      "Epoch 1155/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1863 - val_loss: 1.1940\n",
      "Epoch 1156/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1368 - val_loss: 1.1751\n",
      "Epoch 1157/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1517 - val_loss: 1.2589\n",
      "Epoch 1158/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1746 - val_loss: 1.1674\n",
      "Epoch 1159/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1349 - val_loss: 1.2571\n",
      "Epoch 1160/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1332 - val_loss: 1.2165\n",
      "Epoch 1161/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1403 - val_loss: 1.1999\n",
      "Epoch 1162/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1708 - val_loss: 1.4231\n",
      "Epoch 1163/20000\n",
      "1500/1500 [==============================] - 0s 35us/sample - loss: 1.1640 - val_loss: 1.3208\n",
      "Epoch 1164/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1367 - val_loss: 1.2953\n",
      "Epoch 1165/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1106 - val_loss: 1.2620\n",
      "Epoch 1166/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1782 - val_loss: 1.2471\n",
      "Epoch 1167/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1450 - val_loss: 1.2810\n",
      "Epoch 1168/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1431 - val_loss: 1.1321\n",
      "Epoch 1169/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1409 - val_loss: 1.3334\n",
      "Epoch 1170/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1953 - val_loss: 1.1993\n",
      "Epoch 1171/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1686 - val_loss: 1.1651\n",
      "Epoch 1172/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.1281 - val_loss: 1.2810\n",
      "Epoch 1173/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1490 - val_loss: 1.2169\n",
      "Epoch 1174/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1413 - val_loss: 1.1661\n",
      "Epoch 1175/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1402 - val_loss: 1.2693\n",
      "Epoch 1176/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.2540 - val_loss: 1.4736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1177/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2155 - val_loss: 1.2091\n",
      "Epoch 1178/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1622 - val_loss: 1.2310\n",
      "Epoch 1179/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1578 - val_loss: 1.3010\n",
      "Epoch 1180/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1515 - val_loss: 1.2954\n",
      "Epoch 1181/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1430 - val_loss: 1.3102\n",
      "Epoch 1182/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1150 - val_loss: 1.1771\n",
      "Epoch 1183/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.2035 - val_loss: 1.3027\n",
      "Epoch 1184/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1584 - val_loss: 1.2411\n",
      "Epoch 1185/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1353 - val_loss: 1.1354\n",
      "Epoch 1186/20000\n",
      "1500/1500 [==============================] - 0s 33us/sample - loss: 1.1283 - val_loss: 1.3035\n",
      "Epoch 1187/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1956 - val_loss: 1.1451\n",
      "Epoch 1188/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1630 - val_loss: 1.2560\n",
      "Epoch 1189/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2330 - val_loss: 1.1959\n",
      "Epoch 1190/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1636 - val_loss: 1.1878\n",
      "Epoch 1191/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1341 - val_loss: 1.1780\n",
      "Epoch 1192/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1107 - val_loss: 1.2417\n",
      "Epoch 1193/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1300 - val_loss: 1.2445\n",
      "Epoch 1194/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1687 - val_loss: 1.1811\n",
      "Epoch 1195/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1305 - val_loss: 1.1980\n",
      "Epoch 1196/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1365 - val_loss: 1.3065\n",
      "Epoch 1197/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1404 - val_loss: 1.1679\n",
      "Epoch 1198/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1515 - val_loss: 1.2110\n",
      "Epoch 1199/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1552 - val_loss: 1.2125\n",
      "Epoch 1200/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1203 - val_loss: 1.1880\n",
      "Epoch 1201/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1192 - val_loss: 1.1716\n",
      "Epoch 1202/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1440 - val_loss: 1.2410\n",
      "Epoch 1203/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1577 - val_loss: 1.2495\n",
      "Epoch 1204/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1642 - val_loss: 1.1580\n",
      "Epoch 1205/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1846 - val_loss: 1.4003\n",
      "Epoch 1206/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1617 - val_loss: 1.2613\n",
      "Epoch 1207/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1575 - val_loss: 1.1304\n",
      "Epoch 1208/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1335 - val_loss: 1.1738\n",
      "Epoch 1209/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1942 - val_loss: 1.4379\n",
      "Epoch 1210/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2188 - val_loss: 1.1627\n",
      "Epoch 1211/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1965 - val_loss: 1.3185\n",
      "Epoch 1212/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1380 - val_loss: 1.1745\n",
      "Epoch 1213/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1620 - val_loss: 1.3872\n",
      "Epoch 1214/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2018 - val_loss: 1.1908\n",
      "Epoch 1215/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1563 - val_loss: 1.2299\n",
      "Epoch 1216/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1435 - val_loss: 1.2146\n",
      "Epoch 1217/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1366 - val_loss: 1.1913\n",
      "Epoch 1218/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2118 - val_loss: 1.3222\n",
      "Epoch 1219/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1567 - val_loss: 1.1533\n",
      "Epoch 1220/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1519 - val_loss: 1.3412\n",
      "Epoch 1221/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1270 - val_loss: 1.1880\n",
      "Epoch 1222/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1496 - val_loss: 1.2826\n",
      "Epoch 1223/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1656 - val_loss: 1.2057\n",
      "Epoch 1224/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1345 - val_loss: 1.2057\n",
      "Epoch 1225/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1536 - val_loss: 1.1821\n",
      "Epoch 1226/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1628 - val_loss: 1.2347\n",
      "Epoch 1227/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1550 - val_loss: 1.2510\n",
      "Epoch 1228/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1407 - val_loss: 1.2909\n",
      "Epoch 1229/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1475 - val_loss: 1.1780\n",
      "Epoch 1230/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1386 - val_loss: 1.1817\n",
      "Epoch 1231/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1738 - val_loss: 1.2450\n",
      "Epoch 1232/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1942 - val_loss: 1.2188\n",
      "Epoch 1233/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1698 - val_loss: 1.1792\n",
      "Epoch 1234/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1545 - val_loss: 1.1866\n",
      "Epoch 1235/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1355 - val_loss: 1.2775\n",
      "Epoch 1236/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1613 - val_loss: 1.1954\n",
      "Epoch 1237/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1557 - val_loss: 1.2980\n",
      "Epoch 1238/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1313 - val_loss: 1.2114\n",
      "Epoch 1239/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1410 - val_loss: 1.3743\n",
      "Epoch 1240/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1461 - val_loss: 1.2241\n",
      "Epoch 1241/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1538 - val_loss: 1.5784\n",
      "Epoch 1242/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1884 - val_loss: 1.1707\n",
      "Epoch 1243/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1515 - val_loss: 1.2852\n",
      "Epoch 1244/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1567 - val_loss: 1.2384\n",
      "Epoch 1245/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1276 - val_loss: 1.1982\n",
      "Epoch 1246/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1573 - val_loss: 1.3236\n",
      "Epoch 1247/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1394 - val_loss: 1.1426\n",
      "Epoch 1248/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1304 - val_loss: 1.1373\n",
      "Epoch 1249/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1519 - val_loss: 1.1921\n",
      "Epoch 1250/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1699 - val_loss: 1.1229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1251/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1227 - val_loss: 1.1785\n",
      "Epoch 1252/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1358 - val_loss: 1.2146\n",
      "Epoch 1253/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1432 - val_loss: 1.1893\n",
      "Epoch 1254/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1763 - val_loss: 1.3321\n",
      "Epoch 1255/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1486 - val_loss: 1.2490\n",
      "Epoch 1256/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1738 - val_loss: 1.2074\n",
      "Epoch 1257/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1865 - val_loss: 1.1596\n",
      "Epoch 1258/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1576 - val_loss: 1.1203\n",
      "Epoch 1259/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1629 - val_loss: 1.3298\n",
      "Epoch 1260/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1514 - val_loss: 1.1726\n",
      "Epoch 1261/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1359 - val_loss: 1.2288\n",
      "Epoch 1262/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1497 - val_loss: 1.1768\n",
      "Epoch 1263/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1364 - val_loss: 1.1913\n",
      "Epoch 1264/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1432 - val_loss: 1.1500\n",
      "Epoch 1265/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1637 - val_loss: 1.2866\n",
      "Epoch 1266/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1329 - val_loss: 1.1625\n",
      "Epoch 1267/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1369 - val_loss: 1.3841\n",
      "Epoch 1268/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1698 - val_loss: 1.1539\n",
      "Epoch 1269/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1910 - val_loss: 1.2244\n",
      "Epoch 1270/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1243 - val_loss: 1.1882\n",
      "Epoch 1271/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1440 - val_loss: 1.2075\n",
      "Epoch 1272/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1183 - val_loss: 1.1630\n",
      "Epoch 1273/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1347 - val_loss: 1.1674\n",
      "Epoch 1274/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1442 - val_loss: 1.1740\n",
      "Epoch 1275/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1352 - val_loss: 1.2346\n",
      "Epoch 1276/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1314 - val_loss: 1.2274\n",
      "Epoch 1277/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1586 - val_loss: 1.3067\n",
      "Epoch 1278/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2675 - val_loss: 1.5556\n",
      "Epoch 1279/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1686 - val_loss: 1.3243\n",
      "Epoch 1280/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1485 - val_loss: 1.2336\n",
      "Epoch 1281/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1804 - val_loss: 1.2708\n",
      "Epoch 1282/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1367 - val_loss: 1.1815\n",
      "Epoch 1283/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1236 - val_loss: 1.2116\n",
      "Epoch 1284/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1471 - val_loss: 1.3746\n",
      "Epoch 1285/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1534 - val_loss: 1.2040\n",
      "Epoch 1286/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1116 - val_loss: 1.1899\n",
      "Epoch 1287/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1518 - val_loss: 1.3380\n",
      "Epoch 1288/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1776 - val_loss: 1.3139\n",
      "Epoch 1289/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1980 - val_loss: 1.2396\n",
      "Epoch 1290/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1917 - val_loss: 1.2954\n",
      "Epoch 1291/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1634 - val_loss: 1.2365\n",
      "Epoch 1292/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1573 - val_loss: 1.2082\n",
      "Epoch 1293/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1540 - val_loss: 1.4529\n",
      "Epoch 1294/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1797 - val_loss: 1.4245\n",
      "Epoch 1295/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1443 - val_loss: 1.3885\n",
      "Epoch 1296/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1455 - val_loss: 1.2028\n",
      "Epoch 1297/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1444 - val_loss: 1.1772\n",
      "Epoch 1298/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1455 - val_loss: 1.3080\n",
      "Epoch 1299/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1534 - val_loss: 1.2005\n",
      "Epoch 1300/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1638 - val_loss: 1.2603\n",
      "Epoch 1301/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1494 - val_loss: 1.1494\n",
      "Epoch 1302/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1457 - val_loss: 1.2950\n",
      "Epoch 1303/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1271 - val_loss: 1.2052\n",
      "Epoch 1304/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1326 - val_loss: 1.4623\n",
      "Epoch 1305/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1959 - val_loss: 1.2914\n",
      "Epoch 1306/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1501 - val_loss: 1.3953\n",
      "Epoch 1307/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2079 - val_loss: 1.1854\n",
      "Epoch 1308/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1591 - val_loss: 1.1725\n",
      "Epoch 1309/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1315 - val_loss: 1.1516\n",
      "Epoch 1310/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1296 - val_loss: 1.1771\n",
      "Epoch 1311/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1387 - val_loss: 1.1536\n",
      "Epoch 1312/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1229 - val_loss: 1.1667\n",
      "Epoch 1313/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1470 - val_loss: 1.2165\n",
      "Epoch 1314/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1985 - val_loss: 1.1673\n",
      "Epoch 1315/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1458 - val_loss: 1.2705\n",
      "Epoch 1316/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1445 - val_loss: 1.2792\n",
      "Epoch 1317/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1406 - val_loss: 1.2985\n",
      "Epoch 1318/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1715 - val_loss: 1.2048\n",
      "Epoch 1319/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1815 - val_loss: 1.2836\n",
      "Epoch 1320/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1327 - val_loss: 1.2105\n",
      "Epoch 1321/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1428 - val_loss: 1.2437\n",
      "Epoch 1322/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1719 - val_loss: 1.5689\n",
      "Epoch 1323/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1586 - val_loss: 1.3358\n",
      "Epoch 1324/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.3318 - val_loss: 1.1557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1325/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1903 - val_loss: 1.4026\n",
      "Epoch 1326/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2155 - val_loss: 1.1984\n",
      "Epoch 1327/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2001 - val_loss: 1.1621\n",
      "Epoch 1328/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1653 - val_loss: 1.2428\n",
      "Epoch 1329/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1233 - val_loss: 1.3408\n",
      "Epoch 1330/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1883 - val_loss: 1.3944\n",
      "Epoch 1331/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1700 - val_loss: 1.1837\n",
      "Epoch 1332/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1960 - val_loss: 1.4411\n",
      "Epoch 1333/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1651 - val_loss: 1.3391\n",
      "Epoch 1334/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1469 - val_loss: 1.2649\n",
      "Epoch 1335/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1581 - val_loss: 1.1678\n",
      "Epoch 1336/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1641 - val_loss: 1.4461\n",
      "Epoch 1337/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1359 - val_loss: 1.1826\n",
      "Epoch 1338/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2121 - val_loss: 1.1692\n",
      "Epoch 1339/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1845 - val_loss: 1.2269\n",
      "Epoch 1340/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1417 - val_loss: 1.2721\n",
      "Epoch 1341/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1285 - val_loss: 1.1596\n",
      "Epoch 1342/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1416 - val_loss: 1.1535\n",
      "Epoch 1343/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1694 - val_loss: 1.3980\n",
      "Epoch 1344/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1929 - val_loss: 1.1740\n",
      "Epoch 1345/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1520 - val_loss: 1.2887\n",
      "Epoch 1346/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1895 - val_loss: 1.2112\n",
      "Epoch 1347/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1594 - val_loss: 1.1629\n",
      "Epoch 1348/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1294 - val_loss: 1.2227\n",
      "Epoch 1349/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1327 - val_loss: 1.2069\n",
      "Epoch 1350/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1930 - val_loss: 1.2380\n",
      "Epoch 1351/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1344 - val_loss: 1.1917\n",
      "Epoch 1352/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1767 - val_loss: 1.2527\n",
      "Epoch 1353/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1392 - val_loss: 1.2589\n",
      "Epoch 1354/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1278 - val_loss: 1.1577\n",
      "Epoch 1355/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2170 - val_loss: 1.1723\n",
      "Epoch 1356/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1609 - val_loss: 1.1530\n",
      "Epoch 1357/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2131 - val_loss: 1.3316\n",
      "Epoch 1358/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1682 - val_loss: 1.3019\n",
      "Epoch 1359/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1771 - val_loss: 1.2618\n",
      "Epoch 1360/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1549 - val_loss: 1.2280\n",
      "Epoch 1361/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1585 - val_loss: 1.2632\n",
      "Epoch 1362/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1458 - val_loss: 1.1316\n",
      "Epoch 1363/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1549 - val_loss: 1.1905\n",
      "Epoch 1364/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1859 - val_loss: 1.2417\n",
      "Epoch 1365/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2375 - val_loss: 1.4070\n",
      "Epoch 1366/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1961 - val_loss: 1.2125\n",
      "Epoch 1367/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1446 - val_loss: 1.2185\n",
      "Epoch 1368/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1660 - val_loss: 1.5307\n",
      "Epoch 1369/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1933 - val_loss: 1.1981\n",
      "Epoch 1370/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1326 - val_loss: 1.1751\n",
      "Epoch 1371/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1226 - val_loss: 1.1677\n",
      "Epoch 1372/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1353 - val_loss: 1.2972\n",
      "Epoch 1373/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1831 - val_loss: 1.2202\n",
      "Epoch 1374/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1497 - val_loss: 1.2761\n",
      "Epoch 1375/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1337 - val_loss: 1.2778\n",
      "Epoch 1376/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2241 - val_loss: 1.1353\n",
      "Epoch 1377/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1438 - val_loss: 1.2490\n",
      "Epoch 1378/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1477 - val_loss: 1.2386\n",
      "Epoch 1379/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1294 - val_loss: 1.2933\n",
      "Epoch 1380/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1557 - val_loss: 1.2779\n",
      "Epoch 1381/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1329 - val_loss: 1.2161\n",
      "Epoch 1382/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1659 - val_loss: 1.1894\n",
      "Epoch 1383/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2035 - val_loss: 1.1529\n",
      "Epoch 1384/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1647 - val_loss: 1.1814\n",
      "Epoch 1385/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1211 - val_loss: 1.1228\n",
      "Epoch 1386/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1406 - val_loss: 1.1981\n",
      "Epoch 1387/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1663 - val_loss: 1.2134\n",
      "Epoch 1388/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1898 - val_loss: 1.2748\n",
      "Epoch 1389/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1496 - val_loss: 1.2136\n",
      "Epoch 1390/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1278 - val_loss: 1.1644\n",
      "Epoch 1391/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1279 - val_loss: 1.1662\n",
      "Epoch 1392/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1202 - val_loss: 1.2604\n",
      "Epoch 1393/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1465 - val_loss: 1.1694\n",
      "Epoch 1394/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1627 - val_loss: 1.1657\n",
      "Epoch 1395/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1344 - val_loss: 1.2297\n",
      "Epoch 1396/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1268 - val_loss: 1.2237\n",
      "Epoch 1397/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1266 - val_loss: 1.1648\n",
      "Epoch 1398/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1496 - val_loss: 1.1517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1399/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1365 - val_loss: 1.1627\n",
      "Epoch 1400/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1376 - val_loss: 1.2088\n",
      "Epoch 1401/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1530 - val_loss: 1.1939\n",
      "Epoch 1402/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2570 - val_loss: 1.4555\n",
      "Epoch 1403/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1508 - val_loss: 1.2090\n",
      "Epoch 1404/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1217 - val_loss: 1.1606\n",
      "Epoch 1405/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1462 - val_loss: 1.5183\n",
      "Epoch 1406/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1391 - val_loss: 1.1903\n",
      "Epoch 1407/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1879 - val_loss: 1.1570\n",
      "Epoch 1408/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1634 - val_loss: 1.2522\n",
      "Epoch 1409/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1370 - val_loss: 1.2426\n",
      "Epoch 1410/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1685 - val_loss: 1.1443\n",
      "Epoch 1411/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1275 - val_loss: 1.2113\n",
      "Epoch 1412/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1823 - val_loss: 1.4697\n",
      "Epoch 1413/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1395 - val_loss: 1.1725\n",
      "Epoch 1414/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1726 - val_loss: 1.1633\n",
      "Epoch 1415/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2283 - val_loss: 1.5990\n",
      "Epoch 1416/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1606 - val_loss: 1.2058\n",
      "Epoch 1417/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1679 - val_loss: 1.3653\n",
      "Epoch 1418/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1835 - val_loss: 1.2267\n",
      "Epoch 1419/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1225 - val_loss: 1.2858\n",
      "Epoch 1420/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1403 - val_loss: 1.1899\n",
      "Epoch 1421/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1612 - val_loss: 1.1591\n",
      "Epoch 1422/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1350 - val_loss: 1.2141\n",
      "Epoch 1423/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1745 - val_loss: 1.2017\n",
      "Epoch 1424/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1669 - val_loss: 1.2164\n",
      "Epoch 1425/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1526 - val_loss: 1.2397\n",
      "Epoch 1426/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1410 - val_loss: 1.1926\n",
      "Epoch 1427/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1303 - val_loss: 1.2356\n",
      "Epoch 1428/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1251 - val_loss: 1.1766\n",
      "Epoch 1429/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1316 - val_loss: 1.5766\n",
      "Epoch 1430/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2237 - val_loss: 1.1801\n",
      "Epoch 1431/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1569 - val_loss: 1.2001\n",
      "Epoch 1432/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1682 - val_loss: 1.1210\n",
      "Epoch 1433/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1604 - val_loss: 1.2950\n",
      "Epoch 1434/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2694 - val_loss: 1.1899\n",
      "Epoch 1435/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1338 - val_loss: 1.1787\n",
      "Epoch 1436/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1554 - val_loss: 1.2135\n",
      "Epoch 1437/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2910 - val_loss: 1.2856\n",
      "Epoch 1438/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2050 - val_loss: 1.1419\n",
      "Epoch 1439/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1208 - val_loss: 1.2016\n",
      "Epoch 1440/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1255 - val_loss: 1.1758\n",
      "Epoch 1441/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1963 - val_loss: 1.2235\n",
      "Epoch 1442/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1599 - val_loss: 1.2141\n",
      "Epoch 1443/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1433 - val_loss: 1.1929\n",
      "Epoch 1444/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1551 - val_loss: 1.2454\n",
      "Epoch 1445/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1673 - val_loss: 1.2241\n",
      "Epoch 1446/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2079 - val_loss: 1.1505\n",
      "Epoch 1447/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2013 - val_loss: 1.5079\n",
      "Epoch 1448/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2584 - val_loss: 1.1855\n",
      "Epoch 1449/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1902 - val_loss: 1.1939\n",
      "Epoch 1450/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1645 - val_loss: 1.4957\n",
      "Epoch 1451/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2695 - val_loss: 1.2128\n",
      "Epoch 1452/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1472 - val_loss: 1.1500\n",
      "Epoch 1453/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1427 - val_loss: 1.2623\n",
      "Epoch 1454/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1785 - val_loss: 1.1906\n",
      "Epoch 1455/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1344 - val_loss: 1.2726\n",
      "Epoch 1456/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1570 - val_loss: 1.1649\n",
      "Epoch 1457/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1651 - val_loss: 1.2199\n",
      "Epoch 1458/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1449 - val_loss: 1.2055\n",
      "Epoch 1459/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1678 - val_loss: 1.1942\n",
      "Epoch 1460/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1543 - val_loss: 1.3859\n",
      "Epoch 1461/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1421 - val_loss: 1.1766\n",
      "Epoch 1462/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1634 - val_loss: 1.4512\n",
      "Epoch 1463/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2000 - val_loss: 1.2103\n",
      "Epoch 1464/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1530 - val_loss: 1.1498\n",
      "Epoch 1465/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1413 - val_loss: 1.2531\n",
      "Epoch 1466/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1500 - val_loss: 1.1905\n",
      "Epoch 1467/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1162 - val_loss: 1.2183\n",
      "Epoch 1468/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1267 - val_loss: 1.3750\n",
      "Epoch 1469/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1970 - val_loss: 1.1651\n",
      "Epoch 1470/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1715 - val_loss: 1.1803\n",
      "Epoch 1471/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1722 - val_loss: 1.2055\n",
      "Epoch 1472/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1598 - val_loss: 1.2369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1473/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1363 - val_loss: 1.2094\n",
      "Epoch 1474/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1380 - val_loss: 1.2273\n",
      "Epoch 1475/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1496 - val_loss: 1.2301\n",
      "Epoch 1476/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1631 - val_loss: 1.2379\n",
      "Epoch 1477/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1721 - val_loss: 1.1576\n",
      "Epoch 1478/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2159 - val_loss: 1.2586\n",
      "Epoch 1479/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1673 - val_loss: 1.1867\n",
      "Epoch 1480/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1497 - val_loss: 1.3145\n",
      "Epoch 1481/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1881 - val_loss: 1.2742\n",
      "Epoch 1482/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1596 - val_loss: 1.1724\n",
      "Epoch 1483/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1976 - val_loss: 1.1858\n",
      "Epoch 1484/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2266 - val_loss: 1.3187\n",
      "Epoch 1485/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1493 - val_loss: 1.1365\n",
      "Epoch 1486/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1386 - val_loss: 1.2896\n",
      "Epoch 1487/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1304 - val_loss: 1.2201\n",
      "Epoch 1488/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1276 - val_loss: 1.3239\n",
      "Epoch 1489/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1438 - val_loss: 1.2366\n",
      "Epoch 1490/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2039 - val_loss: 1.1544\n",
      "Epoch 1491/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1454 - val_loss: 1.2101\n",
      "Epoch 1492/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1600 - val_loss: 1.2787\n",
      "Epoch 1493/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1534 - val_loss: 1.4134\n",
      "Epoch 1494/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1550 - val_loss: 1.2304\n",
      "Epoch 1495/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1266 - val_loss: 1.3576\n",
      "Epoch 1496/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1636 - val_loss: 1.1987\n",
      "Epoch 1497/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2335 - val_loss: 1.1927\n",
      "Epoch 1498/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1606 - val_loss: 1.2335\n",
      "Epoch 1499/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1755 - val_loss: 1.3463\n",
      "Epoch 1500/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1684 - val_loss: 1.1668\n",
      "Epoch 1501/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1327 - val_loss: 1.2467\n",
      "Epoch 1502/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1559 - val_loss: 1.1542\n",
      "Epoch 1503/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1677 - val_loss: 1.2023\n",
      "Epoch 1504/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1426 - val_loss: 1.1888\n",
      "Epoch 1505/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1366 - val_loss: 1.1726\n",
      "Epoch 1506/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1667 - val_loss: 1.1986\n",
      "Epoch 1507/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1376 - val_loss: 1.4006\n",
      "Epoch 1508/20000\n",
      "1500/1500 [==============================] - 0s 20us/sample - loss: 1.1638 - val_loss: 1.2249\n",
      "Epoch 1509/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1467 - val_loss: 1.1921\n",
      "Epoch 1510/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1374 - val_loss: 1.2048\n",
      "Epoch 1511/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1473 - val_loss: 1.1597\n",
      "Epoch 1512/20000\n",
      "1500/1500 [==============================] - 0s 20us/sample - loss: 1.1534 - val_loss: 1.2890\n",
      "Epoch 1513/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1249 - val_loss: 1.1555\n",
      "Epoch 1514/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1384 - val_loss: 1.3071\n",
      "Epoch 1515/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1676 - val_loss: 1.2504\n",
      "Epoch 1516/20000\n",
      "1500/1500 [==============================] - 0s 20us/sample - loss: 1.1244 - val_loss: 1.1739\n",
      "Epoch 1517/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1418 - val_loss: 1.1299\n",
      "Epoch 1518/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1529 - val_loss: 1.2916\n",
      "Epoch 1519/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1169 - val_loss: 1.2102\n",
      "Epoch 1520/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1599 - val_loss: 1.1700\n",
      "Epoch 1521/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1820 - val_loss: 1.2426\n",
      "Epoch 1522/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1445 - val_loss: 1.1748\n",
      "Epoch 1523/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1506 - val_loss: 1.1325\n",
      "Epoch 1524/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1445 - val_loss: 1.1640\n",
      "Epoch 1525/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1179 - val_loss: 1.1740\n",
      "Epoch 1526/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1513 - val_loss: 1.2031\n",
      "Epoch 1527/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1460 - val_loss: 1.1766\n",
      "Epoch 1528/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1197 - val_loss: 1.1844\n",
      "Epoch 1529/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1679 - val_loss: 1.2126\n",
      "Epoch 1530/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1418 - val_loss: 1.2133\n",
      "Epoch 1531/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1745 - val_loss: 1.2969\n",
      "Epoch 1532/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1506 - val_loss: 1.2504\n",
      "Epoch 1533/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1650 - val_loss: 1.2864\n",
      "Epoch 1534/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2371 - val_loss: 1.3823\n",
      "Epoch 1535/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1465 - val_loss: 1.2125\n",
      "Epoch 1536/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1176 - val_loss: 1.1841\n",
      "Epoch 1537/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1303 - val_loss: 1.1626\n",
      "Epoch 1538/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1407 - val_loss: 1.2435\n",
      "Epoch 1539/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1343 - val_loss: 1.2555\n",
      "Epoch 1540/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1431 - val_loss: 1.2757\n",
      "Epoch 1541/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1277 - val_loss: 1.2110\n",
      "Epoch 1542/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1270 - val_loss: 1.3115\n",
      "Epoch 1543/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1468 - val_loss: 1.5066\n",
      "Epoch 1544/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1708 - val_loss: 1.1918\n",
      "Epoch 1545/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1403 - val_loss: 1.2589\n",
      "Epoch 1546/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1232 - val_loss: 1.2644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1547/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1403 - val_loss: 1.2138\n",
      "Epoch 1548/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1605 - val_loss: 1.3122\n",
      "Epoch 1549/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1458 - val_loss: 1.1945\n",
      "Epoch 1550/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1898 - val_loss: 1.2183\n",
      "Epoch 1551/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1848 - val_loss: 1.4242\n",
      "Epoch 1552/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1663 - val_loss: 1.1709\n",
      "Epoch 1553/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2496 - val_loss: 1.1964\n",
      "Epoch 1554/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1471 - val_loss: 1.2645\n",
      "Epoch 1555/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1703 - val_loss: 1.2469\n",
      "Epoch 1556/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1517 - val_loss: 1.4134\n",
      "Epoch 1557/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2143 - val_loss: 1.1740\n",
      "Epoch 1558/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1480 - val_loss: 1.2550\n",
      "Epoch 1559/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1837 - val_loss: 1.2038\n",
      "Epoch 1560/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1392 - val_loss: 1.1330\n",
      "Epoch 1561/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1270 - val_loss: 1.2029\n",
      "Epoch 1562/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1445 - val_loss: 1.1820\n",
      "Epoch 1563/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1681 - val_loss: 1.2102\n",
      "Epoch 1564/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1669 - val_loss: 1.1699\n",
      "Epoch 1565/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1555 - val_loss: 1.3022\n",
      "Epoch 1566/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1699 - val_loss: 1.2020\n",
      "Epoch 1567/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1299 - val_loss: 1.2239\n",
      "Epoch 1568/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1473 - val_loss: 1.1698\n",
      "Epoch 1569/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1396 - val_loss: 1.2046\n",
      "Epoch 1570/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1559 - val_loss: 1.2313\n",
      "Epoch 1571/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1647 - val_loss: 1.2183\n",
      "Epoch 1572/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1755 - val_loss: 1.1566\n",
      "Epoch 1573/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1678 - val_loss: 1.1837\n",
      "Epoch 1574/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1555 - val_loss: 1.3179\n",
      "Epoch 1575/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1858 - val_loss: 1.2947\n",
      "Epoch 1576/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1778 - val_loss: 1.2311\n",
      "Epoch 1577/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1584 - val_loss: 1.1525\n",
      "Epoch 1578/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1484 - val_loss: 1.1619\n",
      "Epoch 1579/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1596 - val_loss: 1.1382\n",
      "Epoch 1580/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1261 - val_loss: 1.1676\n",
      "Epoch 1581/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1491 - val_loss: 1.1935\n",
      "Epoch 1582/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1424 - val_loss: 1.1325\n",
      "Epoch 1583/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2194 - val_loss: 1.2764\n",
      "Epoch 1584/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1473 - val_loss: 1.1633\n",
      "Epoch 1585/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1373 - val_loss: 1.2101\n",
      "Epoch 1586/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1489 - val_loss: 1.2874\n",
      "Epoch 1587/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1623 - val_loss: 1.2768\n",
      "Epoch 1588/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1558 - val_loss: 1.1748\n",
      "Epoch 1589/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1440 - val_loss: 1.1719\n",
      "Epoch 1590/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1314 - val_loss: 1.2765\n",
      "Epoch 1591/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1384 - val_loss: 1.1806\n",
      "Epoch 1592/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1172 - val_loss: 1.1877\n",
      "Epoch 1593/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1284 - val_loss: 1.2660\n",
      "Epoch 1594/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1281 - val_loss: 1.1455\n",
      "Epoch 1595/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1878 - val_loss: 1.3593\n",
      "Epoch 1596/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1406 - val_loss: 1.2469\n",
      "Epoch 1597/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1495 - val_loss: 1.1878\n",
      "Epoch 1598/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1847 - val_loss: 1.2361\n",
      "Epoch 1599/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1446 - val_loss: 1.1979\n",
      "Epoch 1600/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1972 - val_loss: 1.4075\n",
      "Epoch 1601/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1590 - val_loss: 1.1841\n",
      "Epoch 1602/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1843 - val_loss: 1.1076\n",
      "Epoch 1603/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1705 - val_loss: 1.4661\n",
      "Epoch 1604/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1706 - val_loss: 1.1657\n",
      "Epoch 1605/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1690 - val_loss: 1.3059\n",
      "Epoch 1606/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1727 - val_loss: 1.1836\n",
      "Epoch 1607/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1672 - val_loss: 1.2059\n",
      "Epoch 1608/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1460 - val_loss: 1.4415\n",
      "Epoch 1609/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1800 - val_loss: 1.2331\n",
      "Epoch 1610/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1376 - val_loss: 1.1419\n",
      "Epoch 1611/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1336 - val_loss: 1.1503\n",
      "Epoch 1612/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1316 - val_loss: 1.2600\n",
      "Epoch 1613/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1097 - val_loss: 1.1972\n",
      "Epoch 1614/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1098 - val_loss: 1.2525\n",
      "Epoch 1615/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1654 - val_loss: 1.1712\n",
      "Epoch 1616/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1750 - val_loss: 1.2797\n",
      "Epoch 1617/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2358 - val_loss: 1.2419\n",
      "Epoch 1618/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1670 - val_loss: 1.1446\n",
      "Epoch 1619/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1333 - val_loss: 1.1697\n",
      "Epoch 1620/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1137 - val_loss: 1.1899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1621/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1437 - val_loss: 1.2560\n",
      "Epoch 1622/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1365 - val_loss: 1.1712\n",
      "Epoch 1623/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1578 - val_loss: 1.2307\n",
      "Epoch 1624/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1414 - val_loss: 1.3204\n",
      "Epoch 1625/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1471 - val_loss: 1.2549\n",
      "Epoch 1626/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.2060 - val_loss: 1.2020\n",
      "Epoch 1627/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1878 - val_loss: 1.3043\n",
      "Epoch 1628/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1739 - val_loss: 1.2277\n",
      "Epoch 1629/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1297 - val_loss: 1.1859\n",
      "Epoch 1630/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1504 - val_loss: 1.3969\n",
      "Epoch 1631/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1698 - val_loss: 1.3387\n",
      "Epoch 1632/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1632 - val_loss: 1.3175\n",
      "Epoch 1633/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1963 - val_loss: 1.2413\n",
      "Epoch 1634/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1136 - val_loss: 1.2673\n",
      "Epoch 1635/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2150 - val_loss: 1.2430\n",
      "Epoch 1636/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1469 - val_loss: 1.1443\n",
      "Epoch 1637/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1963 - val_loss: 1.1911\n",
      "Epoch 1638/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1584 - val_loss: 1.2734\n",
      "Epoch 1639/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1626 - val_loss: 1.2784\n",
      "Epoch 1640/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2370 - val_loss: 1.2257\n",
      "Epoch 1641/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1276 - val_loss: 1.2816\n",
      "Epoch 1642/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1596 - val_loss: 1.2394\n",
      "Epoch 1643/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1409 - val_loss: 1.2329\n",
      "Epoch 1644/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1371 - val_loss: 1.2340\n",
      "Epoch 1645/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1468 - val_loss: 1.1787\n",
      "Epoch 1646/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1444 - val_loss: 1.2273\n",
      "Epoch 1647/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1400 - val_loss: 1.3048\n",
      "Epoch 1648/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1465 - val_loss: 1.2168\n",
      "Epoch 1649/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1639 - val_loss: 1.2132\n",
      "Epoch 1650/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1500 - val_loss: 1.2516\n",
      "Epoch 1651/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1294 - val_loss: 1.2724\n",
      "Epoch 1652/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1437 - val_loss: 1.1687\n",
      "Epoch 1653/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1140 - val_loss: 1.2098\n",
      "Epoch 1654/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1196 - val_loss: 1.1777\n",
      "Epoch 1655/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1691 - val_loss: 1.1963\n",
      "Epoch 1656/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1486 - val_loss: 1.1775\n",
      "Epoch 1657/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1539 - val_loss: 1.1941\n",
      "Epoch 1658/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1474 - val_loss: 1.2118\n",
      "Epoch 1659/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1659 - val_loss: 1.2087\n",
      "Epoch 1660/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1544 - val_loss: 1.1761\n",
      "Epoch 1661/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2227 - val_loss: 1.2087\n",
      "Epoch 1662/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1316 - val_loss: 1.2668\n",
      "Epoch 1663/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1308 - val_loss: 1.1715\n",
      "Epoch 1664/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1301 - val_loss: 1.2429\n",
      "Epoch 1665/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1918 - val_loss: 1.4131\n",
      "Epoch 1666/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2927 - val_loss: 1.4503\n",
      "Epoch 1667/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1636 - val_loss: 1.2379\n",
      "Epoch 1668/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1445 - val_loss: 1.1876\n",
      "Epoch 1669/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1428 - val_loss: 1.1690\n",
      "Epoch 1670/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1231 - val_loss: 1.1667\n",
      "Epoch 1671/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1338 - val_loss: 1.1959\n",
      "Epoch 1672/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1444 - val_loss: 1.1785\n",
      "Epoch 1673/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1196 - val_loss: 1.2041\n",
      "Epoch 1674/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1526 - val_loss: 1.4154\n",
      "Epoch 1675/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1379 - val_loss: 1.3091\n",
      "Epoch 1676/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2249 - val_loss: 1.5660\n",
      "Epoch 1677/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2220 - val_loss: 1.1797\n",
      "Epoch 1678/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1568 - val_loss: 1.2012\n",
      "Epoch 1679/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1449 - val_loss: 1.2458\n",
      "Epoch 1680/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1711 - val_loss: 1.1568\n",
      "Epoch 1681/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1386 - val_loss: 1.2232\n",
      "Epoch 1682/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1587 - val_loss: 1.1967\n",
      "Epoch 1683/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1788 - val_loss: 1.2578\n",
      "Epoch 1684/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1857 - val_loss: 1.3009\n",
      "Epoch 1685/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1532 - val_loss: 1.2749\n",
      "Epoch 1686/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2524 - val_loss: 1.2148\n",
      "Epoch 1687/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2669 - val_loss: 1.4126\n",
      "Epoch 1688/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1452 - val_loss: 1.4052\n",
      "Epoch 1689/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1612 - val_loss: 1.2128\n",
      "Epoch 1690/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1465 - val_loss: 1.2273\n",
      "Epoch 1691/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1454 - val_loss: 1.1908\n",
      "Epoch 1692/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1491 - val_loss: 1.2215\n",
      "Epoch 1693/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1602 - val_loss: 1.1668\n",
      "Epoch 1694/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1422 - val_loss: 1.1853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1695/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1340 - val_loss: 1.1919\n",
      "Epoch 1696/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1311 - val_loss: 1.4125\n",
      "Epoch 1697/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1380 - val_loss: 1.1556\n",
      "Epoch 1698/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1863 - val_loss: 1.1452\n",
      "Epoch 1699/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1266 - val_loss: 1.4174\n",
      "Epoch 1700/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1272 - val_loss: 1.1786\n",
      "Epoch 1701/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1389 - val_loss: 1.3602\n",
      "Epoch 1702/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1583 - val_loss: 1.2126\n",
      "Epoch 1703/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1502 - val_loss: 1.2092\n",
      "Epoch 1704/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1943 - val_loss: 1.1983\n",
      "Epoch 1705/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1681 - val_loss: 1.3244\n",
      "Epoch 1706/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1497 - val_loss: 1.3587\n",
      "Epoch 1707/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1500 - val_loss: 1.1991\n",
      "Epoch 1708/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1435 - val_loss: 1.2401\n",
      "Epoch 1709/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1239 - val_loss: 1.2443\n",
      "Epoch 1710/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1243 - val_loss: 1.3064\n",
      "Epoch 1711/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1231 - val_loss: 1.2149\n",
      "Epoch 1712/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1815 - val_loss: 1.2717\n",
      "Epoch 1713/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2310 - val_loss: 1.7227\n",
      "Epoch 1714/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1995 - val_loss: 1.2259\n",
      "Epoch 1715/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1446 - val_loss: 1.1672\n",
      "Epoch 1716/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1800 - val_loss: 1.2353\n",
      "Epoch 1717/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1379 - val_loss: 1.2592\n",
      "Epoch 1718/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1594 - val_loss: 1.1473\n",
      "Epoch 1719/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1411 - val_loss: 1.2024\n",
      "Epoch 1720/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1315 - val_loss: 1.1972\n",
      "Epoch 1721/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1457 - val_loss: 1.2912\n",
      "Epoch 1722/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1452 - val_loss: 1.1638\n",
      "Epoch 1723/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1648 - val_loss: 1.2660\n",
      "Epoch 1724/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1564 - val_loss: 1.1990\n",
      "Epoch 1725/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1587 - val_loss: 1.2629\n",
      "Epoch 1726/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2128 - val_loss: 1.1493\n",
      "Epoch 1727/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1517 - val_loss: 1.2762\n",
      "Epoch 1728/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1669 - val_loss: 1.3817\n",
      "Epoch 1729/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1578 - val_loss: 1.2161\n",
      "Epoch 1730/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1563 - val_loss: 1.1663\n",
      "Epoch 1731/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1566 - val_loss: 1.2674\n",
      "Epoch 1732/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1589 - val_loss: 1.5570\n",
      "Epoch 1733/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2115 - val_loss: 1.2133\n",
      "Epoch 1734/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1329 - val_loss: 1.3213\n",
      "Epoch 1735/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1426 - val_loss: 1.2042\n",
      "Epoch 1736/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1397 - val_loss: 1.1493\n",
      "Epoch 1737/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1931 - val_loss: 1.2317\n",
      "Epoch 1738/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1706 - val_loss: 1.1601\n",
      "Epoch 1739/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1682 - val_loss: 1.2279\n",
      "Epoch 1740/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2024 - val_loss: 1.4586\n",
      "Epoch 1741/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1723 - val_loss: 1.1638\n",
      "Epoch 1742/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1516 - val_loss: 1.1744\n",
      "Epoch 1743/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1361 - val_loss: 1.2124\n",
      "Epoch 1744/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1769 - val_loss: 1.1587\n",
      "Epoch 1745/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1613 - val_loss: 1.1605\n",
      "Epoch 1746/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1516 - val_loss: 1.2834\n",
      "Epoch 1747/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1467 - val_loss: 1.1953\n",
      "Epoch 1748/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1460 - val_loss: 1.4162\n",
      "Epoch 1749/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1684 - val_loss: 1.1823\n",
      "Epoch 1750/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1530 - val_loss: 1.1992\n",
      "Epoch 1751/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2018 - val_loss: 1.2093\n",
      "Epoch 1752/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2059 - val_loss: 1.1631\n",
      "Epoch 1753/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1835 - val_loss: 1.3727\n",
      "Epoch 1754/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1434 - val_loss: 1.2180\n",
      "Epoch 1755/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1425 - val_loss: 1.2049\n",
      "Epoch 1756/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1372 - val_loss: 1.2147\n",
      "Epoch 1757/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1305 - val_loss: 1.1657\n",
      "Epoch 1758/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1551 - val_loss: 1.4496\n",
      "Epoch 1759/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1541 - val_loss: 1.2597\n",
      "Epoch 1760/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1902 - val_loss: 1.1771\n",
      "Epoch 1761/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1648 - val_loss: 1.1749\n",
      "Epoch 1762/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1603 - val_loss: 1.2219\n",
      "Epoch 1763/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1175 - val_loss: 1.2342\n",
      "Epoch 1764/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1625 - val_loss: 1.2376\n",
      "Epoch 1765/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1736 - val_loss: 1.1638\n",
      "Epoch 1766/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1343 - val_loss: 1.1693\n",
      "Epoch 1767/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1642 - val_loss: 1.1897\n",
      "Epoch 1768/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1558 - val_loss: 1.2446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1769/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1371 - val_loss: 1.2149\n",
      "Epoch 1770/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1299 - val_loss: 1.1862\n",
      "Epoch 1771/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1261 - val_loss: 1.2281\n",
      "Epoch 1772/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1374 - val_loss: 1.2561\n",
      "Epoch 1773/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1193 - val_loss: 1.1877\n",
      "Epoch 1774/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1666 - val_loss: 1.1551\n",
      "Epoch 1775/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1606 - val_loss: 1.2283\n",
      "Epoch 1776/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1542 - val_loss: 1.2740\n",
      "Epoch 1777/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1583 - val_loss: 1.3478\n",
      "Epoch 1778/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1368 - val_loss: 1.1391\n",
      "Epoch 1779/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1473 - val_loss: 1.2940\n",
      "Epoch 1780/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1673 - val_loss: 1.3968\n",
      "Epoch 1781/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1809 - val_loss: 1.2723\n",
      "Epoch 1782/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1538 - val_loss: 1.2401\n",
      "Epoch 1783/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1459 - val_loss: 1.1827\n",
      "Epoch 1784/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1555 - val_loss: 1.3356\n",
      "Epoch 1785/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1472 - val_loss: 1.1839\n",
      "Epoch 1786/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1841 - val_loss: 1.5469\n",
      "Epoch 1787/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1483 - val_loss: 1.2046\n",
      "Epoch 1788/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1391 - val_loss: 1.1791\n",
      "Epoch 1789/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1561 - val_loss: 1.2904\n",
      "Epoch 1790/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1444 - val_loss: 1.2273\n",
      "Epoch 1791/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1606 - val_loss: 1.3221\n",
      "Epoch 1792/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2173 - val_loss: 1.2144\n",
      "Epoch 1793/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2158 - val_loss: 1.1616\n",
      "Epoch 1794/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2014 - val_loss: 1.1976\n",
      "Epoch 1795/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1393 - val_loss: 1.2047\n",
      "Epoch 1796/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1387 - val_loss: 1.1830\n",
      "Epoch 1797/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1684 - val_loss: 1.2005\n",
      "Epoch 1798/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1831 - val_loss: 1.2927\n",
      "Epoch 1799/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1236 - val_loss: 1.1883\n",
      "Epoch 1800/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1895 - val_loss: 1.1980\n",
      "Epoch 1801/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1993 - val_loss: 1.2378\n",
      "Epoch 1802/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1560 - val_loss: 1.1356\n",
      "Epoch 1803/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1183 - val_loss: 1.2220\n",
      "Epoch 1804/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1300 - val_loss: 1.1967\n",
      "Epoch 1805/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1289 - val_loss: 1.1607\n",
      "Epoch 1806/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1848 - val_loss: 1.1792\n",
      "Epoch 1807/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1587 - val_loss: 1.2397\n",
      "Epoch 1808/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1338 - val_loss: 1.1791\n",
      "Epoch 1809/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1658 - val_loss: 1.1524\n",
      "Epoch 1810/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1492 - val_loss: 1.1968\n",
      "Epoch 1811/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1523 - val_loss: 1.3668\n",
      "Epoch 1812/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1241 - val_loss: 1.1853\n",
      "Epoch 1813/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1589 - val_loss: 1.4381\n",
      "Epoch 1814/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1528 - val_loss: 1.3268\n",
      "Epoch 1815/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1625 - val_loss: 1.1754\n",
      "Epoch 1816/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1989 - val_loss: 1.3024\n",
      "Epoch 1817/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1264 - val_loss: 1.2289\n",
      "Epoch 1818/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1740 - val_loss: 1.1818\n",
      "Epoch 1819/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1459 - val_loss: 1.2483\n",
      "Epoch 1820/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1367 - val_loss: 1.2466\n",
      "Epoch 1821/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1594 - val_loss: 1.2726\n",
      "Epoch 1822/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1430 - val_loss: 1.2709\n",
      "Epoch 1823/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1892 - val_loss: 1.3071\n",
      "Epoch 1824/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1393 - val_loss: 1.1861\n",
      "Epoch 1825/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2245 - val_loss: 1.4274\n",
      "Epoch 1826/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1395 - val_loss: 1.1578\n",
      "Epoch 1827/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1348 - val_loss: 1.4682\n",
      "Epoch 1828/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1704 - val_loss: 1.1424\n",
      "Epoch 1829/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1360 - val_loss: 1.1777\n",
      "Epoch 1830/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1298 - val_loss: 1.2618\n",
      "Epoch 1831/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1284 - val_loss: 1.2069\n",
      "Epoch 1832/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1749 - val_loss: 1.3106\n",
      "Epoch 1833/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1314 - val_loss: 1.1701\n",
      "Epoch 1834/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1862 - val_loss: 1.2258\n",
      "Epoch 1835/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1636 - val_loss: 1.1369\n",
      "Epoch 1836/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1661 - val_loss: 1.2749\n",
      "Epoch 1837/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1680 - val_loss: 1.3371\n",
      "Epoch 1838/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1797 - val_loss: 1.1481\n",
      "Epoch 1839/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1715 - val_loss: 1.2861\n",
      "Epoch 1840/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1259 - val_loss: 1.2500\n",
      "Epoch 1841/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2363 - val_loss: 1.1504\n",
      "Epoch 1842/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1356 - val_loss: 1.1602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1843/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1408 - val_loss: 1.2199\n",
      "Epoch 1844/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1257 - val_loss: 1.2150\n",
      "Epoch 1845/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1441 - val_loss: 1.2332\n",
      "Epoch 1846/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2089 - val_loss: 1.2862\n",
      "Epoch 1847/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1667 - val_loss: 1.3992\n",
      "Epoch 1848/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1496 - val_loss: 1.3365\n",
      "Epoch 1849/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1540 - val_loss: 1.3359\n",
      "Epoch 1850/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1380 - val_loss: 1.1836\n",
      "Epoch 1851/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1167 - val_loss: 1.2195\n",
      "Epoch 1852/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2431 - val_loss: 1.3039\n",
      "Epoch 1853/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1769 - val_loss: 1.1401\n",
      "Epoch 1854/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1553 - val_loss: 1.3968\n",
      "Epoch 1855/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1419 - val_loss: 1.2316\n",
      "Epoch 1856/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1448 - val_loss: 1.2032\n",
      "Epoch 1857/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1514 - val_loss: 1.1967\n",
      "Epoch 1858/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1296 - val_loss: 1.2032\n",
      "Epoch 1859/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1389 - val_loss: 1.3155\n",
      "Epoch 1860/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1347 - val_loss: 1.1523\n",
      "Epoch 1861/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1352 - val_loss: 1.1763\n",
      "Epoch 1862/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1684 - val_loss: 1.2119\n",
      "Epoch 1863/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1352 - val_loss: 1.2311\n",
      "Epoch 1864/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1725 - val_loss: 1.3277\n",
      "Epoch 1865/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1695 - val_loss: 1.2159\n",
      "Epoch 1866/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1663 - val_loss: 1.2310\n",
      "Epoch 1867/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1860 - val_loss: 1.2977\n",
      "Epoch 1868/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1552 - val_loss: 1.2330\n",
      "Epoch 1869/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1548 - val_loss: 1.2166\n",
      "Epoch 1870/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1433 - val_loss: 1.2625\n",
      "Epoch 1871/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1588 - val_loss: 1.2494\n",
      "Epoch 1872/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1398 - val_loss: 1.3276\n",
      "Epoch 1873/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1581 - val_loss: 1.1541\n",
      "Epoch 1874/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1480 - val_loss: 1.2342\n",
      "Epoch 1875/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1347 - val_loss: 1.2171\n",
      "Epoch 1876/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1681 - val_loss: 1.2487\n",
      "Epoch 1877/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1905 - val_loss: 1.3482\n",
      "Epoch 1878/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1763 - val_loss: 1.1684\n",
      "Epoch 1879/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1727 - val_loss: 1.2331\n",
      "Epoch 1880/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1506 - val_loss: 1.1578\n",
      "Epoch 1881/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1408 - val_loss: 1.1876\n",
      "Epoch 1882/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1497 - val_loss: 1.2645\n",
      "Epoch 1883/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1437 - val_loss: 1.1727\n",
      "Epoch 1884/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1212 - val_loss: 1.2961\n",
      "Epoch 1885/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1339 - val_loss: 1.2532\n",
      "Epoch 1886/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1365 - val_loss: 1.1723\n",
      "Epoch 1887/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1373 - val_loss: 1.3438\n",
      "Epoch 1888/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1667 - val_loss: 1.4073\n",
      "Epoch 1889/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1415 - val_loss: 1.2284\n",
      "Epoch 1890/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1952 - val_loss: 1.3563\n",
      "Epoch 1891/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1729 - val_loss: 1.3119\n",
      "Epoch 1892/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2372 - val_loss: 1.4195\n",
      "Epoch 1893/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1959 - val_loss: 1.1794\n",
      "Epoch 1894/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1442 - val_loss: 1.3306\n",
      "Epoch 1895/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2564 - val_loss: 1.1820\n",
      "Epoch 1896/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1350 - val_loss: 1.1558\n",
      "Epoch 1897/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1192 - val_loss: 1.2012\n",
      "Epoch 1898/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1459 - val_loss: 1.4824\n",
      "Epoch 1899/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2223 - val_loss: 1.1819\n",
      "Epoch 1900/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1729 - val_loss: 1.4893\n",
      "Epoch 1901/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2653 - val_loss: 1.2234\n",
      "Epoch 1902/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2740 - val_loss: 1.5557\n",
      "Epoch 1903/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.3079 - val_loss: 1.2119\n",
      "Epoch 1904/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1840 - val_loss: 1.1767\n",
      "Epoch 1905/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1122 - val_loss: 1.3602\n",
      "Epoch 1906/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1616 - val_loss: 1.1838\n",
      "Epoch 1907/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1826 - val_loss: 1.1533\n",
      "Epoch 1908/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1347 - val_loss: 1.3232\n",
      "Epoch 1909/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1338 - val_loss: 1.1510\n",
      "Epoch 1910/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1348 - val_loss: 1.2173\n",
      "Epoch 1911/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1332 - val_loss: 1.2523\n",
      "Epoch 1912/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1462 - val_loss: 1.2061\n",
      "Epoch 1913/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1201 - val_loss: 1.1392\n",
      "Epoch 1914/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1684 - val_loss: 1.2786\n",
      "Epoch 1915/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1770 - val_loss: 1.1948\n",
      "Epoch 1916/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1739 - val_loss: 1.1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1917/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1486 - val_loss: 1.1751\n",
      "Epoch 1918/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1259 - val_loss: 1.2429\n",
      "Epoch 1919/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1397 - val_loss: 1.1800\n",
      "Epoch 1920/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1896 - val_loss: 1.2921\n",
      "Epoch 1921/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1394 - val_loss: 1.1571\n",
      "Epoch 1922/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1734 - val_loss: 1.1988\n",
      "Epoch 1923/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1403 - val_loss: 1.3375\n",
      "Epoch 1924/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2135 - val_loss: 1.2342\n",
      "Epoch 1925/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1721 - val_loss: 1.1993\n",
      "Epoch 1926/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1193 - val_loss: 1.2660\n",
      "Epoch 1927/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1362 - val_loss: 1.2087\n",
      "Epoch 1928/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1805 - val_loss: 1.2033\n",
      "Epoch 1929/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1786 - val_loss: 1.2347\n",
      "Epoch 1930/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1325 - val_loss: 1.1890\n",
      "Epoch 1931/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1114 - val_loss: 1.2163\n",
      "Epoch 1932/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1297 - val_loss: 1.1223\n",
      "Epoch 1933/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1338 - val_loss: 1.2934\n",
      "Epoch 1934/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1238 - val_loss: 1.1898\n",
      "Epoch 1935/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1916 - val_loss: 1.2245\n",
      "Epoch 1936/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2144 - val_loss: 1.2509\n",
      "Epoch 1937/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1876 - val_loss: 1.2538\n",
      "Epoch 1938/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1440 - val_loss: 1.2408\n",
      "Epoch 1939/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1624 - val_loss: 1.1793\n",
      "Epoch 1940/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1897 - val_loss: 1.3588\n",
      "Epoch 1941/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1442 - val_loss: 1.2087\n",
      "Epoch 1942/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1254 - val_loss: 1.1689\n",
      "Epoch 1943/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1557 - val_loss: 1.4783\n",
      "Epoch 1944/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1541 - val_loss: 1.2466\n",
      "Epoch 1945/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1245 - val_loss: 1.1974\n",
      "Epoch 1946/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1380 - val_loss: 1.4088\n",
      "Epoch 1947/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1762 - val_loss: 1.1301\n",
      "Epoch 1948/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1289 - val_loss: 1.1716\n",
      "Epoch 1949/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1317 - val_loss: 1.1762\n",
      "Epoch 1950/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1514 - val_loss: 1.2225\n",
      "Epoch 1951/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1408 - val_loss: 1.3646\n",
      "Epoch 1952/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1609 - val_loss: 1.1825\n",
      "Epoch 1953/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1702 - val_loss: 1.1874\n",
      "Epoch 1954/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1395 - val_loss: 1.3587\n",
      "Epoch 1955/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1611 - val_loss: 1.3293\n",
      "Epoch 1956/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1287 - val_loss: 1.1461\n",
      "Epoch 1957/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1680 - val_loss: 1.4860\n",
      "Epoch 1958/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2188 - val_loss: 1.1905\n",
      "Epoch 1959/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1478 - val_loss: 1.1821\n",
      "Epoch 1960/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1259 - val_loss: 1.2455\n",
      "Epoch 1961/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1679 - val_loss: 1.5475\n",
      "Epoch 1962/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1757 - val_loss: 1.3034\n",
      "Epoch 1963/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1887 - val_loss: 1.1384\n",
      "Epoch 1964/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2047 - val_loss: 1.2749\n",
      "Epoch 1965/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1464 - val_loss: 1.1738\n",
      "Epoch 1966/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1970 - val_loss: 1.2964\n",
      "Epoch 1967/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1360 - val_loss: 1.1796\n",
      "Epoch 1968/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1371 - val_loss: 1.5189\n",
      "Epoch 1969/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1443 - val_loss: 1.1535\n",
      "Epoch 1970/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1915 - val_loss: 1.1479\n",
      "Epoch 1971/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1741 - val_loss: 1.3363\n",
      "Epoch 1972/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1230 - val_loss: 1.1873\n",
      "Epoch 1973/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1455 - val_loss: 1.2764\n",
      "Epoch 1974/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1507 - val_loss: 1.2308\n",
      "Epoch 1975/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1393 - val_loss: 1.1964\n",
      "Epoch 1976/20000\n",
      "1500/1500 [==============================] - 0s 34us/sample - loss: 1.1513 - val_loss: 1.1999\n",
      "Epoch 1977/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1209 - val_loss: 1.1289\n",
      "Epoch 1978/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1675 - val_loss: 1.3281\n",
      "Epoch 1979/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1512 - val_loss: 1.3752\n",
      "Epoch 1980/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1755 - val_loss: 1.1840\n",
      "Epoch 1981/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2037 - val_loss: 1.2224\n",
      "Epoch 1982/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1360 - val_loss: 1.1394\n",
      "Epoch 1983/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1617 - val_loss: 1.1752\n",
      "Epoch 1984/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1702 - val_loss: 1.2413\n",
      "Epoch 1985/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1462 - val_loss: 1.3205\n",
      "Epoch 1986/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1265 - val_loss: 1.1834\n",
      "Epoch 1987/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1306 - val_loss: 1.2136\n",
      "Epoch 1988/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1428 - val_loss: 1.1863\n",
      "Epoch 1989/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1420 - val_loss: 1.1911\n",
      "Epoch 1990/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1818 - val_loss: 1.2794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1991/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1483 - val_loss: 1.3063\n",
      "Epoch 1992/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1462 - val_loss: 1.3473\n",
      "Epoch 1993/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1404 - val_loss: 1.1847\n",
      "Epoch 1994/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1146 - val_loss: 1.2347\n",
      "Epoch 1995/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1492 - val_loss: 1.1887\n",
      "Epoch 1996/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1151 - val_loss: 1.2276\n",
      "Epoch 1997/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1429 - val_loss: 1.1969\n",
      "Epoch 1998/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1405 - val_loss: 1.1891\n",
      "Epoch 1999/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1988 - val_loss: 1.2377\n",
      "Epoch 2000/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1354 - val_loss: 1.2042\n",
      "Epoch 2001/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1833 - val_loss: 1.2259\n",
      "Epoch 2002/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1138 - val_loss: 1.2439\n",
      "Epoch 2003/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1714 - val_loss: 1.2650\n",
      "Epoch 2004/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1708 - val_loss: 1.2005\n",
      "Epoch 2005/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1746 - val_loss: 1.1583\n",
      "Epoch 2006/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1163 - val_loss: 1.2659\n",
      "Epoch 2007/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1526 - val_loss: 1.1737\n",
      "Epoch 2008/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1352 - val_loss: 1.2698\n",
      "Epoch 2009/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1500 - val_loss: 1.2051\n",
      "Epoch 2010/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1438 - val_loss: 1.2336\n",
      "Epoch 2011/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1796 - val_loss: 1.1927\n",
      "Epoch 2012/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1533 - val_loss: 1.3276\n",
      "Epoch 2013/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1599 - val_loss: 1.1801\n",
      "Epoch 2014/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1378 - val_loss: 1.1788\n",
      "Epoch 2015/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1592 - val_loss: 1.1880\n",
      "Epoch 2016/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1489 - val_loss: 1.2312\n",
      "Epoch 2017/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1670 - val_loss: 1.2648\n",
      "Epoch 2018/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1516 - val_loss: 1.2142\n",
      "Epoch 2019/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1178 - val_loss: 1.1895\n",
      "Epoch 2020/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1286 - val_loss: 1.2028\n",
      "Epoch 2021/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1450 - val_loss: 1.2082\n",
      "Epoch 2022/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1556 - val_loss: 1.3958\n",
      "Epoch 2023/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1271 - val_loss: 1.1635\n",
      "Epoch 2024/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1214 - val_loss: 1.4265\n",
      "Epoch 2025/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1468 - val_loss: 1.2141\n",
      "Epoch 2026/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1803 - val_loss: 1.3271\n",
      "Epoch 2027/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1665 - val_loss: 1.4185\n",
      "Epoch 2028/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1981 - val_loss: 1.1715\n",
      "Epoch 2029/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1464 - val_loss: 1.2308\n",
      "Epoch 2030/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1652 - val_loss: 1.1467\n",
      "Epoch 2031/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1594 - val_loss: 1.3951\n",
      "Epoch 2032/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1682 - val_loss: 1.1671\n",
      "Epoch 2033/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1168 - val_loss: 1.1992\n",
      "Epoch 2034/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1185 - val_loss: 1.2692\n",
      "Epoch 2035/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1449 - val_loss: 1.1511\n",
      "Epoch 2036/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1357 - val_loss: 1.2508\n",
      "Epoch 2037/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1692 - val_loss: 1.2782\n",
      "Epoch 2038/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1430 - val_loss: 1.2236\n",
      "Epoch 2039/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1532 - val_loss: 1.3827\n",
      "Epoch 2040/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.3346 - val_loss: 1.2549\n",
      "Epoch 2041/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1639 - val_loss: 1.1999\n",
      "Epoch 2042/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1384 - val_loss: 1.3144\n",
      "Epoch 2043/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1591 - val_loss: 1.2296\n",
      "Epoch 2044/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1419 - val_loss: 1.2346\n",
      "Epoch 2045/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1411 - val_loss: 1.1844\n",
      "Epoch 2046/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1657 - val_loss: 1.2027\n",
      "Epoch 2047/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1413 - val_loss: 1.2783\n",
      "Epoch 2048/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1744 - val_loss: 1.1967\n",
      "Epoch 2049/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1390 - val_loss: 1.3249\n",
      "Epoch 2050/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1741 - val_loss: 1.1950\n",
      "Epoch 2051/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1432 - val_loss: 1.2749\n",
      "Epoch 2052/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1175 - val_loss: 1.1607\n",
      "Epoch 2053/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1798 - val_loss: 1.3531\n",
      "Epoch 2054/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1173 - val_loss: 1.2237\n",
      "Epoch 2055/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1534 - val_loss: 1.1614\n",
      "Epoch 2056/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1837 - val_loss: 1.2986\n",
      "Epoch 2057/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1697 - val_loss: 1.2055\n",
      "Epoch 2058/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2224 - val_loss: 1.1838\n",
      "Epoch 2059/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1457 - val_loss: 1.2136\n",
      "Epoch 2060/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1619 - val_loss: 1.2654\n",
      "Epoch 2061/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1443 - val_loss: 1.3075\n",
      "Epoch 2062/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1753 - val_loss: 1.1856\n",
      "Epoch 2063/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1481 - val_loss: 1.1716\n",
      "Epoch 2064/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1477 - val_loss: 1.2037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2065/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1495 - val_loss: 1.2089\n",
      "Epoch 2066/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1381 - val_loss: 1.3027\n",
      "Epoch 2067/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1314 - val_loss: 1.2976\n",
      "Epoch 2068/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1353 - val_loss: 1.2143\n",
      "Epoch 2069/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1873 - val_loss: 1.2614\n",
      "Epoch 2070/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1456 - val_loss: 1.2680\n",
      "Epoch 2071/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1622 - val_loss: 1.3046\n",
      "Epoch 2072/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1973 - val_loss: 1.2955\n",
      "Epoch 2073/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1854 - val_loss: 1.2318\n",
      "Epoch 2074/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1300 - val_loss: 1.2449\n",
      "Epoch 2075/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1736 - val_loss: 1.1581\n",
      "Epoch 2076/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1496 - val_loss: 1.3968\n",
      "Epoch 2077/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1691 - val_loss: 1.1836\n",
      "Epoch 2078/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1478 - val_loss: 1.2310\n",
      "Epoch 2079/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1480 - val_loss: 1.1977\n",
      "Epoch 2080/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1737 - val_loss: 1.4617\n",
      "Epoch 2081/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1251 - val_loss: 1.1906\n",
      "Epoch 2082/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1348 - val_loss: 1.1403\n",
      "Epoch 2083/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1503 - val_loss: 1.1435\n",
      "Epoch 2084/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1440 - val_loss: 1.2507\n",
      "Epoch 2085/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1426 - val_loss: 1.2128\n",
      "Epoch 2086/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1153 - val_loss: 1.3305\n",
      "Epoch 2087/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1315 - val_loss: 1.2510\n",
      "Epoch 2088/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1667 - val_loss: 1.2215\n",
      "Epoch 2089/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1654 - val_loss: 1.1370\n",
      "Epoch 2090/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1864 - val_loss: 1.2833\n",
      "Epoch 2091/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1833 - val_loss: 1.3049\n",
      "Epoch 2092/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2021 - val_loss: 1.3382\n",
      "Epoch 2093/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2468 - val_loss: 1.3338\n",
      "Epoch 2094/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1590 - val_loss: 1.3296\n",
      "Epoch 2095/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1789 - val_loss: 1.1571\n",
      "Epoch 2096/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1766 - val_loss: 1.1697\n",
      "Epoch 2097/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1467 - val_loss: 1.3591\n",
      "Epoch 2098/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1413 - val_loss: 1.2589\n",
      "Epoch 2099/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1412 - val_loss: 1.2531\n",
      "Epoch 2100/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1495 - val_loss: 1.3334\n",
      "Epoch 2101/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1531 - val_loss: 1.2044\n",
      "Epoch 2102/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1811 - val_loss: 1.1555\n",
      "Epoch 2103/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1686 - val_loss: 1.2629\n",
      "Epoch 2104/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1445 - val_loss: 1.2375\n",
      "Epoch 2105/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1367 - val_loss: 1.1732\n",
      "Epoch 2106/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1894 - val_loss: 1.2270\n",
      "Epoch 2107/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1773 - val_loss: 1.1649\n",
      "Epoch 2108/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1249 - val_loss: 1.1629\n",
      "Epoch 2109/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1145 - val_loss: 1.1821\n",
      "Epoch 2110/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1790 - val_loss: 1.3449\n",
      "Epoch 2111/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1400 - val_loss: 1.1702\n",
      "Epoch 2112/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1872 - val_loss: 1.2347\n",
      "Epoch 2113/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1408 - val_loss: 1.2087\n",
      "Epoch 2114/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1619 - val_loss: 1.3129\n",
      "Epoch 2115/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1751 - val_loss: 1.1597\n",
      "Epoch 2116/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1457 - val_loss: 1.3442\n",
      "Epoch 2117/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1404 - val_loss: 1.2631\n",
      "Epoch 2118/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1193 - val_loss: 1.1833\n",
      "Epoch 2119/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1531 - val_loss: 1.1645\n",
      "Epoch 2120/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1815 - val_loss: 1.3708\n",
      "Epoch 2121/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1832 - val_loss: 1.2555\n",
      "Epoch 2122/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1519 - val_loss: 1.1566\n",
      "Epoch 2123/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1391 - val_loss: 1.3112\n",
      "Epoch 2124/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1383 - val_loss: 1.1609\n",
      "Epoch 2125/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1914 - val_loss: 1.3321\n",
      "Epoch 2126/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1318 - val_loss: 1.3256\n",
      "Epoch 2127/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1506 - val_loss: 1.1976\n",
      "Epoch 2128/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1546 - val_loss: 1.2834\n",
      "Epoch 2129/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1997 - val_loss: 1.1992\n",
      "Epoch 2130/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1778 - val_loss: 1.1627\n",
      "Epoch 2131/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1793 - val_loss: 1.1339\n",
      "Epoch 2132/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1529 - val_loss: 1.2056\n",
      "Epoch 2133/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1526 - val_loss: 1.1708\n",
      "Epoch 2134/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1581 - val_loss: 1.1866\n",
      "Epoch 2135/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1394 - val_loss: 1.4160\n",
      "Epoch 2136/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1382 - val_loss: 1.2016\n",
      "Epoch 2137/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1262 - val_loss: 1.1803\n",
      "Epoch 2138/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1543 - val_loss: 1.2175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2139/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1333 - val_loss: 1.1954\n",
      "Epoch 2140/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1102 - val_loss: 1.2175\n",
      "Epoch 2141/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1502 - val_loss: 1.1656\n",
      "Epoch 2142/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1143 - val_loss: 1.2427\n",
      "Epoch 2143/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1174 - val_loss: 1.3161\n",
      "Epoch 2144/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1769 - val_loss: 1.2882\n",
      "Epoch 2145/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2034 - val_loss: 1.1966\n",
      "Epoch 2146/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1714 - val_loss: 1.1366\n",
      "Epoch 2147/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1526 - val_loss: 1.1930\n",
      "Epoch 2148/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1716 - val_loss: 1.2746\n",
      "Epoch 2149/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1205 - val_loss: 1.3346\n",
      "Epoch 2150/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1744 - val_loss: 1.3368\n",
      "Epoch 2151/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1639 - val_loss: 1.2128\n",
      "Epoch 2152/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1308 - val_loss: 1.1811\n",
      "Epoch 2153/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1548 - val_loss: 1.2181\n",
      "Epoch 2154/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1736 - val_loss: 1.2333\n",
      "Epoch 2155/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1600 - val_loss: 1.2268\n",
      "Epoch 2156/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1337 - val_loss: 1.1516\n",
      "Epoch 2157/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1951 - val_loss: 1.1780\n",
      "Epoch 2158/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1384 - val_loss: 1.3173\n",
      "Epoch 2159/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2067 - val_loss: 1.1496\n",
      "Epoch 2160/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1581 - val_loss: 1.3340\n",
      "Epoch 2161/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1445 - val_loss: 1.2474\n",
      "Epoch 2162/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1739 - val_loss: 1.2139\n",
      "Epoch 2163/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1299 - val_loss: 1.1679\n",
      "Epoch 2164/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1319 - val_loss: 1.2781\n",
      "Epoch 2165/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1343 - val_loss: 1.3737\n",
      "Epoch 2166/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1570 - val_loss: 1.1436\n",
      "Epoch 2167/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1599 - val_loss: 1.2513\n",
      "Epoch 2168/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1318 - val_loss: 1.2617\n",
      "Epoch 2169/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1816 - val_loss: 1.2472\n",
      "Epoch 2170/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1432 - val_loss: 1.1905\n",
      "Epoch 2171/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1414 - val_loss: 1.2119\n",
      "Epoch 2172/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1666 - val_loss: 1.1617\n",
      "Epoch 2173/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1613 - val_loss: 1.2314\n",
      "Epoch 2174/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1410 - val_loss: 1.2256\n",
      "Epoch 2175/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1515 - val_loss: 1.1417\n",
      "Epoch 2176/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1471 - val_loss: 1.3049\n",
      "Epoch 2177/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1440 - val_loss: 1.1753\n",
      "Epoch 2178/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1531 - val_loss: 1.3456\n",
      "Epoch 2179/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1304 - val_loss: 1.1539\n",
      "Epoch 2180/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1551 - val_loss: 1.1820\n",
      "Epoch 2181/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1326 - val_loss: 1.3003\n",
      "Epoch 2182/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1225 - val_loss: 1.2829\n",
      "Epoch 2183/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1416 - val_loss: 1.1845\n",
      "Epoch 2184/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1253 - val_loss: 1.2782\n",
      "Epoch 2185/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1117 - val_loss: 1.1932\n",
      "Epoch 2186/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1523 - val_loss: 1.3620\n",
      "Epoch 2187/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1611 - val_loss: 1.1576\n",
      "Epoch 2188/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1483 - val_loss: 1.1798\n",
      "Epoch 2189/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1922 - val_loss: 1.1940\n",
      "Epoch 2190/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1414 - val_loss: 1.2632\n",
      "Epoch 2191/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1210 - val_loss: 1.1732\n",
      "Epoch 2192/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1322 - val_loss: 1.1963\n",
      "Epoch 2193/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1273 - val_loss: 1.1612\n",
      "Epoch 2194/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1333 - val_loss: 1.2100\n",
      "Epoch 2195/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1302 - val_loss: 1.1966\n",
      "Epoch 2196/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1676 - val_loss: 1.1764\n",
      "Epoch 2197/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1761 - val_loss: 1.2132\n",
      "Epoch 2198/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1643 - val_loss: 1.2733\n",
      "Epoch 2199/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2380 - val_loss: 1.1534\n",
      "Epoch 2200/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1566 - val_loss: 1.2849\n",
      "Epoch 2201/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1795 - val_loss: 1.2396\n",
      "Epoch 2202/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1602 - val_loss: 1.1954\n",
      "Epoch 2203/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1829 - val_loss: 1.1736\n",
      "Epoch 2204/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2484 - val_loss: 1.5698\n",
      "Epoch 2205/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.2397 - val_loss: 1.3631\n",
      "Epoch 2206/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2361 - val_loss: 1.3544\n",
      "Epoch 2207/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1313 - val_loss: 1.1709\n",
      "Epoch 2208/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1608 - val_loss: 1.3115\n",
      "Epoch 2209/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1406 - val_loss: 1.2777\n",
      "Epoch 2210/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1483 - val_loss: 1.2678\n",
      "Epoch 2211/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1516 - val_loss: 1.1518\n",
      "Epoch 2212/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1293 - val_loss: 1.2355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2213/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1914 - val_loss: 1.1617\n",
      "Epoch 2214/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1657 - val_loss: 1.1759\n",
      "Epoch 2215/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1410 - val_loss: 1.2677\n",
      "Epoch 2216/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1453 - val_loss: 1.3324\n",
      "Epoch 2217/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1277 - val_loss: 1.1974\n",
      "Epoch 2218/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1175 - val_loss: 1.1873\n",
      "Epoch 2219/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1665 - val_loss: 1.2791\n",
      "Epoch 2220/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1478 - val_loss: 1.2766\n",
      "Epoch 2221/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1895 - val_loss: 1.1847\n",
      "Epoch 2222/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1147 - val_loss: 1.1668\n",
      "Epoch 2223/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1461 - val_loss: 1.1270\n",
      "Epoch 2224/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1861 - val_loss: 1.3803\n",
      "Epoch 2225/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1202 - val_loss: 1.1347\n",
      "Epoch 2226/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1681 - val_loss: 1.3597\n",
      "Epoch 2227/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2012 - val_loss: 1.3378\n",
      "Epoch 2228/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1772 - val_loss: 1.1795\n",
      "Epoch 2229/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1398 - val_loss: 1.2420\n",
      "Epoch 2230/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1252 - val_loss: 1.1659\n",
      "Epoch 2231/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1211 - val_loss: 1.1556\n",
      "Epoch 2232/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1419 - val_loss: 1.2486\n",
      "Epoch 2233/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1423 - val_loss: 1.1635\n",
      "Epoch 2234/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1537 - val_loss: 1.1788\n",
      "Epoch 2235/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1428 - val_loss: 1.2532\n",
      "Epoch 2236/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1506 - val_loss: 1.2502\n",
      "Epoch 2237/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1334 - val_loss: 1.3863\n",
      "Epoch 2238/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1500 - val_loss: 1.1740\n",
      "Epoch 2239/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1241 - val_loss: 1.2284\n",
      "Epoch 2240/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1304 - val_loss: 1.1626\n",
      "Epoch 2241/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1357 - val_loss: 1.1827\n",
      "Epoch 2242/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1266 - val_loss: 1.1691\n",
      "Epoch 2243/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1734 - val_loss: 1.2612\n",
      "Epoch 2244/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1873 - val_loss: 1.1377\n",
      "Epoch 2245/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1538 - val_loss: 1.4587\n",
      "Epoch 2246/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1561 - val_loss: 1.2543\n",
      "Epoch 2247/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1329 - val_loss: 1.2197\n",
      "Epoch 2248/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1647 - val_loss: 1.2523\n",
      "Epoch 2249/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1739 - val_loss: 1.4021\n",
      "Epoch 2250/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1723 - val_loss: 1.2250\n",
      "Epoch 2251/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1664 - val_loss: 1.3395\n",
      "Epoch 2252/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1277 - val_loss: 1.1646\n",
      "Epoch 2253/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1425 - val_loss: 1.2085\n",
      "Epoch 2254/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1247 - val_loss: 1.2013\n",
      "Epoch 2255/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1441 - val_loss: 1.1859\n",
      "Epoch 2256/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1498 - val_loss: 1.2894\n",
      "Epoch 2257/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1589 - val_loss: 1.1933\n",
      "Epoch 2258/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1308 - val_loss: 1.2768\n",
      "Epoch 2259/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1407 - val_loss: 1.1194\n",
      "Epoch 2260/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1271 - val_loss: 1.1812\n",
      "Epoch 2261/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1468 - val_loss: 1.1810\n",
      "Epoch 2262/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2589 - val_loss: 1.5083\n",
      "Epoch 2263/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2831 - val_loss: 1.1767\n",
      "Epoch 2264/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1981 - val_loss: 1.2557\n",
      "Epoch 2265/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1927 - val_loss: 1.1807\n",
      "Epoch 2266/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1558 - val_loss: 1.4738\n",
      "Epoch 2267/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1234 - val_loss: 1.1666\n",
      "Epoch 2268/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1501 - val_loss: 1.3036\n",
      "Epoch 2269/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1583 - val_loss: 1.1380\n",
      "Epoch 2270/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1573 - val_loss: 1.4065\n",
      "Epoch 2271/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2005 - val_loss: 1.2050\n",
      "Epoch 2272/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1623 - val_loss: 1.1869\n",
      "Epoch 2273/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1543 - val_loss: 1.1773\n",
      "Epoch 2274/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1733 - val_loss: 1.2923\n",
      "Epoch 2275/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1474 - val_loss: 1.1647\n",
      "Epoch 2276/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1349 - val_loss: 1.2363\n",
      "Epoch 2277/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1352 - val_loss: 1.2058\n",
      "Epoch 2278/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1542 - val_loss: 1.3454\n",
      "Epoch 2279/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1705 - val_loss: 1.1736\n",
      "Epoch 2280/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1899 - val_loss: 1.2107\n",
      "Epoch 2281/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1351 - val_loss: 1.1722\n",
      "Epoch 2282/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1295 - val_loss: 1.2125\n",
      "Epoch 2283/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1232 - val_loss: 1.1732\n",
      "Epoch 2284/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1466 - val_loss: 1.5206\n",
      "Epoch 2285/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1818 - val_loss: 1.3257\n",
      "Epoch 2286/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1430 - val_loss: 1.2464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2287/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2085 - val_loss: 1.5651\n",
      "Epoch 2288/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2094 - val_loss: 1.2415\n",
      "Epoch 2289/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1320 - val_loss: 1.1831\n",
      "Epoch 2290/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1578 - val_loss: 1.3944\n",
      "Epoch 2291/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1555 - val_loss: 1.2103\n",
      "Epoch 2292/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1556 - val_loss: 1.2724\n",
      "Epoch 2293/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1310 - val_loss: 1.1914\n",
      "Epoch 2294/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1678 - val_loss: 1.2066\n",
      "Epoch 2295/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1534 - val_loss: 1.2329\n",
      "Epoch 2296/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1301 - val_loss: 1.3923\n",
      "Epoch 2297/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1673 - val_loss: 1.2410\n",
      "Epoch 2298/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1422 - val_loss: 1.2329\n",
      "Epoch 2299/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1231 - val_loss: 1.2591\n",
      "Epoch 2300/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1366 - val_loss: 1.3316\n",
      "Epoch 2301/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1486 - val_loss: 1.2953\n",
      "Epoch 2302/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1385 - val_loss: 1.2047\n",
      "Epoch 2303/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2730 - val_loss: 1.1648\n",
      "Epoch 2304/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1612 - val_loss: 1.2469\n",
      "Epoch 2305/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1524 - val_loss: 1.1618\n",
      "Epoch 2306/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1430 - val_loss: 1.1239\n",
      "Epoch 2307/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1701 - val_loss: 1.4959\n",
      "Epoch 2308/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1879 - val_loss: 1.2154\n",
      "Epoch 2309/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1753 - val_loss: 1.2406\n",
      "Epoch 2310/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2264 - val_loss: 1.2304\n",
      "Epoch 2311/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1684 - val_loss: 1.2374\n",
      "Epoch 2312/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1232 - val_loss: 1.2247\n",
      "Epoch 2313/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1339 - val_loss: 1.2480\n",
      "Epoch 2314/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1573 - val_loss: 1.2001\n",
      "Epoch 2315/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1853 - val_loss: 1.1683\n",
      "Epoch 2316/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2234 - val_loss: 1.3568\n",
      "Epoch 2317/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1510 - val_loss: 1.1526\n",
      "Epoch 2318/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1611 - val_loss: 1.2941\n",
      "Epoch 2319/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1948 - val_loss: 1.5333\n",
      "Epoch 2320/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1345 - val_loss: 1.1628\n",
      "Epoch 2321/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1658 - val_loss: 1.1818\n",
      "Epoch 2322/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1441 - val_loss: 1.1836\n",
      "Epoch 2323/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1375 - val_loss: 1.2727\n",
      "Epoch 2324/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1997 - val_loss: 1.1780\n",
      "Epoch 2325/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1504 - val_loss: 1.1270\n",
      "Epoch 2326/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1191 - val_loss: 1.1311\n",
      "Epoch 2327/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1316 - val_loss: 1.2464\n",
      "Epoch 2328/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1369 - val_loss: 1.1578\n",
      "Epoch 2329/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1264 - val_loss: 1.1807\n",
      "Epoch 2330/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1156 - val_loss: 1.1987\n",
      "Epoch 2331/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1168 - val_loss: 1.3254\n",
      "Epoch 2332/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1247 - val_loss: 1.1849\n",
      "Epoch 2333/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1325 - val_loss: 1.2243\n",
      "Epoch 2334/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1727 - val_loss: 1.1779\n",
      "Epoch 2335/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1430 - val_loss: 1.2965\n",
      "Epoch 2336/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1551 - val_loss: 1.1572\n",
      "Epoch 2337/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1569 - val_loss: 1.1496\n",
      "Epoch 2338/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1619 - val_loss: 1.2004\n",
      "Epoch 2339/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1517 - val_loss: 1.1527\n",
      "Epoch 2340/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1444 - val_loss: 1.2675\n",
      "Epoch 2341/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1649 - val_loss: 1.1791\n",
      "Epoch 2342/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1315 - val_loss: 1.3207\n",
      "Epoch 2343/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1478 - val_loss: 1.1734\n",
      "Epoch 2344/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1285 - val_loss: 1.2338\n",
      "Epoch 2345/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1466 - val_loss: 1.2358\n",
      "Epoch 2346/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1623 - val_loss: 1.2222\n",
      "Epoch 2347/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1520 - val_loss: 1.2949\n",
      "Epoch 2348/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1300 - val_loss: 1.2502\n",
      "Epoch 2349/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1962 - val_loss: 1.1704\n",
      "Epoch 2350/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1708 - val_loss: 1.1877\n",
      "Epoch 2351/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1575 - val_loss: 1.2008\n",
      "Epoch 2352/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1469 - val_loss: 1.2054\n",
      "Epoch 2353/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1776 - val_loss: 1.3851\n",
      "Epoch 2354/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1335 - val_loss: 1.2697\n",
      "Epoch 2355/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1174 - val_loss: 1.1648\n",
      "Epoch 2356/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1663 - val_loss: 1.2642\n",
      "Epoch 2357/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1632 - val_loss: 1.3106\n",
      "Epoch 2358/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1648 - val_loss: 1.1567\n",
      "Epoch 2359/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1481 - val_loss: 1.2712\n",
      "Epoch 2360/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2012 - val_loss: 1.2240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2361/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1561 - val_loss: 1.1700\n",
      "Epoch 2362/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1509 - val_loss: 1.2060\n",
      "Epoch 2363/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1254 - val_loss: 1.2287\n",
      "Epoch 2364/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1270 - val_loss: 1.2485\n",
      "Epoch 2365/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1562 - val_loss: 1.3233\n",
      "Epoch 2366/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1561 - val_loss: 1.1718\n",
      "Epoch 2367/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1583 - val_loss: 1.2375\n",
      "Epoch 2368/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1320 - val_loss: 1.2628\n",
      "Epoch 2369/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2160 - val_loss: 1.6173\n",
      "Epoch 2370/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1704 - val_loss: 1.1650\n",
      "Epoch 2371/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2323 - val_loss: 1.3569\n",
      "Epoch 2372/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1485 - val_loss: 1.1896\n",
      "Epoch 2373/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1798 - val_loss: 1.1764\n",
      "Epoch 2374/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1270 - val_loss: 1.2140\n",
      "Epoch 2375/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1825 - val_loss: 1.1974\n",
      "Epoch 2376/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1214 - val_loss: 1.2266\n",
      "Epoch 2377/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1561 - val_loss: 1.3179\n",
      "Epoch 2378/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1511 - val_loss: 1.1328\n",
      "Epoch 2379/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1332 - val_loss: 1.2122\n",
      "Epoch 2380/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1322 - val_loss: 1.2780\n",
      "Epoch 2381/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1285 - val_loss: 1.1664\n",
      "Epoch 2382/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1451 - val_loss: 1.1988\n",
      "Epoch 2383/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1853 - val_loss: 1.2174\n",
      "Epoch 2384/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1391 - val_loss: 1.1628\n",
      "Epoch 2385/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1540 - val_loss: 1.4824\n",
      "Epoch 2386/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1428 - val_loss: 1.4289\n",
      "Epoch 2387/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2605 - val_loss: 1.4494\n",
      "Epoch 2388/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1611 - val_loss: 1.2535\n",
      "Epoch 2389/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1733 - val_loss: 1.2171\n",
      "Epoch 2390/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2922 - val_loss: 1.3843\n",
      "Epoch 2391/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2129 - val_loss: 1.2083\n",
      "Epoch 2392/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1479 - val_loss: 1.2636\n",
      "Epoch 2393/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2032 - val_loss: 1.1845\n",
      "Epoch 2394/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1369 - val_loss: 1.2513\n",
      "Epoch 2395/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1474 - val_loss: 1.2025\n",
      "Epoch 2396/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1178 - val_loss: 1.4223\n",
      "Epoch 2397/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1529 - val_loss: 1.1887\n",
      "Epoch 2398/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1373 - val_loss: 1.2197\n",
      "Epoch 2399/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1550 - val_loss: 1.3739\n",
      "Epoch 2400/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1609 - val_loss: 1.1558\n",
      "Epoch 2401/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1785 - val_loss: 1.1755\n",
      "Epoch 2402/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.2066 - val_loss: 1.4069\n",
      "Epoch 2403/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2220 - val_loss: 1.2095\n",
      "Epoch 2404/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1695 - val_loss: 1.1782\n",
      "Epoch 2405/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1797 - val_loss: 1.5654\n",
      "Epoch 2406/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1908 - val_loss: 1.2088\n",
      "Epoch 2407/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1561 - val_loss: 1.3211\n",
      "Epoch 2408/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1338 - val_loss: 1.2205\n",
      "Epoch 2409/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1705 - val_loss: 1.1581\n",
      "Epoch 2410/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1455 - val_loss: 1.2370\n",
      "Epoch 2411/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1308 - val_loss: 1.2719\n",
      "Epoch 2412/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1308 - val_loss: 1.1643\n",
      "Epoch 2413/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1950 - val_loss: 1.2844\n",
      "Epoch 2414/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2035 - val_loss: 1.2198\n",
      "Epoch 2415/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2887 - val_loss: 1.2922\n",
      "Epoch 2416/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2260 - val_loss: 1.1827\n",
      "Epoch 2417/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1734 - val_loss: 1.2959\n",
      "Epoch 2418/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1531 - val_loss: 1.1538\n",
      "Epoch 2419/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1240 - val_loss: 1.1944\n",
      "Epoch 2420/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1325 - val_loss: 1.1946\n",
      "Epoch 2421/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1212 - val_loss: 1.3119\n",
      "Epoch 2422/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1216 - val_loss: 1.2179\n",
      "Epoch 2423/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1197 - val_loss: 1.2296\n",
      "Epoch 2424/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1362 - val_loss: 1.4370\n",
      "Epoch 2425/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2053 - val_loss: 1.1863\n",
      "Epoch 2426/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1452 - val_loss: 1.2458\n",
      "Epoch 2427/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1273 - val_loss: 1.1469\n",
      "Epoch 2428/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1768 - val_loss: 1.3601\n",
      "Epoch 2429/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1591 - val_loss: 1.1464\n",
      "Epoch 2430/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1329 - val_loss: 1.2971\n",
      "Epoch 2431/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1639 - val_loss: 1.3014\n",
      "Epoch 2432/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1763 - val_loss: 1.2733\n",
      "Epoch 2433/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1474 - val_loss: 1.2424\n",
      "Epoch 2434/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1430 - val_loss: 1.1586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2435/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1609 - val_loss: 1.2020\n",
      "Epoch 2436/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1197 - val_loss: 1.2388\n",
      "Epoch 2437/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1279 - val_loss: 1.1811\n",
      "Epoch 2438/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1074 - val_loss: 1.1653\n",
      "Epoch 2439/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1419 - val_loss: 1.5822\n",
      "Epoch 2440/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1963 - val_loss: 1.1500\n",
      "Epoch 2441/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2030 - val_loss: 1.2631\n",
      "Epoch 2442/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1291 - val_loss: 1.1634\n",
      "Epoch 2443/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1410 - val_loss: 1.1960\n",
      "Epoch 2444/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1381 - val_loss: 1.3253\n",
      "Epoch 2445/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1595 - val_loss: 1.1405\n",
      "Epoch 2446/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1658 - val_loss: 1.2285\n",
      "Epoch 2447/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1998 - val_loss: 1.1795\n",
      "Epoch 2448/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1466 - val_loss: 1.1574\n",
      "Epoch 2449/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1571 - val_loss: 1.1725\n",
      "Epoch 2450/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1264 - val_loss: 1.2471\n",
      "Epoch 2451/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1387 - val_loss: 1.1554\n",
      "Epoch 2452/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1582 - val_loss: 1.4330\n",
      "Epoch 2453/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1397 - val_loss: 1.1736\n",
      "Epoch 2454/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1424 - val_loss: 1.1951\n",
      "Epoch 2455/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1449 - val_loss: 1.1815\n",
      "Epoch 2456/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1482 - val_loss: 1.1230\n",
      "Epoch 2457/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1501 - val_loss: 1.2132\n",
      "Epoch 2458/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1678 - val_loss: 1.3326\n",
      "Epoch 2459/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1724 - val_loss: 1.2117\n",
      "Epoch 2460/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1288 - val_loss: 1.2427\n",
      "Epoch 2461/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1288 - val_loss: 1.1875\n",
      "Epoch 2462/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1139 - val_loss: 1.4445\n",
      "Epoch 2463/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1423 - val_loss: 1.2158\n",
      "Epoch 2464/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1566 - val_loss: 1.2997\n",
      "Epoch 2465/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1309 - val_loss: 1.1560\n",
      "Epoch 2466/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1406 - val_loss: 1.2676\n",
      "Epoch 2467/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1230 - val_loss: 1.2695\n",
      "Epoch 2468/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1521 - val_loss: 1.1739\n",
      "Epoch 2469/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1523 - val_loss: 1.2317\n",
      "Epoch 2470/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1280 - val_loss: 1.1490\n",
      "Epoch 2471/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1621 - val_loss: 1.2888\n",
      "Epoch 2472/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1359 - val_loss: 1.1985\n",
      "Epoch 2473/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1511 - val_loss: 1.5065\n",
      "Epoch 2474/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2562 - val_loss: 1.2078\n",
      "Epoch 2475/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1715 - val_loss: 1.3353\n",
      "Epoch 2476/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1518 - val_loss: 1.2741\n",
      "Epoch 2477/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1621 - val_loss: 1.2300\n",
      "Epoch 2478/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1342 - val_loss: 1.2944\n",
      "Epoch 2479/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1551 - val_loss: 1.2195\n",
      "Epoch 2480/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1595 - val_loss: 1.2652\n",
      "Epoch 2481/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1261 - val_loss: 1.1902\n",
      "Epoch 2482/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1629 - val_loss: 1.2250\n",
      "Epoch 2483/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1460 - val_loss: 1.2526\n",
      "Epoch 2484/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1545 - val_loss: 1.1402\n",
      "Epoch 2485/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1304 - val_loss: 1.1518\n",
      "Epoch 2486/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1483 - val_loss: 1.2009\n",
      "Epoch 2487/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1722 - val_loss: 1.2451\n",
      "Epoch 2488/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1572 - val_loss: 1.2062\n",
      "Epoch 2489/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1166 - val_loss: 1.2589\n",
      "Epoch 2490/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1145 - val_loss: 1.1787\n",
      "Epoch 2491/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1279 - val_loss: 1.1689\n",
      "Epoch 2492/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2053 - val_loss: 1.1803\n",
      "Epoch 2493/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2933 - val_loss: 1.3452\n",
      "Epoch 2494/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2269 - val_loss: 1.1993\n",
      "Epoch 2495/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2127 - val_loss: 1.3469\n",
      "Epoch 2496/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1456 - val_loss: 1.1417\n",
      "Epoch 2497/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1813 - val_loss: 1.1468\n",
      "Epoch 2498/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1686 - val_loss: 1.3469\n",
      "Epoch 2499/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1368 - val_loss: 1.1818\n",
      "Epoch 2500/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1305 - val_loss: 1.2371\n",
      "Epoch 2501/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1602 - val_loss: 1.1617\n",
      "Epoch 2502/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1449 - val_loss: 1.2228\n",
      "Epoch 2503/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1251 - val_loss: 1.1854\n",
      "Epoch 2504/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1597 - val_loss: 1.1577\n",
      "Epoch 2505/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1460 - val_loss: 1.1904\n",
      "Epoch 2506/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1684 - val_loss: 1.1749\n",
      "Epoch 2507/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1545 - val_loss: 1.1442\n",
      "Epoch 2508/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1874 - val_loss: 1.2141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2509/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2161 - val_loss: 1.2409\n",
      "Epoch 2510/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2227 - val_loss: 1.2744\n",
      "Epoch 2511/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2169 - val_loss: 1.2226\n",
      "Epoch 2512/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1944 - val_loss: 1.3174\n",
      "Epoch 2513/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1156 - val_loss: 1.1652\n",
      "Epoch 2514/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1456 - val_loss: 1.3225\n",
      "Epoch 2515/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1478 - val_loss: 1.3508\n",
      "Epoch 2516/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1491 - val_loss: 1.4107\n",
      "Epoch 2517/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.2168 - val_loss: 1.2155\n",
      "Epoch 2518/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1560 - val_loss: 1.1692\n",
      "Epoch 2519/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1323 - val_loss: 1.3284\n",
      "Epoch 2520/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1263 - val_loss: 1.1309\n",
      "Epoch 2521/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1348 - val_loss: 1.3390\n",
      "Epoch 2522/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1655 - val_loss: 1.1742\n",
      "Epoch 2523/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1607 - val_loss: 1.1961\n",
      "Epoch 2524/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1479 - val_loss: 1.1473\n",
      "Epoch 2525/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1624 - val_loss: 1.3095\n",
      "Epoch 2526/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1319 - val_loss: 1.2400\n",
      "Epoch 2527/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1437 - val_loss: 1.2674\n",
      "Epoch 2528/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1732 - val_loss: 1.1681\n",
      "Epoch 2529/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1288 - val_loss: 1.2001\n",
      "Epoch 2530/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1814 - val_loss: 1.1451\n",
      "Epoch 2531/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1378 - val_loss: 1.1846\n",
      "Epoch 2532/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1330 - val_loss: 1.1312\n",
      "Epoch 2533/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1182 - val_loss: 1.1750\n",
      "Epoch 2534/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2257 - val_loss: 1.2056\n",
      "Epoch 2535/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1676 - val_loss: 1.1278\n",
      "Epoch 2536/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1727 - val_loss: 1.2734\n",
      "Epoch 2537/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1146 - val_loss: 1.2116\n",
      "Epoch 2538/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1375 - val_loss: 1.1629\n",
      "Epoch 2539/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1461 - val_loss: 1.2147\n",
      "Epoch 2540/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1602 - val_loss: 1.2208\n",
      "Epoch 2541/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1414 - val_loss: 1.2428\n",
      "Epoch 2542/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1669 - val_loss: 1.2033\n",
      "Epoch 2543/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1231 - val_loss: 1.1416\n",
      "Epoch 2544/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1593 - val_loss: 1.2216\n",
      "Epoch 2545/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1658 - val_loss: 1.2105\n",
      "Epoch 2546/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1462 - val_loss: 1.2986\n",
      "Epoch 2547/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1500 - val_loss: 1.1587\n",
      "Epoch 2548/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1486 - val_loss: 1.4624\n",
      "Epoch 2549/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1432 - val_loss: 1.1337\n",
      "Epoch 2550/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1354 - val_loss: 1.1866\n",
      "Epoch 2551/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1834 - val_loss: 1.1688\n",
      "Epoch 2552/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1478 - val_loss: 1.1283\n",
      "Epoch 2553/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1288 - val_loss: 1.1575\n",
      "Epoch 2554/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1722 - val_loss: 1.2103\n",
      "Epoch 2555/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1255 - val_loss: 1.2306\n",
      "Epoch 2556/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1390 - val_loss: 1.1391\n",
      "Epoch 2557/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2055 - val_loss: 1.1874\n",
      "Epoch 2558/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1580 - val_loss: 1.4190\n",
      "Epoch 2559/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1556 - val_loss: 1.2678\n",
      "Epoch 2560/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1326 - val_loss: 1.2095\n",
      "Epoch 2561/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1524 - val_loss: 1.2249\n",
      "Epoch 2562/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2061 - val_loss: 1.1860\n",
      "Epoch 2563/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.2089 - val_loss: 1.2582\n",
      "Epoch 2564/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1281 - val_loss: 1.1698\n",
      "Epoch 2565/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1672 - val_loss: 1.1606\n",
      "Epoch 2566/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1630 - val_loss: 1.2653\n",
      "Epoch 2567/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2066 - val_loss: 1.2527\n",
      "Epoch 2568/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1881 - val_loss: 1.1799\n",
      "Epoch 2569/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1538 - val_loss: 1.2161\n",
      "Epoch 2570/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1624 - val_loss: 1.1967\n",
      "Epoch 2571/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1375 - val_loss: 1.1876\n",
      "Epoch 2572/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1300 - val_loss: 1.1817\n",
      "Epoch 2573/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1232 - val_loss: 1.1755\n",
      "Epoch 2574/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2693 - val_loss: 1.5633\n",
      "Epoch 2575/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2103 - val_loss: 1.2530\n",
      "Epoch 2576/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1455 - val_loss: 1.1707\n",
      "Epoch 2577/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1310 - val_loss: 1.2527\n",
      "Epoch 2578/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1262 - val_loss: 1.1590\n",
      "Epoch 2579/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1537 - val_loss: 1.2579\n",
      "Epoch 2580/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1338 - val_loss: 1.4034\n",
      "Epoch 2581/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1662 - val_loss: 1.1572\n",
      "Epoch 2582/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1299 - val_loss: 1.1771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2583/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1491 - val_loss: 1.1345\n",
      "Epoch 2584/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1158 - val_loss: 1.2463\n",
      "Epoch 2585/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1505 - val_loss: 1.2171\n",
      "Epoch 2586/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2385 - val_loss: 1.2863\n",
      "Epoch 2587/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1696 - val_loss: 1.2148\n",
      "Epoch 2588/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1931 - val_loss: 1.4895\n",
      "Epoch 2589/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1479 - val_loss: 1.2090\n",
      "Epoch 2590/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1333 - val_loss: 1.1639\n",
      "Epoch 2591/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1441 - val_loss: 1.2008\n",
      "Epoch 2592/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1681 - val_loss: 1.2752\n",
      "Epoch 2593/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1725 - val_loss: 1.2377\n",
      "Epoch 2594/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1562 - val_loss: 1.1593\n",
      "Epoch 2595/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1206 - val_loss: 1.2398\n",
      "Epoch 2596/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1298 - val_loss: 1.1751\n",
      "Epoch 2597/20000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 1.262 - 0s 23us/sample - loss: 1.1407 - val_loss: 1.1387\n",
      "Epoch 2598/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1368 - val_loss: 1.2454\n",
      "Epoch 2599/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1413 - val_loss: 1.1639\n",
      "Epoch 2600/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1290 - val_loss: 1.2278\n",
      "Epoch 2601/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1913 - val_loss: 1.1890\n",
      "Epoch 2602/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1863 - val_loss: 1.2055\n",
      "Epoch 2603/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1657 - val_loss: 1.2862\n",
      "Epoch 2604/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1284 - val_loss: 1.1856\n",
      "Epoch 2605/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1234 - val_loss: 1.1896\n",
      "Epoch 2606/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1583 - val_loss: 1.2968\n",
      "Epoch 2607/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2113 - val_loss: 1.2046\n",
      "Epoch 2608/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1192 - val_loss: 1.2018\n",
      "Epoch 2609/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1558 - val_loss: 1.1534\n",
      "Epoch 2610/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1365 - val_loss: 1.2034\n",
      "Epoch 2611/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1434 - val_loss: 1.2060\n",
      "Epoch 2612/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1474 - val_loss: 1.3078\n",
      "Epoch 2613/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1591 - val_loss: 1.2033\n",
      "Epoch 2614/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1755 - val_loss: 1.5304\n",
      "Epoch 2615/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1946 - val_loss: 1.2573\n",
      "Epoch 2616/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1886 - val_loss: 1.1631\n",
      "Epoch 2617/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1679 - val_loss: 1.2457\n",
      "Epoch 2618/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1221 - val_loss: 1.1346\n",
      "Epoch 2619/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1165 - val_loss: 1.1926\n",
      "Epoch 2620/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1569 - val_loss: 1.4418\n",
      "Epoch 2621/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1556 - val_loss: 1.1893\n",
      "Epoch 2622/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1257 - val_loss: 1.4058\n",
      "Epoch 2623/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1563 - val_loss: 1.7376\n",
      "Epoch 2624/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2339 - val_loss: 1.2154\n",
      "Epoch 2625/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1731 - val_loss: 1.3325\n",
      "Epoch 2626/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1662 - val_loss: 1.1277\n",
      "Epoch 2627/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1222 - val_loss: 1.2373\n",
      "Epoch 2628/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1310 - val_loss: 1.2318\n",
      "Epoch 2629/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1694 - val_loss: 1.3185\n",
      "Epoch 2630/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1803 - val_loss: 1.1912\n",
      "Epoch 2631/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1501 - val_loss: 1.2023\n",
      "Epoch 2632/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1563 - val_loss: 1.1865\n",
      "Epoch 2633/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1566 - val_loss: 1.2949\n",
      "Epoch 2634/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1698 - val_loss: 1.3103\n",
      "Epoch 2635/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1687 - val_loss: 1.2778\n",
      "Epoch 2636/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1516 - val_loss: 1.2199\n",
      "Epoch 2637/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1570 - val_loss: 1.1833\n",
      "Epoch 2638/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1471 - val_loss: 1.1672\n",
      "Epoch 2639/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1437 - val_loss: 1.2358\n",
      "Epoch 2640/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1318 - val_loss: 1.2197\n",
      "Epoch 2641/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1481 - val_loss: 1.2121\n",
      "Epoch 2642/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1873 - val_loss: 1.2117\n",
      "Epoch 2643/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1494 - val_loss: 1.2080\n",
      "Epoch 2644/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1327 - val_loss: 1.2775\n",
      "Epoch 2645/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1619 - val_loss: 1.1445\n",
      "Epoch 2646/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.2156 - val_loss: 1.4408\n",
      "Epoch 2647/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.2106 - val_loss: 1.2363\n",
      "Epoch 2648/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1380 - val_loss: 1.3133\n",
      "Epoch 2649/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1698 - val_loss: 1.1948\n",
      "Epoch 2650/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1394 - val_loss: 1.1708\n",
      "Epoch 2651/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2076 - val_loss: 1.2327\n",
      "Epoch 2652/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1374 - val_loss: 1.2256\n",
      "Epoch 2653/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1675 - val_loss: 1.3088\n",
      "Epoch 2654/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1406 - val_loss: 1.3707\n",
      "Epoch 2655/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2032 - val_loss: 1.1812\n",
      "Epoch 2656/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1436 - val_loss: 1.1889\n",
      "Epoch 2657/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2104 - val_loss: 1.2057\n",
      "Epoch 2658/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1620 - val_loss: 1.1770\n",
      "Epoch 2659/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1361 - val_loss: 1.2394\n",
      "Epoch 2660/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1739 - val_loss: 1.3101\n",
      "Epoch 2661/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1467 - val_loss: 1.1479\n",
      "Epoch 2662/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1819 - val_loss: 1.2209\n",
      "Epoch 2663/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1696 - val_loss: 1.2099\n",
      "Epoch 2664/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2101 - val_loss: 1.2397\n",
      "Epoch 2665/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2708 - val_loss: 1.1892\n",
      "Epoch 2666/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2030 - val_loss: 1.1724\n",
      "Epoch 2667/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1660 - val_loss: 1.3910\n",
      "Epoch 2668/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2696 - val_loss: 1.3646\n",
      "Epoch 2669/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1596 - val_loss: 1.1667\n",
      "Epoch 2670/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1319 - val_loss: 1.1757\n",
      "Epoch 2671/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1459 - val_loss: 1.2437\n",
      "Epoch 2672/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1139 - val_loss: 1.2333\n",
      "Epoch 2673/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1530 - val_loss: 1.2896\n",
      "Epoch 2674/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1795 - val_loss: 1.1137\n",
      "Epoch 2675/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1322 - val_loss: 1.3632\n",
      "Epoch 2676/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1993 - val_loss: 1.1870\n",
      "Epoch 2677/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1543 - val_loss: 1.2901\n",
      "Epoch 2678/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1884 - val_loss: 1.1694\n",
      "Epoch 2679/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2523 - val_loss: 1.6713\n",
      "Epoch 2680/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.3283 - val_loss: 1.1604\n",
      "Epoch 2681/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2476 - val_loss: 1.2053\n",
      "Epoch 2682/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1833 - val_loss: 1.2081\n",
      "Epoch 2683/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1658 - val_loss: 1.2025\n",
      "Epoch 2684/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1551 - val_loss: 1.1381\n",
      "Epoch 2685/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2129 - val_loss: 1.2452\n",
      "Epoch 2686/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1522 - val_loss: 1.1883\n",
      "Epoch 2687/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1354 - val_loss: 1.2201\n",
      "Epoch 2688/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1105 - val_loss: 1.2384\n",
      "Epoch 2689/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1419 - val_loss: 1.3100\n",
      "Epoch 2690/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1624 - val_loss: 1.1716\n",
      "Epoch 2691/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1398 - val_loss: 1.2571\n",
      "Epoch 2692/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1390 - val_loss: 1.1966\n",
      "Epoch 2693/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1320 - val_loss: 1.2137\n",
      "Epoch 2694/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1737 - val_loss: 1.1660\n",
      "Epoch 2695/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1335 - val_loss: 1.1770\n",
      "Epoch 2696/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1391 - val_loss: 1.1942\n",
      "Epoch 2697/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1137 - val_loss: 1.2831\n",
      "Epoch 2698/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1147 - val_loss: 1.1452\n",
      "Epoch 2699/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1916 - val_loss: 1.5400\n",
      "Epoch 2700/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1383 - val_loss: 1.1796\n",
      "Epoch 2701/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1290 - val_loss: 1.2725\n",
      "Epoch 2702/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1393 - val_loss: 1.4127\n",
      "Epoch 2703/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1690 - val_loss: 1.2628\n",
      "Epoch 2704/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1364 - val_loss: 1.2113\n",
      "Epoch 2705/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1369 - val_loss: 1.2992\n",
      "Epoch 2706/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1416 - val_loss: 1.1670\n",
      "Epoch 2707/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1271 - val_loss: 1.1813\n",
      "Epoch 2708/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1327 - val_loss: 1.2085\n",
      "Epoch 2709/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1535 - val_loss: 1.2362\n",
      "Epoch 2710/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1514 - val_loss: 1.1970\n",
      "Epoch 2711/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1637 - val_loss: 1.3195\n",
      "Epoch 2712/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1578 - val_loss: 1.2087\n",
      "Epoch 2713/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1401 - val_loss: 1.2518\n",
      "Epoch 2714/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1370 - val_loss: 1.1806\n",
      "Epoch 2715/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2552 - val_loss: 1.1644\n",
      "Epoch 2716/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1632 - val_loss: 1.2574\n",
      "Epoch 2717/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1312 - val_loss: 1.4674\n",
      "Epoch 2718/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1475 - val_loss: 1.2640\n",
      "Epoch 2719/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1288 - val_loss: 1.1648\n",
      "Epoch 2720/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1457 - val_loss: 1.3041\n",
      "Epoch 2721/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1690 - val_loss: 1.1875\n",
      "Epoch 2722/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1434 - val_loss: 1.2179\n",
      "Epoch 2723/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1526 - val_loss: 1.2136\n",
      "Epoch 2724/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1322 - val_loss: 1.2443\n",
      "Epoch 2725/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1352 - val_loss: 1.2044\n",
      "Epoch 2726/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1595 - val_loss: 1.2783\n",
      "Epoch 2727/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1707 - val_loss: 1.1701\n",
      "Epoch 2728/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1446 - val_loss: 1.3024\n",
      "Epoch 2729/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1409 - val_loss: 1.2352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2730/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1432 - val_loss: 1.3283\n",
      "Epoch 2731/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1478 - val_loss: 1.1806\n",
      "Epoch 2732/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1404 - val_loss: 1.2655\n",
      "Epoch 2733/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1269 - val_loss: 1.1815\n",
      "Epoch 2734/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1311 - val_loss: 1.3171\n",
      "Epoch 2735/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.3003 - val_loss: 1.4331\n",
      "Epoch 2736/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1547 - val_loss: 1.2163\n",
      "Epoch 2737/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1503 - val_loss: 1.1652\n",
      "Epoch 2738/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1778 - val_loss: 1.2119\n",
      "Epoch 2739/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1448 - val_loss: 1.1671\n",
      "Epoch 2740/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1570 - val_loss: 1.1574\n",
      "Epoch 2741/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1701 - val_loss: 1.1666\n",
      "Epoch 2742/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1278 - val_loss: 1.1604\n",
      "Epoch 2743/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1499 - val_loss: 1.1770\n",
      "Epoch 2744/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1416 - val_loss: 1.2229\n",
      "Epoch 2745/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1260 - val_loss: 1.1408\n",
      "Epoch 2746/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1286 - val_loss: 1.5284\n",
      "Epoch 2747/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1709 - val_loss: 1.2216\n",
      "Epoch 2748/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2219 - val_loss: 1.2462\n",
      "Epoch 2749/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1974 - val_loss: 1.2810\n",
      "Epoch 2750/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2104 - val_loss: 1.4130\n",
      "Epoch 2751/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2006 - val_loss: 1.2347\n",
      "Epoch 2752/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1384 - val_loss: 1.4020\n",
      "Epoch 2753/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1650 - val_loss: 1.2251\n",
      "Epoch 2754/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1628 - val_loss: 1.3122\n",
      "Epoch 2755/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1449 - val_loss: 1.2259\n",
      "Epoch 2756/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2040 - val_loss: 1.3038\n",
      "Epoch 2757/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1329 - val_loss: 1.3042\n",
      "Epoch 2758/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1406 - val_loss: 1.3490\n",
      "Epoch 2759/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1477 - val_loss: 1.1729\n",
      "Epoch 2760/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1870 - val_loss: 1.2385\n",
      "Epoch 2761/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1674 - val_loss: 1.1999\n",
      "Epoch 2762/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1455 - val_loss: 1.1829\n",
      "Epoch 2763/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1480 - val_loss: 1.1646\n",
      "Epoch 2764/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1334 - val_loss: 1.2096\n",
      "Epoch 2765/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1572 - val_loss: 1.3379\n",
      "Epoch 2766/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1583 - val_loss: 1.2070\n",
      "Epoch 2767/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1419 - val_loss: 1.2570\n",
      "Epoch 2768/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1233 - val_loss: 1.3033\n",
      "Epoch 2769/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1636 - val_loss: 1.1523\n",
      "Epoch 2770/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1806 - val_loss: 1.1931\n",
      "Epoch 2771/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1642 - val_loss: 1.1389\n",
      "Epoch 2772/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1370 - val_loss: 1.2442\n",
      "Epoch 2773/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1186 - val_loss: 1.1640\n",
      "Epoch 2774/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1450 - val_loss: 1.1557\n",
      "Epoch 2775/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1655 - val_loss: 1.2949\n",
      "Epoch 2776/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1453 - val_loss: 1.3055\n",
      "Epoch 2777/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1502 - val_loss: 1.1599\n",
      "Epoch 2778/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1155 - val_loss: 1.1368\n",
      "Epoch 2779/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2012 - val_loss: 1.1862\n",
      "Epoch 2780/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1429 - val_loss: 1.2151\n",
      "Epoch 2781/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1517 - val_loss: 1.3409\n",
      "Epoch 2782/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1681 - val_loss: 1.3417\n",
      "Epoch 2783/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1482 - val_loss: 1.2154\n",
      "Epoch 2784/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1570 - val_loss: 1.3066\n",
      "Epoch 2785/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1322 - val_loss: 1.3995\n",
      "Epoch 2786/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1324 - val_loss: 1.1977\n",
      "Epoch 2787/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1617 - val_loss: 1.3495\n",
      "Epoch 2788/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1827 - val_loss: 1.1584\n",
      "Epoch 2789/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1688 - val_loss: 1.3124\n",
      "Epoch 2790/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1707 - val_loss: 1.2702\n",
      "Epoch 2791/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1717 - val_loss: 1.1951\n",
      "Epoch 2792/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1849 - val_loss: 1.3466\n",
      "Epoch 2793/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1433 - val_loss: 1.1099\n",
      "Epoch 2794/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1235 - val_loss: 1.2929\n",
      "Epoch 2795/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1476 - val_loss: 1.2192\n",
      "Epoch 2796/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1611 - val_loss: 1.4501\n",
      "Epoch 2797/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1669 - val_loss: 1.1530\n",
      "Epoch 2798/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1840 - val_loss: 1.3623\n",
      "Epoch 2799/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1432 - val_loss: 1.2318\n",
      "Epoch 2800/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1203 - val_loss: 1.2037\n",
      "Epoch 2801/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1511 - val_loss: 1.1803\n",
      "Epoch 2802/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1465 - val_loss: 1.1631\n",
      "Epoch 2803/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1228 - val_loss: 1.2505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2804/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1286 - val_loss: 1.2865\n",
      "Epoch 2805/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1416 - val_loss: 1.2026\n",
      "Epoch 2806/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1337 - val_loss: 1.1811\n",
      "Epoch 2807/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1661 - val_loss: 1.1938\n",
      "Epoch 2808/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1273 - val_loss: 1.2139\n",
      "Epoch 2809/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1567 - val_loss: 1.1708\n",
      "Epoch 2810/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1435 - val_loss: 1.1399\n",
      "Epoch 2811/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1172 - val_loss: 1.1636\n",
      "Epoch 2812/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1321 - val_loss: 1.1980\n",
      "Epoch 2813/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1385 - val_loss: 1.1773\n",
      "Epoch 2814/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1596 - val_loss: 1.1912\n",
      "Epoch 2815/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1404 - val_loss: 1.2379\n",
      "Epoch 2816/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1271 - val_loss: 1.1425\n",
      "Epoch 2817/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2028 - val_loss: 1.2848\n",
      "Epoch 2818/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1546 - val_loss: 1.3988\n",
      "Epoch 2819/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1871 - val_loss: 1.1697\n",
      "Epoch 2820/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1678 - val_loss: 1.2367\n",
      "Epoch 2821/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1544 - val_loss: 1.1738\n",
      "Epoch 2822/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1180 - val_loss: 1.1524\n",
      "Epoch 2823/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1327 - val_loss: 1.2244\n",
      "Epoch 2824/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1576 - val_loss: 1.2333\n",
      "Epoch 2825/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2569 - val_loss: 1.1925\n",
      "Epoch 2826/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1632 - val_loss: 1.1583\n",
      "Epoch 2827/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1692 - val_loss: 1.1496\n",
      "Epoch 2828/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1422 - val_loss: 1.1353\n",
      "Epoch 2829/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1258 - val_loss: 1.3433\n",
      "Epoch 2830/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1759 - val_loss: 1.3039\n",
      "Epoch 2831/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1850 - val_loss: 1.1460\n",
      "Epoch 2832/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1383 - val_loss: 1.3428\n",
      "Epoch 2833/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1609 - val_loss: 1.1511\n",
      "Epoch 2834/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1377 - val_loss: 1.1372\n",
      "Epoch 2835/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1363 - val_loss: 1.2531\n",
      "Epoch 2836/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1260 - val_loss: 1.2018\n",
      "Epoch 2837/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1563 - val_loss: 1.1786\n",
      "Epoch 2838/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1374 - val_loss: 1.3173\n",
      "Epoch 2839/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1930 - val_loss: 1.3914\n",
      "Epoch 2840/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1974 - val_loss: 1.1779\n",
      "Epoch 2841/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1391 - val_loss: 1.2577\n",
      "Epoch 2842/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1699 - val_loss: 1.3508\n",
      "Epoch 2843/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1542 - val_loss: 1.2282\n",
      "Epoch 2844/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1245 - val_loss: 1.2238\n",
      "Epoch 2845/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1592 - val_loss: 1.3213\n",
      "Epoch 2846/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1365 - val_loss: 1.2812\n",
      "Epoch 2847/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1251 - val_loss: 1.2914\n",
      "Epoch 2848/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2270 - val_loss: 1.2889\n",
      "Epoch 2849/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1876 - val_loss: 1.2159\n",
      "Epoch 2850/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1820 - val_loss: 1.3192\n",
      "Epoch 2851/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1644 - val_loss: 1.2877\n",
      "Epoch 2852/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1922 - val_loss: 1.3094\n",
      "Epoch 2853/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1650 - val_loss: 1.2542\n",
      "Epoch 2854/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1606 - val_loss: 1.1632\n",
      "Epoch 2855/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1823 - val_loss: 1.1978\n",
      "Epoch 2856/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1817 - val_loss: 1.4644\n",
      "Epoch 2857/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1718 - val_loss: 1.2247\n",
      "Epoch 2858/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1392 - val_loss: 1.1380\n",
      "Epoch 2859/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1569 - val_loss: 1.1679\n",
      "Epoch 2860/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1291 - val_loss: 1.1843\n",
      "Epoch 2861/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1664 - val_loss: 1.1860\n",
      "Epoch 2862/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1769 - val_loss: 1.4976\n",
      "Epoch 2863/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2693 - val_loss: 1.1666\n",
      "Epoch 2864/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1303 - val_loss: 1.2057\n",
      "Epoch 2865/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1233 - val_loss: 1.3586\n",
      "Epoch 2866/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1480 - val_loss: 1.1785\n",
      "Epoch 2867/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1348 - val_loss: 1.4151\n",
      "Epoch 2868/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1686 - val_loss: 1.1858\n",
      "Epoch 2869/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1212 - val_loss: 1.1576\n",
      "Epoch 2870/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1666 - val_loss: 1.2179\n",
      "Epoch 2871/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1695 - val_loss: 1.1836\n",
      "Epoch 2872/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1320 - val_loss: 1.2273\n",
      "Epoch 2873/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1337 - val_loss: 1.2876\n",
      "Epoch 2874/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1859 - val_loss: 1.3355\n",
      "Epoch 2875/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1560 - val_loss: 1.1330\n",
      "Epoch 2876/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1415 - val_loss: 1.3471\n",
      "Epoch 2877/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1410 - val_loss: 1.1976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2878/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1504 - val_loss: 1.3383\n",
      "Epoch 2879/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1773 - val_loss: 1.1889\n",
      "Epoch 2880/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1671 - val_loss: 1.3178\n",
      "Epoch 2881/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1361 - val_loss: 1.1862\n",
      "Epoch 2882/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1589 - val_loss: 1.2395\n",
      "Epoch 2883/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1384 - val_loss: 1.3372\n",
      "Epoch 2884/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1268 - val_loss: 1.2920\n",
      "Epoch 2885/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1674 - val_loss: 1.3477\n",
      "Epoch 2886/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2443 - val_loss: 1.1761\n",
      "Epoch 2887/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1582 - val_loss: 1.2679\n",
      "Epoch 2888/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1290 - val_loss: 1.2004\n",
      "Epoch 2889/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1460 - val_loss: 1.1118\n",
      "Epoch 2890/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1413 - val_loss: 1.1632\n",
      "Epoch 2891/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1843 - val_loss: 1.1842\n",
      "Epoch 2892/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1601 - val_loss: 1.4123\n",
      "Epoch 2893/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1527 - val_loss: 1.1565\n",
      "Epoch 2894/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1341 - val_loss: 1.2365\n",
      "Epoch 2895/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1402 - val_loss: 1.2491\n",
      "Epoch 2896/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1466 - val_loss: 1.1599\n",
      "Epoch 2897/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1197 - val_loss: 1.2709\n",
      "Epoch 2898/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1185 - val_loss: 1.1907\n",
      "Epoch 2899/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1229 - val_loss: 1.1811\n",
      "Epoch 2900/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1321 - val_loss: 1.1469\n",
      "Epoch 2901/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1853 - val_loss: 1.4347\n",
      "Epoch 2902/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2201 - val_loss: 1.1940\n",
      "Epoch 2903/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1376 - val_loss: 1.1914\n",
      "Epoch 2904/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1542 - val_loss: 1.2166\n",
      "Epoch 2905/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1685 - val_loss: 1.3091\n",
      "Epoch 2906/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1411 - val_loss: 1.4898\n",
      "Epoch 2907/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1452 - val_loss: 1.4336\n",
      "Epoch 2908/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1777 - val_loss: 1.1919\n",
      "Epoch 2909/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1490 - val_loss: 1.2101\n",
      "Epoch 2910/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1750 - val_loss: 1.1486\n",
      "Epoch 2911/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1423 - val_loss: 1.4505\n",
      "Epoch 2912/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1793 - val_loss: 1.2348\n",
      "Epoch 2913/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1775 - val_loss: 1.2469\n",
      "Epoch 2914/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1402 - val_loss: 1.1508\n",
      "Epoch 2915/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2001 - val_loss: 1.3529\n",
      "Epoch 2916/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1638 - val_loss: 1.3617\n",
      "Epoch 2917/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1727 - val_loss: 1.1556\n",
      "Epoch 2918/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1568 - val_loss: 1.1635\n",
      "Epoch 2919/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1545 - val_loss: 1.1842\n",
      "Epoch 2920/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1749 - val_loss: 1.5426\n",
      "Epoch 2921/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.2067 - val_loss: 1.1710\n",
      "Epoch 2922/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1594 - val_loss: 1.2769\n",
      "Epoch 2923/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1315 - val_loss: 1.1809\n",
      "Epoch 2924/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1550 - val_loss: 1.1597\n",
      "Epoch 2925/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1364 - val_loss: 1.1794\n",
      "Epoch 2926/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1277 - val_loss: 1.1592\n",
      "Epoch 2927/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1494 - val_loss: 1.3179\n",
      "Epoch 2928/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1640 - val_loss: 1.4202\n",
      "Epoch 2929/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1598 - val_loss: 1.3645\n",
      "Epoch 2930/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1334 - val_loss: 1.1806\n",
      "Epoch 2931/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1365 - val_loss: 1.1358\n",
      "Epoch 2932/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1395 - val_loss: 1.3021\n",
      "Epoch 2933/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1732 - val_loss: 1.2008\n",
      "Epoch 2934/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1679 - val_loss: 1.1602\n",
      "Epoch 2935/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1517 - val_loss: 1.3520\n",
      "Epoch 2936/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1511 - val_loss: 1.1668\n",
      "Epoch 2937/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1345 - val_loss: 1.1942\n",
      "Epoch 2938/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1858 - val_loss: 1.2868\n",
      "Epoch 2939/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1320 - val_loss: 1.2305\n",
      "Epoch 2940/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1312 - val_loss: 1.2655\n",
      "Epoch 2941/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1449 - val_loss: 1.1571\n",
      "Epoch 2942/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1326 - val_loss: 1.3421\n",
      "Epoch 2943/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1534 - val_loss: 1.2579\n",
      "Epoch 2944/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1404 - val_loss: 1.2071\n",
      "Epoch 2945/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1948 - val_loss: 1.1362\n",
      "Epoch 2946/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1223 - val_loss: 1.2955\n",
      "Epoch 2947/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1460 - val_loss: 1.1472\n",
      "Epoch 2948/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1712 - val_loss: 1.2706\n",
      "Epoch 2949/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1307 - val_loss: 1.1764\n",
      "Epoch 2950/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1962 - val_loss: 1.5226\n",
      "Epoch 2951/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1344 - val_loss: 1.1296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2952/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1577 - val_loss: 1.2025\n",
      "Epoch 2953/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1500 - val_loss: 1.2186\n",
      "Epoch 2954/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1698 - val_loss: 1.1778\n",
      "Epoch 2955/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1776 - val_loss: 1.3038\n",
      "Epoch 2956/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1357 - val_loss: 1.2716\n",
      "Epoch 2957/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1792 - val_loss: 1.2606\n",
      "Epoch 2958/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1212 - val_loss: 1.1749\n",
      "Epoch 2959/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1306 - val_loss: 1.4703\n",
      "Epoch 2960/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1665 - val_loss: 1.1687\n",
      "Epoch 2961/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1397 - val_loss: 1.1792\n",
      "Epoch 2962/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1136 - val_loss: 1.2118\n",
      "Epoch 2963/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1304 - val_loss: 1.2334\n",
      "Epoch 2964/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1345 - val_loss: 1.1974\n",
      "Epoch 2965/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1365 - val_loss: 1.1860\n",
      "Epoch 2966/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1547 - val_loss: 1.1665\n",
      "Epoch 2967/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1603 - val_loss: 1.2780\n",
      "Epoch 2968/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1633 - val_loss: 1.2103\n",
      "Epoch 2969/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1312 - val_loss: 1.1785\n",
      "Epoch 2970/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1199 - val_loss: 1.5934\n",
      "Epoch 2971/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1827 - val_loss: 1.2002\n",
      "Epoch 2972/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2147 - val_loss: 1.6236\n",
      "Epoch 2973/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1795 - val_loss: 1.2720\n",
      "Epoch 2974/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1482 - val_loss: 1.4985\n",
      "Epoch 2975/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1420 - val_loss: 1.3948\n",
      "Epoch 2976/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2463 - val_loss: 1.2324\n",
      "Epoch 2977/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2027 - val_loss: 1.3554\n",
      "Epoch 2978/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1525 - val_loss: 1.2383\n",
      "Epoch 2979/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1257 - val_loss: 1.1708\n",
      "Epoch 2980/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1659 - val_loss: 1.2963\n",
      "Epoch 2981/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1493 - val_loss: 1.1358\n",
      "Epoch 2982/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1238 - val_loss: 1.2135\n",
      "Epoch 2983/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2151 - val_loss: 1.3507\n",
      "Epoch 2984/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1369 - val_loss: 1.2804\n",
      "Epoch 2985/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1362 - val_loss: 1.1636\n",
      "Epoch 2986/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1793 - val_loss: 1.4356\n",
      "Epoch 2987/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1430 - val_loss: 1.1961\n",
      "Epoch 2988/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1506 - val_loss: 1.3328\n",
      "Epoch 2989/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1417 - val_loss: 1.1978\n",
      "Epoch 2990/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1577 - val_loss: 1.2120\n",
      "Epoch 2991/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1816 - val_loss: 1.2601\n",
      "Epoch 2992/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1656 - val_loss: 1.3267\n",
      "Epoch 2993/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1537 - val_loss: 1.1486\n",
      "Epoch 2994/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1377 - val_loss: 1.1667\n",
      "Epoch 2995/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2343 - val_loss: 1.1869\n",
      "Epoch 2996/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1340 - val_loss: 1.2506\n",
      "Epoch 2997/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1346 - val_loss: 1.3036\n",
      "Epoch 2998/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1242 - val_loss: 1.2143\n",
      "Epoch 2999/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1251 - val_loss: 1.2405\n",
      "Epoch 3000/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1217 - val_loss: 1.1961\n",
      "Epoch 3001/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.2000 - val_loss: 1.2210\n",
      "Epoch 3002/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1718 - val_loss: 1.2290\n",
      "Epoch 3003/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1551 - val_loss: 1.2196\n",
      "Epoch 3004/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1674 - val_loss: 1.3016\n",
      "Epoch 3005/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1693 - val_loss: 1.4964\n",
      "Epoch 3006/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2079 - val_loss: 1.1631\n",
      "Epoch 3007/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1359 - val_loss: 1.1810\n",
      "Epoch 3008/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1703 - val_loss: 1.2087\n",
      "Epoch 3009/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1477 - val_loss: 1.1704\n",
      "Epoch 3010/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1692 - val_loss: 1.1978\n",
      "Epoch 3011/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2003 - val_loss: 1.4538\n",
      "Epoch 3012/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1594 - val_loss: 1.3326\n",
      "Epoch 3013/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1867 - val_loss: 1.1920\n",
      "Epoch 3014/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1097 - val_loss: 1.3057\n",
      "Epoch 3015/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1398 - val_loss: 1.1735\n",
      "Epoch 3016/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1385 - val_loss: 1.2290\n",
      "Epoch 3017/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1480 - val_loss: 1.3140\n",
      "Epoch 3018/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1496 - val_loss: 1.2278\n",
      "Epoch 3019/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1305 - val_loss: 1.1786\n",
      "Epoch 3020/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1432 - val_loss: 1.2323\n",
      "Epoch 3021/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1612 - val_loss: 1.3083\n",
      "Epoch 3022/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1438 - val_loss: 1.2995\n",
      "Epoch 3023/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1962 - val_loss: 1.1741\n",
      "Epoch 3024/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1456 - val_loss: 1.2100\n",
      "Epoch 3025/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1342 - val_loss: 1.1384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3026/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1831 - val_loss: 1.2659\n",
      "Epoch 3027/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1492 - val_loss: 1.1203\n",
      "Epoch 3028/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1221 - val_loss: 1.1826\n",
      "Epoch 3029/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1222 - val_loss: 1.1539\n",
      "Epoch 3030/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1770 - val_loss: 1.3319\n",
      "Epoch 3031/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1668 - val_loss: 1.1926\n",
      "Epoch 3032/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1366 - val_loss: 1.1789\n",
      "Epoch 3033/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1395 - val_loss: 1.2500\n",
      "Epoch 3034/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1455 - val_loss: 1.2485\n",
      "Epoch 3035/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1222 - val_loss: 1.2243\n",
      "Epoch 3036/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1605 - val_loss: 1.4104\n",
      "Epoch 3037/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1647 - val_loss: 1.1755\n",
      "Epoch 3038/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1983 - val_loss: 1.2414\n",
      "Epoch 3039/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1271 - val_loss: 1.1961\n",
      "Epoch 3040/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2072 - val_loss: 1.3424\n",
      "Epoch 3041/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1330 - val_loss: 1.1719\n",
      "Epoch 3042/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1317 - val_loss: 1.1787\n",
      "Epoch 3043/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1654 - val_loss: 1.1404\n",
      "Epoch 3044/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2063 - val_loss: 1.2526\n",
      "Epoch 3045/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1626 - val_loss: 1.1503\n",
      "Epoch 3046/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1744 - val_loss: 1.2439\n",
      "Epoch 3047/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1900 - val_loss: 1.2242\n",
      "Epoch 3048/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1821 - val_loss: 1.1574\n",
      "Epoch 3049/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1486 - val_loss: 1.2598\n",
      "Epoch 3050/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1248 - val_loss: 1.2454\n",
      "Epoch 3051/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1283 - val_loss: 1.3577\n",
      "Epoch 3052/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1624 - val_loss: 1.2486\n",
      "Epoch 3053/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1319 - val_loss: 1.1770\n",
      "Epoch 3054/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1803 - val_loss: 1.1396\n",
      "Epoch 3055/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2224 - val_loss: 1.2243\n",
      "Epoch 3056/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1651 - val_loss: 1.1967\n",
      "Epoch 3057/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2174 - val_loss: 1.1797\n",
      "Epoch 3058/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1570 - val_loss: 1.2549\n",
      "Epoch 3059/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1294 - val_loss: 1.2242\n",
      "Epoch 3060/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1249 - val_loss: 1.1549\n",
      "Epoch 3061/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1648 - val_loss: 1.2762\n",
      "Epoch 3062/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1478 - val_loss: 1.2374\n",
      "Epoch 3063/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1710 - val_loss: 1.1251\n",
      "Epoch 3064/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1694 - val_loss: 1.1385\n",
      "Epoch 3065/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1419 - val_loss: 1.2051\n",
      "Epoch 3066/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1608 - val_loss: 1.2294\n",
      "Epoch 3067/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1600 - val_loss: 1.2321\n",
      "Epoch 3068/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1599 - val_loss: 1.1283\n",
      "Epoch 3069/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1427 - val_loss: 1.3646\n",
      "Epoch 3070/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1336 - val_loss: 1.1735\n",
      "Epoch 3071/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1361 - val_loss: 1.1678\n",
      "Epoch 3072/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1481 - val_loss: 1.2187\n",
      "Epoch 3073/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1585 - val_loss: 1.1348\n",
      "Epoch 3074/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1526 - val_loss: 1.5194\n",
      "Epoch 3075/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1503 - val_loss: 1.2179\n",
      "Epoch 3076/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1844 - val_loss: 1.1626\n",
      "Epoch 3077/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1507 - val_loss: 1.2002\n",
      "Epoch 3078/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1453 - val_loss: 1.2149\n",
      "Epoch 3079/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1279 - val_loss: 1.2236\n",
      "Epoch 3080/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1529 - val_loss: 1.1728\n",
      "Epoch 3081/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1670 - val_loss: 1.2820\n",
      "Epoch 3082/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1629 - val_loss: 1.1671\n",
      "Epoch 3083/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1444 - val_loss: 1.1708\n",
      "Epoch 3084/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1387 - val_loss: 1.4371\n",
      "Epoch 3085/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1693 - val_loss: 1.2208\n",
      "Epoch 3086/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1267 - val_loss: 1.1486\n",
      "Epoch 3087/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1679 - val_loss: 1.2120\n",
      "Epoch 3088/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1256 - val_loss: 1.2651\n",
      "Epoch 3089/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1368 - val_loss: 1.2561\n",
      "Epoch 3090/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1549 - val_loss: 1.2211\n",
      "Epoch 3091/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1794 - val_loss: 1.2118\n",
      "Epoch 3092/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1561 - val_loss: 1.2496\n",
      "Epoch 3093/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1272 - val_loss: 1.1658\n",
      "Epoch 3094/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1625 - val_loss: 1.4651\n",
      "Epoch 3095/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1498 - val_loss: 1.1222\n",
      "Epoch 3096/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1336 - val_loss: 1.2561\n",
      "Epoch 3097/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1526 - val_loss: 1.2424\n",
      "Epoch 3098/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1509 - val_loss: 1.2590\n",
      "Epoch 3099/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1579 - val_loss: 1.2291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3100/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1554 - val_loss: 1.1836\n",
      "Epoch 3101/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1824 - val_loss: 1.4158\n",
      "Epoch 3102/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1504 - val_loss: 1.2559\n",
      "Epoch 3103/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1549 - val_loss: 1.1594\n",
      "Epoch 3104/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2036 - val_loss: 1.2826\n",
      "Epoch 3105/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1553 - val_loss: 1.1430\n",
      "Epoch 3106/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1440 - val_loss: 1.2791\n",
      "Epoch 3107/20000\n",
      "1500/1500 [==============================] - 0s 30us/sample - loss: 1.1349 - val_loss: 1.2136\n",
      "Epoch 3108/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1568 - val_loss: 1.1234\n",
      "Epoch 3109/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1272 - val_loss: 1.2359\n",
      "Epoch 3110/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1288 - val_loss: 1.2969\n",
      "Epoch 3111/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1569 - val_loss: 1.1388\n",
      "Epoch 3112/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2032 - val_loss: 1.2163\n",
      "Epoch 3113/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1639 - val_loss: 1.2388\n",
      "Epoch 3114/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1941 - val_loss: 1.2276\n",
      "Epoch 3115/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1418 - val_loss: 1.2207\n",
      "Epoch 3116/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1648 - val_loss: 1.2781\n",
      "Epoch 3117/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1405 - val_loss: 1.2163\n",
      "Epoch 3118/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1151 - val_loss: 1.3195\n",
      "Epoch 3119/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1420 - val_loss: 1.1822\n",
      "Epoch 3120/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1714 - val_loss: 1.2506\n",
      "Epoch 3121/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1565 - val_loss: 1.2428\n",
      "Epoch 3122/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1665 - val_loss: 1.1518\n",
      "Epoch 3123/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1635 - val_loss: 1.2531\n",
      "Epoch 3124/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2079 - val_loss: 1.1382\n",
      "Epoch 3125/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2001 - val_loss: 1.3650\n",
      "Epoch 3126/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1954 - val_loss: 1.2146\n",
      "Epoch 3127/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1705 - val_loss: 1.1871\n",
      "Epoch 3128/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1427 - val_loss: 1.2075\n",
      "Epoch 3129/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1685 - val_loss: 1.5077\n",
      "Epoch 3130/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1789 - val_loss: 1.2076\n",
      "Epoch 3131/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1358 - val_loss: 1.1337\n",
      "Epoch 3132/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1602 - val_loss: 1.4328\n",
      "Epoch 3133/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1301 - val_loss: 1.1417\n",
      "Epoch 3134/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1397 - val_loss: 1.3054\n",
      "Epoch 3135/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1459 - val_loss: 1.1929\n",
      "Epoch 3136/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1495 - val_loss: 1.2393\n",
      "Epoch 3137/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1693 - val_loss: 1.1839\n",
      "Epoch 3138/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1325 - val_loss: 1.3517\n",
      "Epoch 3139/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1638 - val_loss: 1.2114\n",
      "Epoch 3140/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1798 - val_loss: 1.1643\n",
      "Epoch 3141/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1645 - val_loss: 1.2263\n",
      "Epoch 3142/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1585 - val_loss: 1.1873\n",
      "Epoch 3143/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1377 - val_loss: 1.1817\n",
      "Epoch 3144/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1876 - val_loss: 1.2496\n",
      "Epoch 3145/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1426 - val_loss: 1.1665\n",
      "Epoch 3146/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1586 - val_loss: 1.1507\n",
      "Epoch 3147/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1647 - val_loss: 1.1746\n",
      "Epoch 3148/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1475 - val_loss: 1.3669\n",
      "Epoch 3149/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1704 - val_loss: 1.2475\n",
      "Epoch 3150/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.2524 - val_loss: 1.6041\n",
      "Epoch 3151/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1721 - val_loss: 1.2549\n",
      "Epoch 3152/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1788 - val_loss: 1.1359\n",
      "Epoch 3153/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1470 - val_loss: 1.2309\n",
      "Epoch 3154/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1162 - val_loss: 1.3165\n",
      "Epoch 3155/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1942 - val_loss: 1.1931\n",
      "Epoch 3156/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1729 - val_loss: 1.1992\n",
      "Epoch 3157/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1144 - val_loss: 1.1550\n",
      "Epoch 3158/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1135 - val_loss: 1.3563\n",
      "Epoch 3159/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1692 - val_loss: 1.1883\n",
      "Epoch 3160/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1697 - val_loss: 1.1693\n",
      "Epoch 3161/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1729 - val_loss: 1.3847\n",
      "Epoch 3162/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2107 - val_loss: 1.1895\n",
      "Epoch 3163/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1476 - val_loss: 1.1900\n",
      "Epoch 3164/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2431 - val_loss: 1.1983\n",
      "Epoch 3165/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1470 - val_loss: 1.1414\n",
      "Epoch 3166/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1315 - val_loss: 1.2289\n",
      "Epoch 3167/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1686 - val_loss: 1.3124\n",
      "Epoch 3168/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1638 - val_loss: 1.2801\n",
      "Epoch 3169/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1408 - val_loss: 1.2854\n",
      "Epoch 3170/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1463 - val_loss: 1.3009\n",
      "Epoch 3171/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1341 - val_loss: 1.2823\n",
      "Epoch 3172/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1654 - val_loss: 1.1474\n",
      "Epoch 3173/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1594 - val_loss: 1.3197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3174/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1713 - val_loss: 1.3066\n",
      "Epoch 3175/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1749 - val_loss: 1.4682\n",
      "Epoch 3176/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1842 - val_loss: 1.1505\n",
      "Epoch 3177/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1481 - val_loss: 1.3082\n",
      "Epoch 3178/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1580 - val_loss: 1.2066\n",
      "Epoch 3179/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1285 - val_loss: 1.1512\n",
      "Epoch 3180/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1375 - val_loss: 1.1564\n",
      "Epoch 3181/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1414 - val_loss: 1.2441\n",
      "Epoch 3182/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1929 - val_loss: 1.1816\n",
      "Epoch 3183/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1556 - val_loss: 1.3492\n",
      "Epoch 3184/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1605 - val_loss: 1.1652\n",
      "Epoch 3185/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1394 - val_loss: 1.2334\n",
      "Epoch 3186/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1254 - val_loss: 1.1713\n",
      "Epoch 3187/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1074 - val_loss: 1.1840\n",
      "Epoch 3188/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1446 - val_loss: 1.3317\n",
      "Epoch 3189/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1584 - val_loss: 1.1875\n",
      "Epoch 3190/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1646 - val_loss: 1.3405\n",
      "Epoch 3191/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1476 - val_loss: 1.2797\n",
      "Epoch 3192/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1941 - val_loss: 1.3792\n",
      "Epoch 3193/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1491 - val_loss: 1.2749\n",
      "Epoch 3194/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1357 - val_loss: 1.1517\n",
      "Epoch 3195/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1568 - val_loss: 1.1855\n",
      "Epoch 3196/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1345 - val_loss: 1.2711\n",
      "Epoch 3197/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1672 - val_loss: 1.1995\n",
      "Epoch 3198/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1371 - val_loss: 1.1529\n",
      "Epoch 3199/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1360 - val_loss: 1.2132\n",
      "Epoch 3200/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1246 - val_loss: 1.1868\n",
      "Epoch 3201/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1242 - val_loss: 1.1747\n",
      "Epoch 3202/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1625 - val_loss: 1.1889\n",
      "Epoch 3203/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1650 - val_loss: 1.2484\n",
      "Epoch 3204/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1717 - val_loss: 1.1876\n",
      "Epoch 3205/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1606 - val_loss: 1.1486\n",
      "Epoch 3206/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1431 - val_loss: 1.2755\n",
      "Epoch 3207/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1704 - val_loss: 1.1820\n",
      "Epoch 3208/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1244 - val_loss: 1.3002\n",
      "Epoch 3209/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1787 - val_loss: 1.4577\n",
      "Epoch 3210/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1392 - val_loss: 1.1780\n",
      "Epoch 3211/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1338 - val_loss: 1.3434\n",
      "Epoch 3212/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1390 - val_loss: 1.1540\n",
      "Epoch 3213/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1792 - val_loss: 1.2048\n",
      "Epoch 3214/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1654 - val_loss: 1.1746\n",
      "Epoch 3215/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1312 - val_loss: 1.2601\n",
      "Epoch 3216/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2417 - val_loss: 1.3604\n",
      "Epoch 3217/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1379 - val_loss: 1.1271\n",
      "Epoch 3218/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1735 - val_loss: 1.3838\n",
      "Epoch 3219/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2136 - val_loss: 1.1535\n",
      "Epoch 3220/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1384 - val_loss: 1.1470\n",
      "Epoch 3221/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1227 - val_loss: 1.1761\n",
      "Epoch 3222/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1617 - val_loss: 1.2553\n",
      "Epoch 3223/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1313 - val_loss: 1.2347\n",
      "Epoch 3224/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2222 - val_loss: 1.1989\n",
      "Epoch 3225/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1642 - val_loss: 1.1923\n",
      "Epoch 3226/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1108 - val_loss: 1.2072\n",
      "Epoch 3227/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1206 - val_loss: 1.3578\n",
      "Epoch 3228/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1696 - val_loss: 1.1278\n",
      "Epoch 3229/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1279 - val_loss: 1.3638\n",
      "Epoch 3230/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1259 - val_loss: 1.3571\n",
      "Epoch 3231/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1412 - val_loss: 1.2432\n",
      "Epoch 3232/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1747 - val_loss: 1.1957\n",
      "Epoch 3233/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1520 - val_loss: 1.1878\n",
      "Epoch 3234/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1525 - val_loss: 1.1584\n",
      "Epoch 3235/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1185 - val_loss: 1.1733\n",
      "Epoch 3236/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1528 - val_loss: 1.2283\n",
      "Epoch 3237/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1308 - val_loss: 1.3142\n",
      "Epoch 3238/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1304 - val_loss: 1.2007\n",
      "Epoch 3239/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1390 - val_loss: 1.4483\n",
      "Epoch 3240/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1584 - val_loss: 1.1521\n",
      "Epoch 3241/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1369 - val_loss: 1.1973\n",
      "Epoch 3242/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1407 - val_loss: 1.2614\n",
      "Epoch 3243/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1290 - val_loss: 1.2126\n",
      "Epoch 3244/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1565 - val_loss: 1.3161\n",
      "Epoch 3245/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1741 - val_loss: 1.1455\n",
      "Epoch 3246/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1158 - val_loss: 1.5173\n",
      "Epoch 3247/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1864 - val_loss: 1.2189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3248/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1567 - val_loss: 1.3000\n",
      "Epoch 3249/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1589 - val_loss: 1.1693\n",
      "Epoch 3250/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1706 - val_loss: 1.1533\n",
      "Epoch 3251/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1492 - val_loss: 1.1585\n",
      "Epoch 3252/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1372 - val_loss: 1.2077\n",
      "Epoch 3253/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1378 - val_loss: 1.1422\n",
      "Epoch 3254/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1401 - val_loss: 1.3127\n",
      "Epoch 3255/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1557 - val_loss: 1.3938\n",
      "Epoch 3256/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1892 - val_loss: 1.1671\n",
      "Epoch 3257/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1311 - val_loss: 1.2816\n",
      "Epoch 3258/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1367 - val_loss: 1.2368\n",
      "Epoch 3259/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1902 - val_loss: 1.1950\n",
      "Epoch 3260/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1483 - val_loss: 1.1754\n",
      "Epoch 3261/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1414 - val_loss: 1.4378\n",
      "Epoch 3262/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1746 - val_loss: 1.1703\n",
      "Epoch 3263/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2080 - val_loss: 1.5463\n",
      "Epoch 3264/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2418 - val_loss: 1.1623\n",
      "Epoch 3265/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1696 - val_loss: 1.2731\n",
      "Epoch 3266/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1522 - val_loss: 1.8005\n",
      "Epoch 3267/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2649 - val_loss: 1.2306\n",
      "Epoch 3268/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2006 - val_loss: 1.5156\n",
      "Epoch 3269/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1763 - val_loss: 1.1523\n",
      "Epoch 3270/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1407 - val_loss: 1.1898\n",
      "Epoch 3271/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1519 - val_loss: 1.2265\n",
      "Epoch 3272/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1373 - val_loss: 1.2768\n",
      "Epoch 3273/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1760 - val_loss: 1.1644\n",
      "Epoch 3274/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1225 - val_loss: 1.2830\n",
      "Epoch 3275/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1657 - val_loss: 1.1481\n",
      "Epoch 3276/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1451 - val_loss: 1.2104\n",
      "Epoch 3277/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1354 - val_loss: 1.2661\n",
      "Epoch 3278/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2363 - val_loss: 1.4700\n",
      "Epoch 3279/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1526 - val_loss: 1.3129\n",
      "Epoch 3280/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1661 - val_loss: 1.2344\n",
      "Epoch 3281/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1291 - val_loss: 1.1497\n",
      "Epoch 3282/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1751 - val_loss: 1.3028\n",
      "Epoch 3283/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1784 - val_loss: 1.1626\n",
      "Epoch 3284/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1300 - val_loss: 1.2125\n",
      "Epoch 3285/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1283 - val_loss: 1.1548\n",
      "Epoch 3286/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1619 - val_loss: 1.1842\n",
      "Epoch 3287/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1611 - val_loss: 1.2816\n",
      "Epoch 3288/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1460 - val_loss: 1.2181\n",
      "Epoch 3289/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2037 - val_loss: 1.2376\n",
      "Epoch 3290/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1553 - val_loss: 1.2096\n",
      "Epoch 3291/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1221 - val_loss: 1.1569\n",
      "Epoch 3292/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1542 - val_loss: 1.2283\n",
      "Epoch 3293/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1364 - val_loss: 1.1531\n",
      "Epoch 3294/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1446 - val_loss: 1.2966\n",
      "Epoch 3295/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1941 - val_loss: 1.3744\n",
      "Epoch 3296/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1761 - val_loss: 1.2319\n",
      "Epoch 3297/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1893 - val_loss: 1.3665\n",
      "Epoch 3298/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1974 - val_loss: 1.4639\n",
      "Epoch 3299/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2083 - val_loss: 1.2557\n",
      "Epoch 3300/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1922 - val_loss: 1.3182\n",
      "Epoch 3301/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1808 - val_loss: 1.1131\n",
      "Epoch 3302/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2082 - val_loss: 1.2094\n",
      "Epoch 3303/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1635 - val_loss: 1.1957\n",
      "Epoch 3304/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1274 - val_loss: 1.2296\n",
      "Epoch 3305/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1275 - val_loss: 1.3301\n",
      "Epoch 3306/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1666 - val_loss: 1.2187\n",
      "Epoch 3307/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1192 - val_loss: 1.1618\n",
      "Epoch 3308/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1208 - val_loss: 1.3487\n",
      "Epoch 3309/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1342 - val_loss: 1.1854\n",
      "Epoch 3310/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1320 - val_loss: 1.3494\n",
      "Epoch 3311/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1569 - val_loss: 1.1778\n",
      "Epoch 3312/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1262 - val_loss: 1.3290\n",
      "Epoch 3313/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1251 - val_loss: 1.2493\n",
      "Epoch 3314/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1296 - val_loss: 1.2354\n",
      "Epoch 3315/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1274 - val_loss: 1.1776\n",
      "Epoch 3316/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2322 - val_loss: 1.2423\n",
      "Epoch 3317/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1204 - val_loss: 1.2331\n",
      "Epoch 3318/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1248 - val_loss: 1.2734\n",
      "Epoch 3319/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1284 - val_loss: 1.3514\n",
      "Epoch 3320/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1392 - val_loss: 1.1425\n",
      "Epoch 3321/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1608 - val_loss: 1.2448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3322/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1378 - val_loss: 1.2014\n",
      "Epoch 3323/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1306 - val_loss: 1.1406\n",
      "Epoch 3324/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1539 - val_loss: 1.1493\n",
      "Epoch 3325/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1888 - val_loss: 1.1841\n",
      "Epoch 3326/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1446 - val_loss: 1.4153\n",
      "Epoch 3327/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1721 - val_loss: 1.2141\n",
      "Epoch 3328/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1666 - val_loss: 1.2462\n",
      "Epoch 3329/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1455 - val_loss: 1.2341\n",
      "Epoch 3330/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1748 - val_loss: 1.3825\n",
      "Epoch 3331/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2316 - val_loss: 1.2071\n",
      "Epoch 3332/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1667 - val_loss: 1.2762\n",
      "Epoch 3333/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1512 - val_loss: 1.1847\n",
      "Epoch 3334/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1261 - val_loss: 1.3145\n",
      "Epoch 3335/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1405 - val_loss: 1.1798\n",
      "Epoch 3336/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1408 - val_loss: 1.2855\n",
      "Epoch 3337/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1452 - val_loss: 1.1871\n",
      "Epoch 3338/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2135 - val_loss: 1.1587\n",
      "Epoch 3339/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1905 - val_loss: 1.3457\n",
      "Epoch 3340/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1393 - val_loss: 1.1675\n",
      "Epoch 3341/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1718 - val_loss: 1.5188\n",
      "Epoch 3342/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1441 - val_loss: 1.1340\n",
      "Epoch 3343/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1482 - val_loss: 1.3291\n",
      "Epoch 3344/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1503 - val_loss: 1.1401\n",
      "Epoch 3345/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1666 - val_loss: 1.2092\n",
      "Epoch 3346/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1397 - val_loss: 1.1734\n",
      "Epoch 3347/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1476 - val_loss: 1.1939\n",
      "Epoch 3348/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1191 - val_loss: 1.1678\n",
      "Epoch 3349/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1320 - val_loss: 1.1802\n",
      "Epoch 3350/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1750 - val_loss: 1.1939\n",
      "Epoch 3351/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1236 - val_loss: 1.3183\n",
      "Epoch 3352/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1300 - val_loss: 1.1452\n",
      "Epoch 3353/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1366 - val_loss: 1.1998\n",
      "Epoch 3354/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1756 - val_loss: 1.3477\n",
      "Epoch 3355/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1941 - val_loss: 1.1938\n",
      "Epoch 3356/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.2018 - val_loss: 1.1487\n",
      "Epoch 3357/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1292 - val_loss: 1.1354\n",
      "Epoch 3358/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1349 - val_loss: 1.1326\n",
      "Epoch 3359/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1377 - val_loss: 1.2568\n",
      "Epoch 3360/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1474 - val_loss: 1.2085\n",
      "Epoch 3361/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1867 - val_loss: 1.2140\n",
      "Epoch 3362/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1591 - val_loss: 1.3506\n",
      "Epoch 3363/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2202 - val_loss: 1.1820\n",
      "Epoch 3364/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1460 - val_loss: 1.4138\n",
      "Epoch 3365/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1524 - val_loss: 1.2754\n",
      "Epoch 3366/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1485 - val_loss: 1.3365\n",
      "Epoch 3367/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1455 - val_loss: 1.1537\n",
      "Epoch 3368/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1475 - val_loss: 1.3577\n",
      "Epoch 3369/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1358 - val_loss: 1.2543\n",
      "Epoch 3370/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1297 - val_loss: 1.1952\n",
      "Epoch 3371/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1580 - val_loss: 1.2008\n",
      "Epoch 3372/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1616 - val_loss: 1.3103\n",
      "Epoch 3373/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1298 - val_loss: 1.1352\n",
      "Epoch 3374/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1272 - val_loss: 1.2124\n",
      "Epoch 3375/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1578 - val_loss: 1.1941\n",
      "Epoch 3376/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1427 - val_loss: 1.2055\n",
      "Epoch 3377/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2055 - val_loss: 1.2920\n",
      "Epoch 3378/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1371 - val_loss: 1.2110\n",
      "Epoch 3379/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1591 - val_loss: 1.2286\n",
      "Epoch 3380/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1902 - val_loss: 1.2391\n",
      "Epoch 3381/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1528 - val_loss: 1.1995\n",
      "Epoch 3382/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1259 - val_loss: 1.1577\n",
      "Epoch 3383/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1311 - val_loss: 1.3143\n",
      "Epoch 3384/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1813 - val_loss: 1.1460\n",
      "Epoch 3385/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1295 - val_loss: 1.1651\n",
      "Epoch 3386/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1462 - val_loss: 1.1614\n",
      "Epoch 3387/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1908 - val_loss: 1.5685\n",
      "Epoch 3388/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1694 - val_loss: 1.2199\n",
      "Epoch 3389/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1253 - val_loss: 1.1967\n",
      "Epoch 3390/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1613 - val_loss: 1.2618\n",
      "Epoch 3391/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1400 - val_loss: 1.1689\n",
      "Epoch 3392/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1484 - val_loss: 1.4012\n",
      "Epoch 3393/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1711 - val_loss: 1.1917\n",
      "Epoch 3394/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1439 - val_loss: 1.2112\n",
      "Epoch 3395/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1164 - val_loss: 1.1676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3396/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1232 - val_loss: 1.1775\n",
      "Epoch 3397/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1383 - val_loss: 1.2572\n",
      "Epoch 3398/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1273 - val_loss: 1.1829\n",
      "Epoch 3399/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1597 - val_loss: 1.3319\n",
      "Epoch 3400/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1409 - val_loss: 1.1758\n",
      "Epoch 3401/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1568 - val_loss: 1.3555\n",
      "Epoch 3402/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1740 - val_loss: 1.1907\n",
      "Epoch 3403/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1490 - val_loss: 1.1924\n",
      "Epoch 3404/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1420 - val_loss: 1.2063\n",
      "Epoch 3405/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1581 - val_loss: 1.1740\n",
      "Epoch 3406/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1332 - val_loss: 1.2995\n",
      "Epoch 3407/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2018 - val_loss: 1.2545\n",
      "Epoch 3408/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2575 - val_loss: 1.1883\n",
      "Epoch 3409/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.2169 - val_loss: 1.2215\n",
      "Epoch 3410/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1394 - val_loss: 1.1613\n",
      "Epoch 3411/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1566 - val_loss: 1.4267\n",
      "Epoch 3412/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1881 - val_loss: 1.1628\n",
      "Epoch 3413/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1451 - val_loss: 1.1820\n",
      "Epoch 3414/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1431 - val_loss: 1.1724\n",
      "Epoch 3415/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1161 - val_loss: 1.2208\n",
      "Epoch 3416/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1289 - val_loss: 1.2952\n",
      "Epoch 3417/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2096 - val_loss: 1.2150\n",
      "Epoch 3418/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1757 - val_loss: 1.1534\n",
      "Epoch 3419/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1719 - val_loss: 1.3509\n",
      "Epoch 3420/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1359 - val_loss: 1.1612\n",
      "Epoch 3421/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1563 - val_loss: 1.2726\n",
      "Epoch 3422/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1473 - val_loss: 1.1991\n",
      "Epoch 3423/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1331 - val_loss: 1.1895\n",
      "Epoch 3424/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2264 - val_loss: 1.2048\n",
      "Epoch 3425/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1588 - val_loss: 1.1903\n",
      "Epoch 3426/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1688 - val_loss: 1.3476\n",
      "Epoch 3427/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1943 - val_loss: 1.1565\n",
      "Epoch 3428/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2269 - val_loss: 1.3753\n",
      "Epoch 3429/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1340 - val_loss: 1.5015\n",
      "Epoch 3430/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1888 - val_loss: 1.1352\n",
      "Epoch 3431/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1439 - val_loss: 1.1631\n",
      "Epoch 3432/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1497 - val_loss: 1.3353\n",
      "Epoch 3433/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1741 - val_loss: 1.2189\n",
      "Epoch 3434/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1531 - val_loss: 1.2740\n",
      "Epoch 3435/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1811 - val_loss: 1.1394\n",
      "Epoch 3436/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1474 - val_loss: 1.2727\n",
      "Epoch 3437/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.1346 - val_loss: 1.1561\n",
      "Epoch 3438/20000\n",
      "1500/1500 [==============================] - 0s 32us/sample - loss: 1.1406 - val_loss: 1.2470\n",
      "Epoch 3439/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1451 - val_loss: 1.2527\n",
      "Epoch 3440/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1659 - val_loss: 1.1877\n",
      "Epoch 3441/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1458 - val_loss: 1.2002\n",
      "Epoch 3442/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1423 - val_loss: 1.3075\n",
      "Epoch 3443/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1697 - val_loss: 1.3632\n",
      "Epoch 3444/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1594 - val_loss: 1.2049\n",
      "Epoch 3445/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1789 - val_loss: 1.1971\n",
      "Epoch 3446/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2090 - val_loss: 1.1883\n",
      "Epoch 3447/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1347 - val_loss: 1.1444\n",
      "Epoch 3448/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1856 - val_loss: 1.2587\n",
      "Epoch 3449/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1649 - val_loss: 1.5160\n",
      "Epoch 3450/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1631 - val_loss: 1.1582\n",
      "Epoch 3451/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1403 - val_loss: 1.2036\n",
      "Epoch 3452/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1410 - val_loss: 1.1981\n",
      "Epoch 3453/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1446 - val_loss: 1.6345\n",
      "Epoch 3454/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1718 - val_loss: 1.1615\n",
      "Epoch 3455/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1423 - val_loss: 1.2267\n",
      "Epoch 3456/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1318 - val_loss: 1.3232\n",
      "Epoch 3457/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1421 - val_loss: 1.1808\n",
      "Epoch 3458/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1303 - val_loss: 1.1408\n",
      "Epoch 3459/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1512 - val_loss: 1.3393\n",
      "Epoch 3460/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1908 - val_loss: 1.2958\n",
      "Epoch 3461/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1306 - val_loss: 1.1543\n",
      "Epoch 3462/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1423 - val_loss: 1.1445\n",
      "Epoch 3463/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1787 - val_loss: 1.1542\n",
      "Epoch 3464/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1954 - val_loss: 1.4283\n",
      "Epoch 3465/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1638 - val_loss: 1.2621\n",
      "Epoch 3466/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2027 - val_loss: 1.2408\n",
      "Epoch 3467/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1586 - val_loss: 1.1894\n",
      "Epoch 3468/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1509 - val_loss: 1.3388\n",
      "Epoch 3469/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1390 - val_loss: 1.1568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3470/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1233 - val_loss: 1.2553\n",
      "Epoch 3471/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1496 - val_loss: 1.2350\n",
      "Epoch 3472/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1793 - val_loss: 1.1759\n",
      "Epoch 3473/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1561 - val_loss: 1.3312\n",
      "Epoch 3474/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1560 - val_loss: 1.3029\n",
      "Epoch 3475/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1324 - val_loss: 1.1579\n",
      "Epoch 3476/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1209 - val_loss: 1.1791\n",
      "Epoch 3477/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1515 - val_loss: 1.2378\n",
      "Epoch 3478/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1595 - val_loss: 1.1850\n",
      "Epoch 3479/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1120 - val_loss: 1.2962\n",
      "Epoch 3480/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1485 - val_loss: 1.1878\n",
      "Epoch 3481/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1320 - val_loss: 1.2308\n",
      "Epoch 3482/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1395 - val_loss: 1.2094\n",
      "Epoch 3483/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1271 - val_loss: 1.1699\n",
      "Epoch 3484/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1551 - val_loss: 1.2438\n",
      "Epoch 3485/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2751 - val_loss: 1.3420\n",
      "Epoch 3486/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.2097 - val_loss: 1.2605\n",
      "Epoch 3487/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1743 - val_loss: 1.2289\n",
      "Epoch 3488/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1263 - val_loss: 1.6674\n",
      "Epoch 3489/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1808 - val_loss: 1.1775\n",
      "Epoch 3490/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1223 - val_loss: 1.1619\n",
      "Epoch 3491/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1507 - val_loss: 1.1882\n",
      "Epoch 3492/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1446 - val_loss: 1.2999\n",
      "Epoch 3493/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1730 - val_loss: 1.3630\n",
      "Epoch 3494/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1545 - val_loss: 1.5455\n",
      "Epoch 3495/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2247 - val_loss: 1.2311\n",
      "Epoch 3496/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1189 - val_loss: 1.2004\n",
      "Epoch 3497/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1377 - val_loss: 1.3848\n",
      "Epoch 3498/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1746 - val_loss: 1.1675\n",
      "Epoch 3499/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1429 - val_loss: 1.2620\n",
      "Epoch 3500/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1575 - val_loss: 1.1758\n",
      "Epoch 3501/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1374 - val_loss: 1.2591\n",
      "Epoch 3502/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1512 - val_loss: 1.1378\n",
      "Epoch 3503/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1396 - val_loss: 1.2076\n",
      "Epoch 3504/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1455 - val_loss: 1.2202\n",
      "Epoch 3505/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1477 - val_loss: 1.2565\n",
      "Epoch 3506/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1378 - val_loss: 1.2604\n",
      "Epoch 3507/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1481 - val_loss: 1.1831\n",
      "Epoch 3508/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1212 - val_loss: 1.2656\n",
      "Epoch 3509/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1418 - val_loss: 1.2535\n",
      "Epoch 3510/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1474 - val_loss: 1.2204\n",
      "Epoch 3511/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1780 - val_loss: 1.2453\n",
      "Epoch 3512/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1970 - val_loss: 1.1950\n",
      "Epoch 3513/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2035 - val_loss: 1.1864\n",
      "Epoch 3514/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2122 - val_loss: 1.2594\n",
      "Epoch 3515/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1650 - val_loss: 1.1568\n",
      "Epoch 3516/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1282 - val_loss: 1.2341\n",
      "Epoch 3517/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1366 - val_loss: 1.1639\n",
      "Epoch 3518/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1494 - val_loss: 1.1994\n",
      "Epoch 3519/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1276 - val_loss: 1.4578\n",
      "Epoch 3520/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1701 - val_loss: 1.2240\n",
      "Epoch 3521/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1255 - val_loss: 1.1435\n",
      "Epoch 3522/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1390 - val_loss: 1.1903\n",
      "Epoch 3523/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1250 - val_loss: 1.1527\n",
      "Epoch 3524/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1636 - val_loss: 1.1749\n",
      "Epoch 3525/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1697 - val_loss: 1.1722\n",
      "Epoch 3526/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1362 - val_loss: 1.2233\n",
      "Epoch 3527/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1478 - val_loss: 1.1461\n",
      "Epoch 3528/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1152 - val_loss: 1.1559\n",
      "Epoch 3529/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1481 - val_loss: 1.1810\n",
      "Epoch 3530/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1311 - val_loss: 1.1727\n",
      "Epoch 3531/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1503 - val_loss: 1.2784\n",
      "Epoch 3532/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1408 - val_loss: 1.2022\n",
      "Epoch 3533/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1212 - val_loss: 1.1794\n",
      "Epoch 3534/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1779 - val_loss: 1.3249\n",
      "Epoch 3535/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1334 - val_loss: 1.1997\n",
      "Epoch 3536/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1634 - val_loss: 1.1777\n",
      "Epoch 3537/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1468 - val_loss: 1.2621\n",
      "Epoch 3538/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1284 - val_loss: 1.2917\n",
      "Epoch 3539/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1226 - val_loss: 1.2103\n",
      "Epoch 3540/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1546 - val_loss: 1.1701\n",
      "Epoch 3541/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1618 - val_loss: 1.3253\n",
      "Epoch 3542/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1245 - val_loss: 1.2354\n",
      "Epoch 3543/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1543 - val_loss: 1.1432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3544/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1541 - val_loss: 1.1803\n",
      "Epoch 3545/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1653 - val_loss: 1.2249\n",
      "Epoch 3546/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1856 - val_loss: 1.2249\n",
      "Epoch 3547/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2004 - val_loss: 1.1670\n",
      "Epoch 3548/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1576 - val_loss: 1.1958\n",
      "Epoch 3549/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.1781 - val_loss: 1.2115\n",
      "Epoch 3550/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1518 - val_loss: 1.4134\n",
      "Epoch 3551/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1569 - val_loss: 1.2367\n",
      "Epoch 3552/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1903 - val_loss: 1.1698\n",
      "Epoch 3553/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1242 - val_loss: 1.1641\n",
      "Epoch 3554/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1130 - val_loss: 1.1865\n",
      "Epoch 3555/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1270 - val_loss: 1.2587\n",
      "Epoch 3556/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1367 - val_loss: 1.3386\n",
      "Epoch 3557/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1416 - val_loss: 1.1593\n",
      "Epoch 3558/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1267 - val_loss: 1.1874\n",
      "Epoch 3559/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1315 - val_loss: 1.2827\n",
      "Epoch 3560/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2923 - val_loss: 1.1675\n",
      "Epoch 3561/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2020 - val_loss: 1.2007\n",
      "Epoch 3562/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1627 - val_loss: 1.2973\n",
      "Epoch 3563/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1566 - val_loss: 1.3890\n",
      "Epoch 3564/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1851 - val_loss: 1.2021\n",
      "Epoch 3565/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1482 - val_loss: 1.2228\n",
      "Epoch 3566/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1365 - val_loss: 1.1777\n",
      "Epoch 3567/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1252 - val_loss: 1.1518\n",
      "Epoch 3568/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1527 - val_loss: 1.1949\n",
      "Epoch 3569/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1526 - val_loss: 1.1557\n",
      "Epoch 3570/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1915 - val_loss: 1.5595\n",
      "Epoch 3571/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.2449 - val_loss: 1.2067\n",
      "Epoch 3572/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1515 - val_loss: 1.2023\n",
      "Epoch 3573/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1315 - val_loss: 1.2781\n",
      "Epoch 3574/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2328 - val_loss: 1.1737\n",
      "Epoch 3575/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1910 - val_loss: 1.2168\n",
      "Epoch 3576/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1821 - val_loss: 1.1768\n",
      "Epoch 3577/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1793 - val_loss: 1.1454\n",
      "Epoch 3578/20000\n",
      "1500/1500 [==============================] - 0s 21us/sample - loss: 1.1489 - val_loss: 1.1850\n",
      "Epoch 3579/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1734 - val_loss: 1.2067\n",
      "Epoch 3580/20000\n",
      "1500/1500 [==============================] - 0s 26us/sample - loss: 1.1708 - val_loss: 1.1390\n",
      "Epoch 3581/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1681 - val_loss: 1.4357\n",
      "Epoch 3582/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1821 - val_loss: 1.1483\n",
      "Epoch 3583/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1440 - val_loss: 1.2274\n",
      "Epoch 3584/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2410 - val_loss: 1.2769\n",
      "Epoch 3585/20000\n",
      "1500/1500 [==============================] - 0s 22us/sample - loss: 1.2000 - val_loss: 1.2030\n",
      "Epoch 3586/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1906 - val_loss: 1.2087\n",
      "Epoch 3587/20000\n",
      "1500/1500 [==============================] - 0s 28us/sample - loss: 1.1628 - val_loss: 1.2197\n",
      "Epoch 3588/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1426 - val_loss: 1.2679\n",
      "Epoch 3589/20000\n",
      "1500/1500 [==============================] - 0s 27us/sample - loss: 1.1619 - val_loss: 1.2477\n",
      "Epoch 3590/20000\n",
      "1500/1500 [==============================] - 0s 25us/sample - loss: 1.1577 - val_loss: 1.1895\n",
      "Epoch 3591/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1399 - val_loss: 1.4281\n",
      "Epoch 3592/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1607 - val_loss: 1.2615\n",
      "Epoch 3593/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1415 - val_loss: 1.2089\n",
      "Epoch 3594/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1144 - val_loss: 1.4399\n",
      "Epoch 3595/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.2478 - val_loss: 1.2415\n",
      "Epoch 3596/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1696 - val_loss: 1.2165\n",
      "Epoch 3597/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1367 - val_loss: 1.4839\n",
      "Epoch 3598/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1853 - val_loss: 1.1928\n",
      "Epoch 3599/20000\n",
      "1500/1500 [==============================] - 0s 29us/sample - loss: 1.1492 - val_loss: 1.1497\n",
      "Epoch 3600/20000\n",
      "1500/1500 [==============================] - 0s 31us/sample - loss: 1.2368 - val_loss: 1.3023\n",
      "Epoch 3601/20000\n",
      "1500/1500 [==============================] - 0s 24us/sample - loss: 1.1366 - val_loss: 1.2075\n",
      "Epoch 3602/20000\n",
      "1500/1500 [==============================] - 0s 23us/sample - loss: 1.1321 - val_loss: 1.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [06:50<00:00, 205.35s/it]\n"
     ]
    }
   ],
   "source": [
    "t = ta.Scan(x=train_df, y=train_label,\n",
    "            x_val=test_df, y_val=test_label,\n",
    "            model=numerai_model,\n",
    "            params=p,\n",
    "            experiment_name='Predykcja OMC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-material",
   "metadata": {},
   "source": [
    "# 3. Wczytuje wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "buried-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/STUDIA/ROK_II/Projekt/Okres Między Ciążowy/Sieci neuro/Zestaw jalowka + krowa/Predykcja OMC/052121175036.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-ultimate",
   "metadata": {},
   "source": [
    "## 3.1 Wyliczam ilość neuronów i połączeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "advance-producer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   round_epochs      loss  val_loss activation_layer  batc_normalization  \\\n",
      "1          3602  1.132074  1.151797             selu               False   \n",
      "0          5032  1.388968  1.153912             selu                True   \n",
      "\n",
      "   batch_size  dropout  epochs  first_neuron  hidden_layers  hidden_neuron  \\\n",
      "1          64        0   20000           160              1             25   \n",
      "0          64        0   20000           160              1             25   \n",
      "\n",
      "  kernel_initializer last_activation optimizer  nodes    links  \\\n",
      "1               ones          linear      adam    185  17020.0   \n",
      "0               ones          linear      adam    185  17020.0   \n",
      "\n",
      "   val_loss_improvement  \n",
      "1             -0.019723  \n",
      "0              0.235056  \n"
     ]
    }
   ],
   "source": [
    "df['nodes'] = df.first_neuron + df.hidden_neuron*df.hidden_layers\n",
    "df['links'] =  df.nodes * (df.nodes-1) / 2\n",
    "df['val_loss_improvement'] = df.loss - df.val_loss \n",
    "#compare to baseline log-loss (higher is better)\n",
    "print(df.sort_values('val_loss').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "086e68cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>activation_layer</th>\n",
       "      <th>batc_normalization</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>hidden_neuron</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>nodes</th>\n",
       "      <th>links</th>\n",
       "      <th>val_loss_improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3602</td>\n",
       "      <td>1.132074</td>\n",
       "      <td>1.151797</td>\n",
       "      <td>selu</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>ones</td>\n",
       "      <td>linear</td>\n",
       "      <td>adam</td>\n",
       "      <td>185</td>\n",
       "      <td>17020.0</td>\n",
       "      <td>-0.019723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5032</td>\n",
       "      <td>1.388968</td>\n",
       "      <td>1.153912</td>\n",
       "      <td>selu</td>\n",
       "      <td>True</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>ones</td>\n",
       "      <td>linear</td>\n",
       "      <td>adam</td>\n",
       "      <td>185</td>\n",
       "      <td>17020.0</td>\n",
       "      <td>0.235056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round_epochs      loss  val_loss activation_layer  batc_normalization  \\\n",
       "1          3602  1.132074  1.151797             selu               False   \n",
       "0          5032  1.388968  1.153912             selu                True   \n",
       "\n",
       "   batch_size  dropout  epochs  first_neuron  hidden_layers  hidden_neuron  \\\n",
       "1          64        0   20000           160              1             25   \n",
       "0          64        0   20000           160              1             25   \n",
       "\n",
       "  kernel_initializer last_activation optimizer  nodes    links  \\\n",
       "1               ones          linear      adam    185  17020.0   \n",
       "0               ones          linear      adam    185  17020.0   \n",
       "\n",
       "   val_loss_improvement  \n",
       "1             -0.019723  \n",
       "0              0.235056  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-plenty",
   "metadata": {},
   "source": [
    "## 3.2 Najlepszy wynik walidacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "superb-membership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1517969125111898"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sorted-death",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([1.15179691, 1.15200839, 1.15221988, 1.15243136, 1.15264284,\n",
       "        1.15285432, 1.1530658 , 1.15327728, 1.15348877, 1.15370025,\n",
       "        1.15391173]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANI0lEQVR4nO3dX4xc512H8efLmlRQGoLwBlr/YV3kUozUoHTrVkKFoIrWDhALwYXTiEBoZVmqgZuIuLLUXkSViCIEqpp2ZVVWVAnqm6bFBbcJNzQXbYTXxUnsNq4WJ423DrKTQCsIaur2x8WctJPJ7O7x5pxZu34+0ipzznln9t1XR3n2zOyMU1VIkq5uP7HWE5AkrT1jIEkyBpIkYyBJwhhIkoB1a/WN169fXzMzM2v17SXpinT8+PFnq2q668ddsxjMzMwwPz+/Vt9ekq5ISb7Zx+P6NJEkyRhIkoyBJAljIEnCGEiSMAaSJFrEIMmhJOeTnFzieJJ8NMlCkseS3Nj9NCVJfWpzZXA/sGOZ4zuBrc3XHuATr35akqRJWjEGVfUw8PwyQ3YBn6qBR4Drkry+qwlKkvrXxTuQNwBnh7YXm33PjA5MsofB1QObN29e9Tec2f/Pq77vq/XUX//umn1vSd3x/yMv18ULyBmzb+w/n1ZVB6tqtqpmp6c7/2gNSdIqdRGDRWDT0PZG4FwHjytJmpAuYnAEuL35q6J3AN+uqlc8RSRJunyt+JpBkk8DNwHrkywCHwZ+EqCq5oCjwM3AAvACcEdfk5Uk9WPFGFTVrSscL+ADnc1IkjRxvgNZkmQMJEnGQJKEMZAkYQwkSRgDSRLGQJKEMZAkYQwkSRgDSRLGQJKEMZAkYQwkSRgDSRLGQJKEMZAkYQwkSRgDSRLGQJKEMZAkYQwkSRgDSRLGQJKEMZAkYQwkSRgDSRLGQJKEMZAkYQwkSRgDSRLGQJKEMZAk0TIGSXYkOZ1kIcn+Mcd/Nsnnkzya5FSSO7qfqiSpLyvGIMkUcB+wE9gG3Jpk28iwDwBfq6obgJuAv0lyTcdzlST1pM2VwXZgoarOVNWLwGFg18iYAl6XJMDPAM8DFzudqSSpN21isAE4O7S92Owb9jHgV4FzwOPAX1bVD0YfKMmeJPNJ5i9cuLDKKUuSutYmBhmzr0a23wOcAN4A/DrwsSTXvuJOVQeraraqZqenpy9xqpKkvrSJwSKwaWh7I4MrgGF3AA/UwALwJPDmbqYoSepbmxgcA7Ym2dK8KLwbODIy5mngXQBJfgH4FeBMlxOVJPVn3UoDqupikn3Ag8AUcKiqTiXZ2xyfA+4G7k/yOIOnle6qqmd7nLckqUMrxgCgqo4CR0f2zQ3dPge8u9upSZImxXcgS5KMgSTJGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJFrGIMmOJKeTLCTZv8SYm5KcSHIqyZe6naYkqU/rVhqQZAq4D/gdYBE4luRIVX1taMx1wMeBHVX1dJLre5qvJKkHba4MtgMLVXWmql4EDgO7Rsa8F3igqp4GqKrz3U5TktSnNjHYAJwd2l5s9g17E/BzSf41yfEkt3c1QUlS/1Z8mgjImH015nHeCrwL+CngK0keqapvvOyBkj3AHoDNmzdf+mwlSb1oc2WwCGwa2t4InBsz5otV9b9V9SzwMHDD6ANV1cGqmq2q2enp6dXOWZLUsTYxOAZsTbIlyTXAbuDIyJh/BN6ZZF2SnwbeDny926lKkvqy4tNEVXUxyT7gQWAKOFRVp5LsbY7PVdXXk3wReAz4AfDJqjrZ58QlSd1p85oBVXUUODqyb25k+17g3u6mJkmaFN+BLEkyBpIkYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiRaxiDJjiSnkywk2b/MuLcl+X6SP+puipKkvq0YgyRTwH3ATmAbcGuSbUuMuwd4sOtJSpL61ebKYDuwUFVnqupF4DCwa8y4Pwc+A5zvcH6SpAloE4MNwNmh7cVm3w8l2QD8ATC33AMl2ZNkPsn8hQsXLnWukqSetIlBxuyrke2/A+6qqu8v90BVdbCqZqtqdnp6uuUUJUl9W9dizCKwaWh7I3BuZMwscDgJwHrg5iQXq+pzXUxSktSvNjE4BmxNsgX4FrAbeO/wgKra8tLtJPcD/2QIJOnKsWIMqupikn0M/kpoCjhUVaeS7G2OL/s6gSTp8tfmyoCqOgocHdk3NgJV9aevflqSpEnyHciSJGMgSTIGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSSJljFIsiPJ6SQLSfaPOX5bkseary8nuaH7qUqS+rJiDJJMAfcBO4FtwK1Jto0MexL4rap6C3A3cLDriUqS+tPmymA7sFBVZ6rqReAwsGt4QFV9uar+q9l8BNjY7TQlSX1qE4MNwNmh7cVm31LeB3xh3IEke5LMJ5m/cOFC+1lKknrVJgYZs6/GDkx+m0EM7hp3vKoOVtVsVc1OT0+3n6UkqVfrWoxZBDYNbW8Ezo0OSvIW4JPAzqp6rpvpSZImoc2VwTFga5ItSa4BdgNHhgck2Qw8APxxVX2j+2lKkvq04pVBVV1Msg94EJgCDlXVqSR7m+NzwIeAnwc+ngTgYlXN9jdtSVKX2jxNRFUdBY6O7Jsbuv1+4P3dTk2SNCm+A1mSZAwkScZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJtIxBkh1JTidZSLJ/zPEk+Whz/LEkN3Y/VUlSX1aMQZIp4D5gJ7ANuDXJtpFhO4Gtzdce4BMdz1OS1KM2VwbbgYWqOlNVLwKHgV0jY3YBn6qBR4Drkry+47lKknqyrsWYDcDZoe1F4O0txmwAnhkelGQPgysHgP9JcvqSZrv21ucenl3rSVzG1oPrswzXZ3lXzfrknku+y/Da/FKnk2m0iUHG7KtVjKGqDgIHW3zPy1KS+aqaXet5XK5cn+W5PstzfZY2ibVp8zTRIrBpaHsjcG4VYyRJl6k2MTgGbE2yJck1wG7gyMiYI8DtzV8VvQP4dlU9M/pAkqTL04pPE1XVxST7gAeBKeBQVZ1Ksrc5PgccBW4GFoAXgDv6m/KaumKf4poQ12d5rs/yXJ+l9b42qXrFU/uSpKuM70CWJBkDSdJVFIMkh5KcT3JyieNvTvKVJN9NcufIsaeSPJ7kRJL5of33Jnmi+QiOzya5bujYB5uP5zid5D29/WAdmeT6JJlJ8n/N+BNJ5nr94TrQ0/rc3azNiSQPJXnD0DHPnyXWx/PnFfe9M0klWT+079LPn6q6Kr6A3wRuBE4ucfx64G3AR4A7R449Bawfc593A+ua2/cA9zS3twGPAq8BtgD/AUyt9RpcRuszs9T3uVy/elqfa4du/wUw5/nTan08f350bBODP+755ktjVnv+XDVXBlX1MPD8MsfPV9Ux4HuX8JgPVdXFZvMRBu+vgMHHcxyuqu9W1ZMM/spq++pmPhkTXp8rTk/r852hzdfyozdqev6w7PpccfpYn8bfAn/Fy9dmVefPVRODV6mAh5Icbz5SY5w/A77Q3F7q4zl+XF3q+gBsSfLvSb6U5J39T3FNLbk+ST6S5CxwG/ChZrfnT2OJ9QHPH5LcAnyrqh4dGb+q86fNx1EIfqOqziW5HviXJE80pQcgyQHgIvD3L+0a8xhX7G81LVzq+jwDbK6q55K8Ffhckl8b+U3wx8mS61NVB4ADST4I7AM+jOfPSutz1Z8/wDxwgMFTsaNWdf54ZdBCVZ1r/nse+CxDl1xJ/gT4PeC2ap6w4yr7eI5LXZ/m8vW55vZxBs9pvmnS856U5dZnyD8Af9jc9vx5pR+uj+cP24FfZvB6wKNJnmJwjnw1yS+yyvPHGKwgyWuTvO6l2wxKfLLZ3gHcBdxSVS8M3e0IsDvJa5JsYfDvPPzbZGc+GatZnyTTGfw7GSR5I4P1OTPpuU/CCuuzdWjoLcATzW3PH5ZeH88fTlbV41V1fVXNVNUMgwDcWFX/yWrPn7V+lX1SX8CnGVxefq9ZuPcBe4G9zfGXivod4L+b29cCb2TwyvyjwCngwNBjLjB4bu5E8zU3dOwAg99YTgM71/rnv5zWh8FveKea+3wV+P21/vnXaH0+w+B/fI8Bnwc2eP6svD6eP2Mf/ymG/uJoNeePH0chSfJpIkmSMZAkYQwkSRgDSRLGQJKEMZAkYQwkScD/Ax5g+kp/FNlbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-mumbai",
   "metadata": {},
   "source": [
    "## 3.3 Jednowymairowe zależności\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-football",
   "metadata": {},
   "source": [
    "### 3.3.1 Pierwsza warstwa neurony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "intimate-clearance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Log-Loss  as function of first_neuron')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'first_neuron'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Log-Loss  as function of {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-engineering",
   "metadata": {},
   "source": [
    "### 3.3.2 Liczba ukrytych neuronów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "about-address",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Log-Loss as function of hidden_neuron')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEXCAYAAACOFGLrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcXElEQVR4nO3de5wcZZ3v8c8XEoIGImAGgSQQLgEEFgLO4eiLi3BgQ0Auu0ZYOCCgKxEWNnLWeEGQm4vLWdDVrCLggQMIieLGuAoCQQUiCodMIJCA4Z6QSQIZIDkBLyGX3/5RT0Nl6J7piU9nejLf9+s1r1TXU5dfVXf62/VUdbUiAjMzs1w26e0CzMxs4+JgMTOzrBwsZmaWlYPFzMyycrCYmVlWDhYzM8vKwWL9lqRzJL0i6U1J79+A6/2KpP+zodZXWu/fSlqYtnf/Ku0habca854qaXoXy75f0mdqtI1Myx6w/tVbX+Jg2QhJmi/pyAav4zBJ7Y1cRyNJGgh8ExgTEVtExGsNWs+79lNEfD0iqr4JN9jVwHlpex/ryYwRcVtEjGlQXbaRcbBYf/UBYHPgyd4uZAPaif61vdn5qKs+DpZ+RNIgSd+StDj9fUvSoFL7FyUtSW2f6aprpJv1fDB1jSyX9KSk40ttx0h6StIbkhZJmpjGD5V0R5rndUm/kVT19Snp26lLZ4WkWZIOKbUdKKkttb0i6ZtV5t8deDo9XC7p19W6a8rdO5LOlPSgpKslLZP0oqSjS9NuI+n/pn23TNJPJQ0G7gJ2SN1Pb0raQdKlkm4tzXt82k/L0zo/WGqbL2mipCck/X9JP5K0eY39somkiyQtkLRU0i2S3pee9zeBTYHHJT3fxdN3pKRn0zZ8V5LK219a119Lmpdq+g6gUtumaT+9KukF4GOd6nyfpBvSa22RpH+WtGk9+7mWtN++Jum36bU1XdLQUvuHJf0u7ePHJR3WaR8fWXr89vNTel38vaSXgF/X2s+dpj9D0ktpH1zYXf0bGwdL/3Ih8GFgNLAfcCBwEYCkscA/AUcCuwEfXZ8VqOhi+jkwHdgW+EfgNkl7pEluAD4bEVsC+wC/TuM/D7QDLRRHE18Bat1vaGbahm2AycCPS2+23wa+HRFDgF2B2zvPHBHPAHunh1tFxP+oc/P+O0UgDQX+Fbih8sYL/AB4b1rutsC/RcQfgKOBxan7aYuIWFxeYAq5KcD5adt/Afxc0malyU4CxgI7A/sCZ9ao78z0dziwC7AF8J2IWBkRW6Rp9ouIXbvYxmOB/0bx+jgJOKrzBOkNeyrFa2co8DxwUGmSs9Jy9gdagU90WsTNwGqK19n+wBig3DXY1X7uyv8EPkWx/zcDKh9ahgF3Av9M8ZqZCEyV1FLHMis+CnyQYn+cSZX93Gn6g4E9gCOAi8sfFvqFiPDfRvYHzAeOrDL+eeCY0uOjgPlp+EbgX0ptu1G8se9WYx2HAe1Vxh8CvAxsUho3Bbg0Db8EfBYY0mm+y4H/rLW+brZ3GcUbJsAM4DJgaDfzjEzbN6Da4zTufuAzafhM4LlS23vT9NsB2wNrga3r2U/ApcCtafirwO2ltk2ARcBhpefytFL7vwLX1timXwH/UHq8B7CqtI01n89S+8Glx7cDXy5t/4Np+HTg4dJ0ovhQUNlXvwbOLrWPqexbig8NK4H3lNpPAe7rbj9383zeD1xUevwPwN1p+EvADzpNfw9wRrX/L52en8rrYpd69nNp+uGl9keAk3v6uu7Lfz5i6V92ABaUHi9I4yptC0ttbw9L2rHUlfNmHetYGBFrO61nWBoeBxwDLJD0gKSPpPFXAc8B0yW9IOnLtVYg6fOSfp+6YZYD76P4dAvw98DuwDxJMyUd2029PfFyZSAi/pgGtwBGAK9HxLL1WOY6z0nabwt5Z3+ts17gj2md3S4rDVfezOtVz7rWea1E8e65sFZ7p5p2AgYCS1K31HLgOoqjjHfV0Gk/r2/tOwEnVtaX1nkwxQeCenXevu72c73P2UbJJ6L6l8WsewJ3xzQOYAkwvDTtiMpARLxE/f8xFgMjJG1SCpcdgWfSsmYCJ6Qus/MoPhWPiIg3KLrDPi9pb+A+STMj4lflhas4n/Ilii6GJyNiraRlpD7+iHgWOEXF+ZmPA/8h6f1RdEt1pdL+XmBFGt6uzm1eCGwjaauIWN6prbvbhy8G/qryIHX5jKA4aumpyvNbsSNFl9Mr67Gsriyh9Poo1Vy1PdVRsZDiiGVoRKzOXFctCymOWM6q0f4Hiue9otrzXn4eu9rP5f9D/ZaPWDZeAyVtXvobQNEldZGkltRPfjFQOYl8O/ApFSfe35vautVpHZtTHPb/AfiipIHpJOlxwA8lbabi+xDvi4hVFG/ga9JyjpW0W3qTqoxfU2WVW1L8J+4ABki6GBhSquc0SS0p1Jan0dWWs46I6KB4Mz8tnXz+NMU5mm5FxBKKk/TXSNo6bfehqfkV4P2Vk7tV3A58TNIRKWw/T/HG+7t61t3JFOB/SdpZ0hbA14EfNeAN/E5gb0kfT6+rCaz7Znw7MEHScElbA28ffaZ9NR34hqQh6UT4rpLW65xenW4FjpN0VHpuN1dxGXglBGYDJ6fnrdo5oc421H7usxwsG69fAH8q/V1KcfKyDXgCmAM8msYREXcBk4D7KLqkHkrLWdnFOoZ1WsefKD6pHk9x0vpV4Brg9IiYl+b5JDBf0grgbOC0NH4U8EvgzbTuayLi/irrvIfiTfwZii6IP7NuN8VY4MnUZfdtir7tP3exDWVnAV8AXqM4Cd+TN/dPUvSzzwOWUpyMJ233FOCF1A2zQ3mmiHiaYh/8O8X+Og44LiLe6sG6K26kuIhgBvAixb75x/VYTpci4lXgROBKin01CvhtaZLvUzxPj1O8xn7SaRGnU5xcf4ri/Nh/0LNuqZ7WuxA4geKCkA6K18sXeOf976sUHyKWUZyfm9zNIjfIfu7LlE4uma0jXcUyFxjkT2Jm1hM+YrG3qbjlx2ap++J/Az93qJhZTzlYrOyzFF0Fz1Oclzind8sxe0f5ysROf4d0P7dtSO4KMzOzrBp6xCLpRhW3PJhbo31PSQ9JWql0a49S23xJcyTNltRWZd6JKm6dUL5twwWSnpP0tKR3fWPYzMwar9HfY7mJ4lYHt9Rof53iUsW/qdF+eLoCZR2SRgB/TfEt7sq4vYCTKa7m2QH4paTdI6LLS02HDh0aI0eO7HIjzMxsXbNmzXo1IqreFqehwRIRMySN7KJ9KbBU0sdqTVPDvwFfpLgFSMUJwA8jYiXwoqTnKO6F9VCV+d82cuRI2tredUBkZmZdkLSgVlszn7wPitt7zJI0vjJSxZ1yF0XE452mH8a632doZ93bYrxN0ngVd8Bt6+joyF23mVm/1sy3dDkoIhZL2ha4V9I8ii/3XUhxU7vOqt39tOqVCRFxPXA9QGtrq69eMDPLqGmDJdLtxSNiqaRpFN1ayyhuHf54cecPhgOPSjqQ4gilfH+i4bxzHywzM9tAmrIrTNJgSVtWhimOUOZGxJyI2DYiRkbESIowOSAiXgZ+RnG/n0GSdqa4zcQjvbQJZmb9VkOPWCRNofg9iqEqfvf7EopbZhMR10rajqJ7awiwVtL5wF4Ut0Cflo5KBgCTI+LurtYVEU9Kup3i/kOrgXO7uyLMzMzy6/dfkGxtbQ1fFWZm1jOSZkVEa7W2puwKMzOzvqtpT95b/zR16lQWLVqf37ja+FQuhW9p6clPs2+8hg0bxrhx43q7DKuDg8WsSa1c2dVP4Zg1LweLNRV/In3HpEmTAJgwYUIvV2LWMz7HYmZmWTlYzMwsKweLmZll5WAxM7OsHCxmZpaVg8XMzLJysJiZWVYOFjMzy8rBYmZmWTlYzMwsKweLmZll5WAxM7OsHCxmZpaVg8XMzLJysJiZWVYOFjMzy8rBYmZmWTlYzMwsKweLmZll5WAxM7OsHCxmZpaVg8XMzLJysJiZWVYOFjMzy8rBYmZmWTlYzMwsKweLmZll5WAxM7OsHCxmZpaVg8XMzLJysJiZWVYOFjMzy8rBYmZmWTlYzMwsq4YGi6QbJS2VNLdG+56SHpK0UtLETm3zJc2RNFtSW2n81yQ9kcZPl7RDGj9S0p/S+NmSrm3ktpmZWXWNPmK5CRjbRfvrwATg6hrth0fE6IhoLY27KiL2jYjRwB3AxaW259P0oyPi7L+gbjMzW08NDZaImEERHrXal0bETGBVD5a5ovRwMBDrX6GZmeXWzOdYApguaZak8eUGSVdIWgicyrpHLDtLekzSA5IOqbVgSeMltUlq6+joaEz1Zmb9VDMHy0ERcQBwNHCupEMrDRFxYUSMAG4DzkujlwA7RsT+wD8BkyUNqbbgiLg+IlojorWlpaWxW2Fm1s80bbBExOL071JgGnBglckmA+PSdCsj4rU0PAt4Hth9w1RrZmYVTRkskgZL2rIyDIwB5qbHo0qTHg/MS+NbJG2ahncBRgEvbMi6zcwMBjRy4ZKmAIcBQyW1A5cAAwEi4lpJ2wFtwBBgraTzgb2AocA0SZUaJ0fE3WmxV0raA1gLLAAqV38dClwuaTWwBjg7ImpeOGBmZo3R0GCJiFO6aX8ZGF6laQWwX415xtUYPxWY2tMazcwsr6bsCjMzs77LwWJmZlk5WMzMLCsHi5mZZdXQk/dWn6lTp7Jo0aLeLsOaTHt7OwCTJk3q5Uqs2QwbNoxx46pex9QUHCxNYNGiRSx84Xk+sJmfDnvHwFVrAHirfUEvV2LN5JW3Vvd2Cd3yO1mT+MBmAzh9+617uwwza3K3LFnW2yV0y+dYzMwsKweLmZll5WAxM7OsHCxmZpaVg8XMzLJysJiZWVYOFjMzy8rBYmZmWTlYzMwsKweLmZll5WAxM7OsHCxmZpaVg8XMzLJysJiZWVYOFjMzy8rBYmZmWTlYzMwsKweLmZll5WAxM7OsHCxmZpaVg8XMzLJysJiZWVYOFjMzy8rBYmZmWTlYzMwsKweLmZll5WAxM7OsHCxmZpaVg8XMzLJysJiZWVYNDRZJN0paKmlujfY9JT0kaaWkiZ3a5kuaI2m2pLbS+K9JeiKNny5ph1LbBZKek/S0pKMat2VmZlZLXcEi6URJW6bhiyT9RNIBdcx6EzC2i/bXgQnA1TXaD4+I0RHRWhp3VUTsGxGjgTuAi1NdewEnA3undV4jadM6ajQzs4zqPWL5akS8Ielg4CjgZuB73c0UETMowqNW+9KImAmsqrMOImJF6eFgINLwCcAPI2JlRLwIPAccWO9yzcwsj3qDZU3692PA9yLiP4HNGlPS2wKYLmmWpPHlBklXSFoInEo6YgGGAQtLk7WncWZmtgHVGyyLJF0HnAT8QtKgHsy7vg6KiAOAo4FzJR1aaYiICyNiBHAbcF4arSrLiCrjkDReUpukto6Ojtx1m5n1a/WGw0nAPcDYiFgObAN8oVFFAUTE4vTvUmAa1bu1JgPj0nA7MKLUNhxYXGPZ10dEa0S0trS05CvazMzqDpbtgTsj4llJhwEnAo80qihJg0sXCwwGxgBz0+NRpUmPB+al4Z8BJ0saJGlnYFQjazQzs+oG1DndVKBV0m7ADRRv4pOBY7qaSdIU4DBgqKR24BJgIEBEXCtpO6ANGAKslXQ+sBcwFJgmqVLj5Ii4Oy32Skl7AGuBBcDZaXlPSrodeApYDZwbEZVzQ2ZmtoHUGyxrI2K1pI8D34qIf5f0WHczRcQp3bS/TNFl1dkKYL8a84yrNj61XQFc0V1dZmbWOPV2ha2SdApwOsV3RyAdeZiZmZXVGyyfAj4CXBERL6ZzGLc2riwzM+ur6gqWiHgKmAjMkbQP0B4RVza0MjMz65PqOseSrgS7GZhP8X2REZLOSN+sNzMze1u9J++/AYyJiKcBJO0OTAE+1KjCzMysb6r3HMvASqgARMQz+OS9mZlVUe8RS5ukG4AfpMenArMaU5KZmfVl9QbLOcC5FLe4FzADuKZRRfU3HR0d/Hnlam5Zsqy3SzGzJvfKytVs3uT3OKwrWCJiJfDN9GdmZlZTl8EiaQ417hAMEBH7Zq+oH2ppaeGtlX/k9O237u1SzKzJ3bJkGZs1+c1zuztiOXaDVGFmZhuNLoMlIhbUsxBJD0XER/KUZGZmfVmuH+vaPNNyzMysj8sVLDXPw5iZWf/S6J8XNjOzfiZXsFT7vXkzM+uHcgXLJzMtx8zM+rjuvsfyBtXPnwiIiBhCMTC3AbWZmVkf1N3lxltuqELMzGzjUO+9wgCQtC2lS4sj4qXsFZmZWZ9W1zkWScdLehZ4EXiA4ge/7mpgXWZm1kfVe/L+a8CHgWciYmfgCOC3DavKzMz6rHqDZVVEvAZsImmTiLgPGN24sszMrK+q9xzLcklbAL8BbpO0FFjduLLMzKyvqveIZQawFfA54G7geeC4BtVkZmZ9WL3BIuAe4H5gC+BHqWvMzMxsHXUFS0RcFhF7U/w88Q7AA5J+2dDKzMysT+rpLV2WAi8DrwHb5i/HzMz6unq/x3KOpPuBXwFDgbP8s8RmZlZNvVeF7QScHxGzG1iLmZltBOoKloj4cqMLMTOzjYN/6MvMzLJysJiZWVYOFjMzy8rBYmZmWTlYzMwsKweLmZll5WAxM7OsGhoskm6UtFTS3Brte0p6SNJKSRM7tc2XNEfSbEltpfFXSZon6QlJ0yRtlcaPlPSnNP1sSdc2ctvMzKy6Rh+x3ASM7aL9dWACcHWN9sMjYnREtJbG3Qvsk24p8wxwQant+TT96Ig4+y+o28zM1lNDgyUiZlCER632pRExE1jVg2VOj4jKj4w9DAz/y6o0M7OcmvkcSwDTJc2SNL7GNJ8G7io93lnSY5IekHRIrQVLGi+pTVJbR0dHzprNzPq9em9C2RsOiojFkrYF7pU0Lx0BASDpQoqfR74tjVoC7BgRr0n6EPBTSXtHxIrOC46I64HrAVpbW6PhW2Jm1o807RFLRCxO/y4FpgEHVtoknQEcC5waEZGmW1n5VcuImEXx88m7b+i6zcz6u6YMFkmDJW1ZGQbGAHPT47HAl4DjI+KPpXlaJG2ahncBRgEvbOjazcz6u4Z2hUmaAhwGDJXUDlwCDASIiGslbQe0AUOAtZLOB/ai+DGxaZIqNU6OiLvTYr8DDKLoHgN4OF0BdihwuaTVwBrg7IioeeGAmZk1RkODJSJO6ab9Zapf1bUC2K/GPLvVGD8VmNrTGs3MLK+m7AozM7O+y8FiZmZZOVjMzCwrB4uZmWXlYDEzs6wcLGZmlpWDxczMsnKwmJlZVg4WMzPLysFiZmZZNfNt8/uVV95azS1LlvV2GdZElq1aA8DWAzft5Uqsmbzy1mpG9HYR3XCwNIFhw4b1dgnWhFa1twOw2XD/SKq9YwTN/57hYGkC48aN6+0SrAlNmjQJgAkTJvRyJWY943MsZmaWlYPFzMyycrCYmVlWDhYzM8vKwWJmZlk5WMzMLCsHi5mZZeVgMTOzrBwsZmaWlYPFzMyycrCYmVlWDhYzM8vKwWJmZlk5WMzMLCsHi5mZZeVgMTOzrBwsZmaWlYPFzMyycrCYmVlWDhYzM8vKwWJmZlk5WMzMLCsHi5mZZeVgMTOzrBwsZmaWVUODRdKNkpZKmlujfU9JD0laKWlip7b5kuZImi2prTT+KknzJD0haZqkrUptF0h6TtLTko5q2IaZmVlNjT5iuQkY20X768AE4Ooa7YdHxOiIaC2NuxfYJyL2BZ4BLgCQtBdwMrB3Wuc1kjb9y8o3M7OeamiwRMQMivCo1b40ImYCq3qwzOkRsTo9fBgYnoZPAH4YESsj4kXgOeDA9avczMzWVzOfYwlguqRZksbXmObTwF1peBiwsNTWnsa9i6TxktoktXV0dGQr2MzMmjtYDoqIA4CjgXMlHVpulHQhsBq4rTKqyjKi2oIj4vqIaI2I1paWlpw1m5n1e00bLBGxOP27FJhGqVtL0hnAscCpEVEJj3ZgRGkRw4HFG6ZaMzOraMpgkTRY0paVYWAMMDc9Hgt8CTg+Iv5Ymu1nwMmSBknaGRgFPLJhKzczswGNXLikKcBhwFBJ7cAlwECAiLhW0nZAGzAEWCvpfGAvYCgwTVKlxskRcXda7HeAQcC9qf3hiDg7Ip6UdDvwFEUX2bkRsaaR22dmZu/W0GCJiFO6aX+Zd67qKlsB7Fdjnt26WN4VwBU9qdHMzPJqyq4wMzPruxwsZmaWlYPFzMyycrCYmVlWDhYzM8vKwWJmZlk5WMzMLCsHi5mZZeVgMTOzrBwsZmaWlYPFzMyycrCYmVlWDb0JpVlPTZ06lUWLFvV2GU2hvb0dgEmTJvVyJc1h2LBhjBs3rrfLsDo4WMya1KBBg3q7BLP14mCxpuJPpGZ9n8+xmJlZVg4WMzPLysFiZmZZOVjMzCwrB4uZmWXlYDEzs6wcLGZmlpWDxczMslJE9HYNvUpSB7Cgt+swq2Eo8GpvF2FWxU4R0VKtod8Hi1kzk9QWEa29XYdZT7grzMzMsnKwmJlZVg4Ws+Z2fW8XYNZTPsdiZmZZ+YjFzMyycrCYmVlWDhazJiBphKT7JP1e0pOSPpfGXyppkaTZ6e+Y3q7VrDs+x2LWBCRtD2wfEY9K2hKYBfwNcBLwZkRc3Zv1mfWEf5rYrAlExBJgSRp+Q9LvgWG9W5XZ+nFXmFmTkTQS2B/4f2nUeZKekHSjpK17rzKz+jhYzJqIpC2AqcD5EbEC+B6wKzCa4ojmG71XnVl9fI7FrElIGgjcAdwTEd+s0j4SuCMi9tnQtZn1hI9YzJqAJAE3AL8vh0o6qV/xt8DcDV2bWU/5iMWsCUg6GPgNMAdYm0Z/BTiFohssgPnAZ9OJfrOm5WAxM7Os3BVmZmZZOVjMzCwrB4uZmWXlYDEzs6wcLGZmlpWDxczMsnKwmCWSRkp61xcQJV0u6cgq4w+TdEeNZc2XNLQRdZo1O9/d2KwbEXFxb9fQKJIGRMTq3q7DNi4+YjFb16aSvp9+bGu6pPdIuknSJwAkjZU0T9KDwMcrM0l6f5r+MUnXASq1nSbpkfRDXddJ2jSNf1PSFZIel/SwpA/UKirVMEnS7yS9UKkntX1B0sx0B+TL0rh1jr4kTZR0aRq+X9LXJT0AfE7SEanuOekOyoPSdPMlXSbp0dS2Z55dbBs7B4vZukYB342IvYHlwLhKg6TNge8DxwGHANuV5rsEeDAi9gd+BuyY5vkg8HfAQRExGlgDnJrmGQw8HBH7ATOAs7qpbXvgYOBY4Mq0/DGp5gMpbv3yIUmH1rGdW0XER4HvAjcBfxcRf0XRi3FOabpXI+IAirssT6xjuWYOFrNOXoyI2Wl4FjCy1LZnan82insh3VpqO7TyOCLuBJal8UcAHwJmSpqdHu+S2t6iuJtxtXVV89OIWBsRTwGVo5sx6e8x4NFU46g6tvNH6d890jY9kx7fnLal4ic9qM8M8DkWs85WlobXAO/p1N7VzfWqtQm4OSIuqNK2Kt65Wd8auv//WK5NpX//JSKuW2el0nDW/eC4eadl/aHTcrpbZz31mQE+YjHriXnAzpJ2TY9PKbXNIHVxSToaqPzS46+AT0jaNrVtI2mnjDXdA3w6/UAYkoaldb0CbJvO/Qyi6D6rtU0jJe2WHn8SeCBjfdYP+ROIWZ0i4s+SxgN3SnoVeBCo/OjWZcAUSY9SvDG/lOZ5StJFwHRJmwCrgHOBBZlqmp7O4zxU/KQLbwKnRcRSSZdT/LzxixQBUmubPgX8WNIAYCZwbY7arP/ybfPNzCwrd4WZmVlW7gozayKSLgRO7DT6xxFxRW/UY7Y+3BVmZmZZuSvMzMyycrCYmVlWDhYzM8vKwWJmZln9FxOxOjcOMkV7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'hidden_neuron'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Log-Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-thing",
   "metadata": {},
   "source": [
    "### 3.3.3 Liczba ukrytych warstw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1759a313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of hidden_layers')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'hidden_layers'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e3bf4",
   "metadata": {},
   "source": [
    "### 3.3.4 Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "033d0ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of batch_size')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'batch_size'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7c87c",
   "metadata": {},
   "source": [
    "### 3.3.5 kernel_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e46dab39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of kernel_initializer')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'kernel_initializer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051af8d3",
   "metadata": {},
   "source": [
    "### 3.3.6 activation_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d43df1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of activation_layer')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'activation_layer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135cd8b9",
   "metadata": {},
   "source": [
    "### 3.3.6 Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef5f4b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of optimizer')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'optimizer'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1865a6",
   "metadata": {},
   "source": [
    "### 3.3.7 Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f772265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Loss as function of batc_normalization')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'batc_normalization'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_title(f'Validation Loss as function of {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8539bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'CI Validation Loss as function of batch normalization')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'batc_normalization'\n",
    "ax = sns.boxplot(x=metric, y=\"val_loss\", data=df.reset_index(),color='salmon')\n",
    "ax.set_ylim([1.1, 1.6]) \n",
    "ax.set_ylabel('Absolute Error of validation loss')\n",
    "ax.set_xlabel('Batch normalization')\n",
    "ax.set_title('CI Validation Loss as function of batch normalization') #ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c665dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
